{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Question 1: Word2Vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Importing libraries and reading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup             \n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords # Import the stop word list\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier \n",
    "from sklearn.metrics import roc_auc_score,accuracy_score, roc_curve,auc\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "train = pd.read_csv(\"labeledTrainData.tsv\", header=0, delimiter=\"\\t\", quoting=3)\n",
    "test  = pd.read_csv(\"testData.tsv\", header=0, delimiter=\"\\t\", quoting=3)\n",
    "unlabeled_train = pd.read_csv( \"unlabeledTrainData.tsv\", header=0, delimiter=\"\\t\", quoting=3 )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "[Kaggle tutorial blog](https://www.kaggle.com/c/word2vec-nlp-tutorial#part-2-word-vectors) instructions followed to create functions and models below.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Function to convert raw review text to word lists "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def review_to_wordlist( review, remove_stopwords=False ):\n",
    "    # Function to convert a document to a sequence of words,\n",
    "    # optionally removing stop words.  Returns a list of words.\n",
    "    #\n",
    "    # 1. Remove HTML\n",
    "    review_text = BeautifulSoup(review, \"html5lib\").get_text()\n",
    "    #  \n",
    "    # 2. Remove non-letters\n",
    "    review_text = re.sub(\"[^a-zA-Z]\",\" \", review_text)\n",
    "    #\n",
    "    # 3. Convert words to lower case and split them\n",
    "    words = review_text.lower().split()\n",
    "    #\n",
    "    # 4. Optionally remove stop words (false by default)\n",
    "    if remove_stopwords:\n",
    "        stops = set(stopwords.words(\"english\"))\n",
    "        words = [w for w in words if not w in stops]\n",
    "    #\n",
    "    # 5. Return a list of words\n",
    "    return(words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "The Word2Vec model expects sentences as its input. Hence, we will create a function to split sentences with the punkt tokenizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/anuragroy/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Download the punkt tokenizer for sentence splitting\n",
    "import nltk.data\n",
    "nltk.download('punkt')   \n",
    "\n",
    "# Load the punkt tokenizer\n",
    "tokenizer = nltk.data.load('tokenizers/punkt/english.pickle')\n",
    "# Define a function to split a review into parsed sentences\n",
    "def review_to_sentences( review, tokenizer, remove_stopwords=False ):\n",
    "    # Function to split a review into parsed sentences. Returns a \n",
    "    # list of sentences, where each sentence is a list of words\n",
    "    #\n",
    "    # 1. Use the NLTK tokenizer to split the paragraph into sentences\n",
    "    raw_sentences = tokenizer.tokenize(review.strip())\n",
    "    #\n",
    "    # 2. Loop over each sentence\n",
    "    sentences = []\n",
    "    for raw_sentence in raw_sentences:\n",
    "        # If a sentence is empty, skip it\n",
    "        if len(raw_sentence) > 0:\n",
    "            # Otherwise, call review_to_wordlist to get a list of words\n",
    "            sentences.append( review_to_wordlist( raw_sentence, \\\n",
    "              remove_stopwords ))\n",
    "    #\n",
    "    # Return the list of sentences (each sentence is a list of words,\n",
    "    # so this returns a list of lists\n",
    "    return sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Parsing sentences from the datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing sentences from training set\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/anuragroy/miniconda3/lib/python3.5/site-packages/bs4/__init__.py:219: UserWarning: \"b'.'\" looks like a filename, not markup. You shouldprobably open this file and pass the filehandle intoBeautiful Soup.\n",
      "  'Beautiful Soup.' % markup)\n",
      "/Users/anuragroy/miniconda3/lib/python3.5/site-packages/bs4/__init__.py:282: UserWarning: \"http://www.happierabroad.com\"\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing sentences from unlabeled set\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/anuragroy/miniconda3/lib/python3.5/site-packages/bs4/__init__.py:282: UserWarning: \"http://www.archive.org/details/LovefromaStranger\"\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/Users/anuragroy/miniconda3/lib/python3.5/site-packages/bs4/__init__.py:282: UserWarning: \"http://www.loosechangeguide.com/LooseChangeGuide.html\"\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/Users/anuragroy/miniconda3/lib/python3.5/site-packages/bs4/__init__.py:282: UserWarning: \"http://www.msnbc.msn.com/id/4972055/site/newsweek/\"\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/Users/anuragroy/miniconda3/lib/python3.5/site-packages/bs4/__init__.py:219: UserWarning: \"b'..'\" looks like a filename, not markup. You shouldprobably open this file and pass the filehandle intoBeautiful Soup.\n",
      "  'Beautiful Soup.' % markup)\n",
      "/Users/anuragroy/miniconda3/lib/python3.5/site-packages/bs4/__init__.py:282: UserWarning: \"http://www.youtube.com/watch?v=a0KSqelmgN8\"\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/Users/anuragroy/miniconda3/lib/python3.5/site-packages/bs4/__init__.py:282: UserWarning: \"http://jake-weird.blogspot.com/2007/08/beneath.html\"\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Parsing complete\n"
     ]
    }
   ],
   "source": [
    "sentences = []  # Initialize an empty list of sentences\n",
    "\n",
    "print (\"Parsing sentences from training set\")\n",
    "for review in train[\"review\"]:\n",
    "    sentences += review_to_sentences(review, tokenizer)\n",
    "\n",
    "print (\"Parsing sentences from unlabeled set\")\n",
    "for review in unlabeled_train[\"review\"]:\n",
    "    sentences += review_to_sentences(review, tokenizer)\n",
    "\n",
    "print (\"\\n Parsing complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Import the built-in logging module and configure it so that Word2Vec \n",
    "# creates nice output messages\n",
    "import logging\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s',\\\n",
    "    level=logging.INFO)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Part a)\n",
    "\n",
    "We will now use word2vec to create vector representations for each model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-04-21 21:06:25,974 : INFO : collecting all words and their counts\n",
      "2017-04-21 21:06:25,975 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2017-04-21 21:06:26,043 : INFO : PROGRESS: at sentence #10000, processed 225803 words, keeping 17776 word types\n",
      "2017-04-21 21:06:26,108 : INFO : PROGRESS: at sentence #20000, processed 451892 words, keeping 24948 word types\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-04-21 21:06:26,168 : INFO : PROGRESS: at sentence #30000, processed 671315 words, keeping 30034 word types\n",
      "2017-04-21 21:06:26,233 : INFO : PROGRESS: at sentence #40000, processed 897815 words, keeping 34348 word types\n",
      "2017-04-21 21:06:26,288 : INFO : PROGRESS: at sentence #50000, processed 1116963 words, keeping 37761 word types\n",
      "2017-04-21 21:06:26,351 : INFO : PROGRESS: at sentence #60000, processed 1338404 words, keeping 40723 word types\n",
      "2017-04-21 21:06:26,407 : INFO : PROGRESS: at sentence #70000, processed 1561580 words, keeping 43333 word types\n",
      "2017-04-21 21:06:26,469 : INFO : PROGRESS: at sentence #80000, processed 1780887 words, keeping 45714 word types\n",
      "2017-04-21 21:06:26,528 : INFO : PROGRESS: at sentence #90000, processed 2004996 words, keeping 48135 word types\n",
      "2017-04-21 21:06:26,589 : INFO : PROGRESS: at sentence #100000, processed 2226967 words, keeping 50207 word types\n",
      "2017-04-21 21:06:26,648 : INFO : PROGRESS: at sentence #110000, processed 2446581 words, keeping 52081 word types\n",
      "2017-04-21 21:06:26,709 : INFO : PROGRESS: at sentence #120000, processed 2668776 words, keeping 54119 word types\n",
      "2017-04-21 21:06:26,770 : INFO : PROGRESS: at sentence #130000, processed 2894304 words, keeping 55847 word types\n",
      "2017-04-21 21:06:26,828 : INFO : PROGRESS: at sentence #140000, processed 3107006 words, keeping 57346 word types\n",
      "2017-04-21 21:06:26,889 : INFO : PROGRESS: at sentence #150000, processed 3332628 words, keeping 59055 word types\n",
      "2017-04-21 21:06:26,948 : INFO : PROGRESS: at sentence #160000, processed 3555316 words, keeping 60617 word types\n",
      "2017-04-21 21:06:27,007 : INFO : PROGRESS: at sentence #170000, processed 3778656 words, keeping 62077 word types\n",
      "2017-04-21 21:06:27,070 : INFO : PROGRESS: at sentence #180000, processed 3999237 words, keeping 63496 word types\n",
      "2017-04-21 21:06:27,134 : INFO : PROGRESS: at sentence #190000, processed 4224450 words, keeping 64794 word types\n",
      "2017-04-21 21:06:27,197 : INFO : PROGRESS: at sentence #200000, processed 4448604 words, keeping 66087 word types\n",
      "2017-04-21 21:06:27,257 : INFO : PROGRESS: at sentence #210000, processed 4669968 words, keeping 67390 word types\n",
      "2017-04-21 21:06:27,318 : INFO : PROGRESS: at sentence #220000, processed 4894969 words, keeping 68697 word types\n",
      "2017-04-21 21:06:27,383 : INFO : PROGRESS: at sentence #230000, processed 5117546 words, keeping 69958 word types\n",
      "2017-04-21 21:06:27,446 : INFO : PROGRESS: at sentence #240000, processed 5345051 words, keeping 71167 word types\n",
      "2017-04-21 21:06:27,506 : INFO : PROGRESS: at sentence #250000, processed 5559166 words, keeping 72351 word types\n",
      "2017-04-21 21:06:27,567 : INFO : PROGRESS: at sentence #260000, processed 5779147 words, keeping 73478 word types\n",
      "2017-04-21 21:06:27,622 : INFO : PROGRESS: at sentence #270000, processed 6000436 words, keeping 74767 word types\n",
      "2017-04-21 21:06:27,684 : INFO : PROGRESS: at sentence #280000, processed 6226315 words, keeping 76369 word types\n",
      "2017-04-21 21:06:27,744 : INFO : PROGRESS: at sentence #290000, processed 6449475 words, keeping 77839 word types\n",
      "2017-04-21 21:06:27,808 : INFO : PROGRESS: at sentence #300000, processed 6674078 words, keeping 79171 word types\n",
      "2017-04-21 21:06:27,870 : INFO : PROGRESS: at sentence #310000, processed 6899392 words, keeping 80480 word types\n",
      "2017-04-21 21:06:27,933 : INFO : PROGRESS: at sentence #320000, processed 7124279 words, keeping 81808 word types\n",
      "2017-04-21 21:06:27,990 : INFO : PROGRESS: at sentence #330000, processed 7346022 words, keeping 83030 word types\n",
      "2017-04-21 21:06:28,054 : INFO : PROGRESS: at sentence #340000, processed 7575534 words, keeping 84280 word types\n",
      "2017-04-21 21:06:28,113 : INFO : PROGRESS: at sentence #350000, processed 7798804 words, keeping 85425 word types\n",
      "2017-04-21 21:06:28,175 : INFO : PROGRESS: at sentence #360000, processed 8019467 words, keeping 86596 word types\n",
      "2017-04-21 21:06:28,244 : INFO : PROGRESS: at sentence #370000, processed 8246659 words, keeping 87708 word types\n",
      "2017-04-21 21:06:28,309 : INFO : PROGRESS: at sentence #380000, processed 8471806 words, keeping 88878 word types\n",
      "2017-04-21 21:06:28,372 : INFO : PROGRESS: at sentence #390000, processed 8701556 words, keeping 89907 word types\n",
      "2017-04-21 21:06:28,429 : INFO : PROGRESS: at sentence #400000, processed 8924505 words, keeping 90916 word types\n",
      "2017-04-21 21:06:28,491 : INFO : PROGRESS: at sentence #410000, processed 9145855 words, keeping 91880 word types\n",
      "2017-04-21 21:06:28,554 : INFO : PROGRESS: at sentence #420000, processed 9366935 words, keeping 92912 word types\n",
      "2017-04-21 21:06:28,616 : INFO : PROGRESS: at sentence #430000, processed 9594472 words, keeping 93932 word types\n",
      "2017-04-21 21:06:28,680 : INFO : PROGRESS: at sentence #440000, processed 9821225 words, keeping 94906 word types\n",
      "2017-04-21 21:06:28,746 : INFO : PROGRESS: at sentence #450000, processed 10044987 words, keeping 96036 word types\n",
      "2017-04-21 21:06:28,814 : INFO : PROGRESS: at sentence #460000, processed 10277747 words, keeping 97088 word types\n",
      "2017-04-21 21:06:28,872 : INFO : PROGRESS: at sentence #470000, processed 10505672 words, keeping 97933 word types\n",
      "2017-04-21 21:06:28,935 : INFO : PROGRESS: at sentence #480000, processed 10726056 words, keeping 98862 word types\n",
      "2017-04-21 21:06:29,000 : INFO : PROGRESS: at sentence #490000, processed 10952800 words, keeping 99871 word types\n",
      "2017-04-21 21:06:29,060 : INFO : PROGRESS: at sentence #500000, processed 11174456 words, keeping 100765 word types\n",
      "2017-04-21 21:06:29,117 : INFO : PROGRESS: at sentence #510000, processed 11399731 words, keeping 101699 word types\n",
      "2017-04-21 21:06:29,178 : INFO : PROGRESS: at sentence #520000, processed 11623082 words, keeping 102598 word types\n",
      "2017-04-21 21:06:29,245 : INFO : PROGRESS: at sentence #530000, processed 11847480 words, keeping 103400 word types\n",
      "2017-04-21 21:06:29,311 : INFO : PROGRESS: at sentence #540000, processed 12072095 words, keeping 104265 word types\n",
      "2017-04-21 21:06:29,375 : INFO : PROGRESS: at sentence #550000, processed 12297646 words, keeping 105133 word types\n",
      "2017-04-21 21:06:29,438 : INFO : PROGRESS: at sentence #560000, processed 12518936 words, keeping 105997 word types\n",
      "2017-04-21 21:06:29,496 : INFO : PROGRESS: at sentence #570000, processed 12748083 words, keeping 106787 word types\n",
      "2017-04-21 21:06:29,559 : INFO : PROGRESS: at sentence #580000, processed 12969579 words, keeping 107665 word types\n",
      "2017-04-21 21:06:29,624 : INFO : PROGRESS: at sentence #590000, processed 13195104 words, keeping 108501 word types\n",
      "2017-04-21 21:06:29,680 : INFO : PROGRESS: at sentence #600000, processed 13417302 words, keeping 109218 word types\n",
      "2017-04-21 21:06:29,746 : INFO : PROGRESS: at sentence #610000, processed 13638325 words, keeping 110092 word types\n",
      "2017-04-21 21:06:29,813 : INFO : PROGRESS: at sentence #620000, processed 13864650 words, keeping 110837 word types\n",
      "2017-04-21 21:06:29,878 : INFO : PROGRESS: at sentence #630000, processed 14088936 words, keeping 111610 word types\n",
      "2017-04-21 21:06:29,941 : INFO : PROGRESS: at sentence #640000, processed 14309719 words, keeping 112416 word types\n",
      "2017-04-21 21:06:30,006 : INFO : PROGRESS: at sentence #650000, processed 14535475 words, keeping 113196 word types\n",
      "2017-04-21 21:06:30,062 : INFO : PROGRESS: at sentence #660000, processed 14758265 words, keeping 113945 word types\n",
      "2017-04-21 21:06:30,123 : INFO : PROGRESS: at sentence #670000, processed 14981658 words, keeping 114643 word types\n",
      "2017-04-21 21:06:30,189 : INFO : PROGRESS: at sentence #680000, processed 15206490 words, keeping 115354 word types\n",
      "2017-04-21 21:06:30,254 : INFO : PROGRESS: at sentence #690000, processed 15428683 words, keeping 116131 word types\n",
      "2017-04-21 21:06:30,320 : INFO : PROGRESS: at sentence #700000, processed 15657389 words, keeping 116943 word types\n",
      "2017-04-21 21:06:30,379 : INFO : PROGRESS: at sentence #710000, processed 15880378 words, keeping 117596 word types\n",
      "2017-04-21 21:06:30,443 : INFO : PROGRESS: at sentence #720000, processed 16105665 words, keeping 118221 word types\n",
      "2017-04-21 21:06:30,506 : INFO : PROGRESS: at sentence #730000, processed 16332046 words, keeping 118954 word types\n",
      "2017-04-21 21:06:30,569 : INFO : PROGRESS: at sentence #740000, processed 16553079 words, keeping 119668 word types\n",
      "2017-04-21 21:06:30,630 : INFO : PROGRESS: at sentence #750000, processed 16771406 words, keeping 120295 word types\n",
      "2017-04-21 21:06:30,691 : INFO : PROGRESS: at sentence #760000, processed 16990810 words, keeping 120930 word types\n",
      "2017-04-21 21:06:30,755 : INFO : PROGRESS: at sentence #770000, processed 17217947 words, keeping 121703 word types\n",
      "2017-04-21 21:06:30,823 : INFO : PROGRESS: at sentence #780000, processed 17448093 words, keeping 122402 word types\n",
      "2017-04-21 21:06:30,882 : INFO : PROGRESS: at sentence #790000, processed 17675169 words, keeping 123066 word types\n",
      "2017-04-21 21:06:30,920 : INFO : collected 123504 word types from a corpus of 17798270 raw words and 795538 sentences\n",
      "2017-04-21 21:06:30,921 : INFO : Loading a fresh vocabulary\n",
      "2017-04-21 21:06:31,030 : INFO : min_count=40 retains 16490 unique words (13% of original 123504, drops 107014)\n",
      "2017-04-21 21:06:31,031 : INFO : min_count=40 leaves 17239125 word corpus (96% of original 17798270, drops 559145)\n",
      "2017-04-21 21:06:31,081 : INFO : deleting the raw counts dictionary of 123504 items\n",
      "2017-04-21 21:06:31,088 : INFO : sample=0.001 downsamples 48 most-common words\n",
      "2017-04-21 21:06:31,089 : INFO : downsampling leaves estimated 12749798 word corpus (74.0% of prior 17239125)\n",
      "2017-04-21 21:06:31,090 : INFO : estimated required memory for 16490 words and 100 dimensions: 21437000 bytes\n",
      "2017-04-21 21:06:31,161 : INFO : resetting layer weights\n",
      "2017-04-21 21:06:31,348 : INFO : training model with 4 workers on 16490 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=5 window=5\n",
      "2017-04-21 21:06:32,362 : INFO : PROGRESS: at 2.00% examples, 1256359 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-21 21:06:33,363 : INFO : PROGRESS: at 4.03% examples, 1271467 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-21 21:06:34,364 : INFO : PROGRESS: at 6.03% examples, 1271256 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-21 21:06:35,371 : INFO : PROGRESS: at 8.08% examples, 1276695 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-21 21:06:36,379 : INFO : PROGRESS: at 10.10% examples, 1278204 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-21 21:06:37,383 : INFO : PROGRESS: at 12.10% examples, 1278675 words/s, in_qsize 6, out_qsize 1\n",
      "2017-04-21 21:06:38,393 : INFO : PROGRESS: at 14.12% examples, 1278007 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-21 21:06:39,394 : INFO : PROGRESS: at 16.15% examples, 1279916 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-21 21:06:40,403 : INFO : PROGRESS: at 18.14% examples, 1277923 words/s, in_qsize 6, out_qsize 1\n",
      "2017-04-21 21:06:41,406 : INFO : PROGRESS: at 20.17% examples, 1279103 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-21 21:06:42,411 : INFO : PROGRESS: at 22.19% examples, 1278644 words/s, in_qsize 6, out_qsize 1\n",
      "2017-04-21 21:06:43,418 : INFO : PROGRESS: at 24.24% examples, 1279178 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-21 21:06:44,432 : INFO : PROGRESS: at 26.28% examples, 1278837 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-21 21:06:45,435 : INFO : PROGRESS: at 28.31% examples, 1279676 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-21 21:06:46,436 : INFO : PROGRESS: at 30.31% examples, 1279674 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-21 21:06:47,439 : INFO : PROGRESS: at 32.31% examples, 1279862 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-21 21:06:48,443 : INFO : PROGRESS: at 34.32% examples, 1279969 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-21 21:06:49,446 : INFO : PROGRESS: at 36.34% examples, 1280178 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-21 21:06:50,448 : INFO : PROGRESS: at 38.34% examples, 1280103 words/s, in_qsize 6, out_qsize 1\n",
      "2017-04-21 21:06:51,450 : INFO : PROGRESS: at 40.33% examples, 1279583 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-21 21:06:52,454 : INFO : PROGRESS: at 42.35% examples, 1278979 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-21 21:06:53,460 : INFO : PROGRESS: at 44.37% examples, 1278751 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-21 21:06:54,469 : INFO : PROGRESS: at 46.42% examples, 1278899 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-21 21:06:55,469 : INFO : PROGRESS: at 48.42% examples, 1278878 words/s, in_qsize 6, out_qsize 1\n",
      "2017-04-21 21:06:56,474 : INFO : PROGRESS: at 50.43% examples, 1278987 words/s, in_qsize 6, out_qsize 1\n",
      "2017-04-21 21:06:57,483 : INFO : PROGRESS: at 52.44% examples, 1279119 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-21 21:06:58,490 : INFO : PROGRESS: at 54.46% examples, 1279358 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-21 21:06:59,496 : INFO : PROGRESS: at 56.51% examples, 1279869 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-21 21:07:00,498 : INFO : PROGRESS: at 58.51% examples, 1279789 words/s, in_qsize 6, out_qsize 1\n",
      "2017-04-21 21:07:01,501 : INFO : PROGRESS: at 60.52% examples, 1279879 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-21 21:07:02,504 : INFO : PROGRESS: at 62.57% examples, 1280221 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-21 21:07:03,507 : INFO : PROGRESS: at 64.59% examples, 1279907 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-21 21:07:04,510 : INFO : PROGRESS: at 66.61% examples, 1279739 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-21 21:07:05,517 : INFO : PROGRESS: at 68.58% examples, 1279089 words/s, in_qsize 6, out_qsize 1\n",
      "2017-04-21 21:07:06,518 : INFO : PROGRESS: at 70.57% examples, 1278678 words/s, in_qsize 6, out_qsize 1\n",
      "2017-04-21 21:07:07,523 : INFO : PROGRESS: at 72.44% examples, 1276529 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-21 21:07:08,524 : INFO : PROGRESS: at 74.36% examples, 1275270 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-21 21:07:09,538 : INFO : PROGRESS: at 76.37% examples, 1274901 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-21 21:07:10,548 : INFO : PROGRESS: at 78.38% examples, 1274924 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-21 21:07:11,556 : INFO : PROGRESS: at 80.40% examples, 1274927 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-21 21:07:12,559 : INFO : PROGRESS: at 82.41% examples, 1274795 words/s, in_qsize 6, out_qsize 1\n",
      "2017-04-21 21:07:13,562 : INFO : PROGRESS: at 84.46% examples, 1275175 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-21 21:07:14,566 : INFO : PROGRESS: at 86.50% examples, 1275486 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-21 21:07:15,569 : INFO : PROGRESS: at 88.52% examples, 1275689 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-21 21:07:16,571 : INFO : PROGRESS: at 90.51% examples, 1275569 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-21 21:07:17,578 : INFO : PROGRESS: at 92.50% examples, 1275452 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-21 21:07:18,580 : INFO : PROGRESS: at 94.51% examples, 1275659 words/s, in_qsize 6, out_qsize 1\n",
      "2017-04-21 21:07:19,581 : INFO : PROGRESS: at 96.53% examples, 1275871 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-21 21:07:20,583 : INFO : PROGRESS: at 98.52% examples, 1275767 words/s, in_qsize 6, out_qsize 1\n",
      "2017-04-21 21:07:21,295 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2017-04-21 21:07:21,296 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2017-04-21 21:07:21,301 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2017-04-21 21:07:21,305 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2017-04-21 21:07:21,306 : INFO : training on 88991350 raw words (63750104 effective words) took 50.0s, 1276193 effective words/s\n",
      "2017-04-21 21:07:21,324 : INFO : precomputing L2-norms of word weight vectors\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Set values for various parameters\n",
    "num_features = 100    # Word vector dimensionality                      \n",
    "min_word_count = 40   # Minimum word count                        \n",
    "num_workers = 4       # Number of threads to run in parallel\n",
    "context = 5          # Context window size                                                                                    \n",
    "downsampling = 1e-3   # Downsample setting for frequent words\n",
    "\n",
    "# Initialize and train the model (this will take some time)\n",
    "from gensim.models import word2vec\n",
    "print (\"Training model...\")\n",
    "model = word2vec.Word2Vec(sentences, workers=num_workers, \\\n",
    "            size=num_features, min_count = min_word_count, \\\n",
    "            window = context, sample = downsampling)\n",
    "\n",
    "# If you don't plan to train the model any further, calling \n",
    "# init_sims will make the model much more memory-efficient.\n",
    "model.init_sims(replace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Part b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-04-21 21:07:21,426 : INFO : loading projection weights from /Users/anuragroy/Downloads/GoogleNews-vectors-negative300.bin\n",
      "2017-04-21 21:08:16,758 : INFO : loaded (3000000, 300) matrix from /Users/anuragroy/Downloads/GoogleNews-vectors-negative300.bin\n"
     ]
    }
   ],
   "source": [
    "# Load Google's pre-trained Word2Vec model.\n",
    "import gensim\n",
    "google_model = gensim.models.KeyedVectors.load_word2vec_format('/Users/anuragroy/Downloads/GoogleNews-vectors-negative300.bin', \\\n",
    "                                                               binary=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "google_dict = dict(zip(google_model.index2word,range(len(google_model.index2word))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Part c)\n",
    "\n",
    "Creating set Z1, and clustering into 10 segments:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken for K Means clustering (Z1):  3.520582914352417 seconds.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "import time\n",
    "\n",
    "start = time.time() # Start time\n",
    " \n",
    "Z1 = model.wv.syn0\n",
    "num_clusters = 10  \n",
    "\n",
    "# Initalize a k-means object and use it to extract centroids\n",
    "kmeans_clustering = KMeans( n_clusters = num_clusters )\n",
    "idx = kmeans_clustering.fit_predict(Z1)\n",
    "\n",
    "# Get the end time and print how long the process took\n",
    "end = time.time()\n",
    "elapsed = end - start\n",
    "print (\"Time taken for K Means clustering (Z1): \", elapsed, \"seconds.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "word_centroid_map = dict(zip( model.wv.index2word, idx ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Sample of 20 words from each cluster:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Cluster: 1 \n",
      "\n",
      "['armageddon', 'norris', 'puppet', 'franchise', 'candyman', 'bullshit', 'yikes', 'marple', 'indy', 'penultimate', 'foremost', 'ingmar', 'serial', 'chan', 'dutch', 'maestro', 'pales', 'midnight', 'swashbuckler', 'swashbuckling']\n",
      "\n",
      "Cluster: 2 \n",
      "\n",
      "['suburb', 'aboard', 'mutants', 'union', 'warp', 'rendezvous', 'detectives', 'voodoo', 'continental', 'houses', 'fools', 'oil', 'championship', 'lab', 'areas', 'crust', 'petrified', 'thieves', 'pow', 'jewels']\n",
      "\n",
      "Cluster: 3 \n",
      "\n",
      "['corn', 'um', 'bait', 'chunks', 'cursing', 'throats', 'spiders', 'calendar', 'drill', 'hefty', 'eggs', 'grinning', 'hangs', 'boob', 'thrown', 'screeching', 'vent', 'flashes', 'grocery', 'yelled']\n",
      "\n",
      "Cluster: 4 \n",
      "\n",
      "['aspects', 'integrity', 'avoiding', 'persistent', 'destruction', 'symbol', 'baggage', 'relations', 'budgetary', 'principle', 'continuing', 'layers', 'rampant', 'observations', 'expansion', 'abduction', 'anger', 'profession', 'human', 'advantage']\n",
      "\n",
      "Cluster: 5 \n",
      "\n",
      "['wow', 'funniest', 'entire', 'independent', 'benefit', 'easily', 'english', 'so', 'didn', 'wish', 'criticism', 'concept', 'hard', 'yourselves', 'conceivable', 'collection', 'mins', 'promise', 'handedly', 'warning']\n",
      "\n",
      "Cluster: 6 \n",
      "\n",
      "['taller', 'unfaithful', 'pesky', 'southerner', 'femme', 'parent', 'servant', 'baron', 'magician', 'scottish', 'pammy', 'ranger', 'boyhood', 'malicious', 'kisses', 'ruthless', 'replacement', 'prophet', 'sailor', 'mat']\n",
      "\n",
      "Cluster: 7 \n",
      "\n",
      "['clarkson', 'alan', 'pang', 'stalwart', 'lombard', 'stack', 'wally', 'branagh', 'burt', 'vonnegut', 'rogers', 'lou', 'nielsen', 'borgnine', 'patty', 'shelly', 'witherspoon', 'pedro', 'otto', 'toto']\n",
      "\n",
      "Cluster: 8 \n",
      "\n",
      "['comfortable', 'meticulously', 'accurate', 'intriguing', 'suspenseful', 'implausible', 'ridden', 'distinctly', 'insane', 'coaster', 'fabricated', 'unintentionally', 'generic', 'lousy', 'layered', 'appealing', 'placement', 'bogus', 'realist', 'acted']\n",
      "\n",
      "Cluster: 9 \n",
      "\n",
      "['consist', 'compose', 'remember', 'imply', 'ferrell', 'seek', 'relating', 'help', 'lure', 'feel', 'pose', 'stick', 'disagree', 'gladly', 'love', 'raise', 'relive', 'adjust', 'ruin', 'build']\n",
      "\n",
      "Cluster: 10 \n",
      "\n",
      "['concentrating', 'removes', 'annoyed', 'bothered', 'considered', 'enhanced', 'reported', 'endured', 'perfected', 'invites', 'hunted', 'afloat', 'failed', 'uses', 'rejected', 'witnessing', 'declared', 'perceived', 'cured', 'phoned']\n"
     ]
    }
   ],
   "source": [
    "for clust in range(10):\n",
    "    print (\"\\nCluster:\", clust+1, \"\\n\")\n",
    "    word_list = [key for key, val in word_centroid_map.items() if val == clust][:20]\n",
    "    print (word_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def create_bag_of_centroids( wordlist, word_centroid_map ):\n",
    "    #\n",
    "    # The number of clusters is equal to the highest cluster index\n",
    "    # in the word / centroid map\n",
    "    num_centroids = max( word_centroid_map.values() ) + 1\n",
    "    #\n",
    "    # Pre-allocate the bag of centroids vector (for speed)\n",
    "    bag_of_centroids = np.zeros( num_centroids, dtype=\"float32\" )\n",
    "    #\n",
    "    # Loop over the words in the review. If the word is in the vocabulary,\n",
    "    # find which cluster it belongs to, and increment that cluster count \n",
    "    # by one\n",
    "    for word in wordlist:\n",
    "        if word in word_centroid_map:\n",
    "            index = word_centroid_map[word]\n",
    "            bag_of_centroids[index] += 1\n",
    "    #\n",
    "    # Return the \"bag of centroids\"\n",
    "    return bag_of_centroids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# ****************************************************************\n",
    "# Calculate average feature vectors for training and testing sets,\n",
    "# using the functions we defined above. Notice that we now use stop word\n",
    "# removal.\n",
    "\n",
    "clean_train_reviews = []\n",
    "for review in train[\"review\"]:\n",
    "    clean_train_reviews.append( review_to_wordlist( review, \\\n",
    "        remove_stopwords=True ))\n",
    "    \n",
    "clean_test_reviews = []\n",
    "for review in test[\"review\"]:\n",
    "    clean_test_reviews.append( review_to_wordlist( review, \\\n",
    "        remove_stopwords=True ))    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### Creating design matrices X1 and X1_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# Pre-allocate an array for the training set bags of centroids (for speed)\n",
    "X1  = np.zeros( (train[\"review\"].size, num_clusters), \\\n",
    "    dtype=\"float32\" )\n",
    "\n",
    "# Transform the training set reviews into bags of centroids\n",
    "counter = 0\n",
    "for review in clean_train_reviews:\n",
    "    X1[counter] = create_bag_of_centroids( review, \\\n",
    "        word_centroid_map )\n",
    "    counter += 1\n",
    "\n",
    "# Repeat for test reviews \n",
    "X1_test = np.zeros(( test[\"review\"].size, num_clusters), \\\n",
    "    dtype=\"float32\" )\n",
    "\n",
    "counter = 0\n",
    "for review in clean_test_reviews:\n",
    "    X1_test[counter] = create_bag_of_centroids( review, \\\n",
    "        word_centroid_map )\n",
    "    counter += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### To create set Z2, we will first subset Google's pretrained model to include only the terms in the word_centroid_map in the interest of speed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "google_dict2 = defaultdict()\n",
    "for key in word_centroid_map.keys():\n",
    "    try:\n",
    "        google_dict2[key] = google_dict[key]\n",
    "    except KeyError:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken for K Means clustering:  9.9491708278656 seconds.\n"
     ]
    }
   ],
   "source": [
    "start = time.time() # Start time\n",
    " \n",
    "Z2 = google_model.syn0[list(google_dict2.values())]\n",
    "num_clusters = 10\n",
    "\n",
    "# Initalize a k-means object and use it to extract centroids\n",
    "kmeans_clustering2 = KMeans( n_clusters = num_clusters )\n",
    "idx2 = kmeans_clustering2.fit_predict( Z2 )\n",
    "\n",
    "# Get the end time and print how long the process took\n",
    "end = time.time()\n",
    "elapsed = end - start\n",
    "print (\"Time taken for K Means clustering: \", elapsed, \"seconds.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "word_centroid_map2 = dict(zip(list(google_dict2.keys()), idx2 ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Sample of 20 words from each cluster:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Cluster: 1 \n",
      "\n",
      "['meticulously', 'suspenseful', 'layered', 'femme', 'maestro', 'swashbuckler', 'comic', 'swashbuckling', 'lovemaking', 'artistically', 'documentaries', 'story', 'edited', 'jazzy', 'themes', 'scriptwriting', 'dialog', 'animator', 'extravaganza', 'scriptwriter']\n",
      "\n",
      "Cluster: 2 \n",
      "\n",
      "['integrity', 'destruction', 'baggage', 'relations', 'criticism', 'realist', 'principle', 'observations', 'handedly', 'anger', 'profession', 'voice', 'human', 'feel', 'fullest', 'downfall', 'allies', 'credentials', 'difficulties', 'boredom']\n",
      "\n",
      "Cluster: 3 \n",
      "\n",
      "['removes', 'hangs', 'pales', 'invites', 'uses', 'resides', 'feeds', 'rises', 'elevates', 'recovers', 'strives', 'tends', 'draws', 'disturbs', 'dominates', 'steals', 'prefers', 'concludes', 'crosses', 'refuses']\n",
      "\n",
      "Cluster: 4 \n",
      "\n",
      "['concentrating', 'stalwart', 'ridden', 'aboard', 'avoiding', 'fabricated', 'bothered', 'didn', 'remember', 'endured', 'perfected', 'penultimate', 'spaced', 'serving', 'acted', 'midnight', 'kept', 'thrown', 'nominated', 'hunted']\n",
      "\n",
      "Cluster: 5 \n",
      "\n",
      "['corn', 'stack', 'coaster', 'paste', 'warp', 'bait', 'lures', 'chunks', 'throats', 'spiders', 'patty', 'dictionary', 'layers', 'oil', 'indoors', 'crust', 'sentinel', 'kisses', 'daphne', 'jewels']\n",
      "\n",
      "Cluster: 6 \n",
      "\n",
      "['aspects', 'drilling', 'entire', 'accurate', 'independent', 'lombard', 'persistent', 'consist', 'benefit', 'franchise', 'generic', 'considered', 'enhanced', 'calculated', 'placement', 'reported', 'so', 'wish', 'calendar', 'concept']\n",
      "\n",
      "Cluster: 7 \n",
      "\n",
      "['alan', 'pang', 'um', 'wally', 'norris', 'je', 'burt', 'rogers', 'english', 'selena', 'wong', 'lou', 'shelly', 'indy', 'otto', 'rea', 'chan', 'toto', 'dutch', 'roberts']\n",
      "\n",
      "Cluster: 8 \n",
      "\n",
      "['suburb', 'union', 'southerner', 'rendezvous', 'detectives', 'baron', 'magician', 'unemployed', 'entertainer', 'abduction', 'ranger', 'oldman', 'boyhood', 'thieves', 'monument', 'letterman', 'prophet', 'sailor', 'excursion', 'operative']\n",
      "\n",
      "Cluster: 9 \n",
      "\n",
      "['wow', 'funniest', 'armageddon', 'thugs', 'insane', 'nutty', 'unfaithful', 'mutants', 'puppet', 'pesky', 'candyman', 'bullshit', 'yourselves', 'voodoo', 'grinning', 'typecast', 'fools', 'boob', 'screeching', 'terminator']\n",
      "\n",
      "Cluster: 10 \n",
      "\n",
      "['comfortable', 'intriguing', 'implausible', 'boggling', 'annoyed', 'unintentionally', 'lousy', 'appealing', 'hard', 'conceivable', 'underplayed', 'meager', 'rampant', 'arbitrary', 'callous', 'insipid', 'suddenly', 'differently', 'simpler', 'malicious']\n"
     ]
    }
   ],
   "source": [
    "for clust in range(10):\n",
    "    print (\"\\nCluster:\", clust+1, \"\\n\")\n",
    "    word_list = [key for key, val in word_centroid_map2.items() if val == clust][:20]\n",
    "    print (word_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### Creating design matrices X2 and X2_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Pre-allocate an array for the training set bags of centroids (for speed)\n",
    "X2 = np.zeros( (train[\"review\"].size, num_clusters), \\\n",
    "    dtype=\"float32\" )\n",
    "\n",
    "# Transform the training set reviews into bags of centroids\n",
    "counter = 0\n",
    "for review in clean_train_reviews:\n",
    "    X2[counter] = create_bag_of_centroids( review, \\\n",
    "        word_centroid_map2 )\n",
    "    counter += 1\n",
    "\n",
    "# Repeat for test reviews \n",
    "X2_test = np.zeros(( test[\"review\"].size, num_clusters), \\\n",
    "    dtype=\"float32\" )\n",
    "\n",
    "counter = 0\n",
    "for review in clean_test_reviews:\n",
    "    X2_test[counter] = create_bag_of_centroids( review, \\\n",
    "        word_centroid_map2 )\n",
    "    counter += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Question 2\n",
    "\n",
    "## Part a) \n",
    "\n",
    "LDA model with ntopics = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Building a cleaned list of training reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "clean_train_reviews_2 = []\n",
    "for review in train[\"review\"]:\n",
    "    clean_train_reviews_2.append( review_to_wordlist( review, \\\n",
    "        remove_stopwords=True ))\n",
    "       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Building a cleaned list of test reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "clean_test_reviews_2 = []\n",
    "for review in test[\"review\"]:\n",
    "    clean_test_reviews_2.append( review_to_wordlist( review, \\\n",
    "        remove_stopwords=True ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "To convert the training data into vectors, we will represent each review by its unique id with the help of a gensim dictionary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-04-21 21:56:07,161 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2017-04-21 21:56:08,723 : INFO : adding document #10000 to Dictionary(51374 unique tokens: ['squirts', 'sculptured', 'londoner', 'midriffs', 'isabove']...)\n",
      "2017-04-21 21:56:10,238 : INFO : adding document #20000 to Dictionary(67660 unique tokens: ['squirts', 'sculptured', 'londoner', 'midriffs', 'isabove']...)\n",
      "2017-04-21 21:56:10,996 : INFO : built Dictionary(74065 unique tokens: ['squirts', 'sculptured', 'londoner', 'midriffs', 'isabove']...) from 25000 documents (total 2988089 corpus positions)\n"
     ]
    }
   ],
   "source": [
    "dict_lda = gensim.corpora.Dictionary(clean_train_reviews_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Using the dictionary above, we create a corpus using doc2bow() to find occurrences of each word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "corpus_lda = [dict_lda.doc2bow(words) for words in clean_train_reviews_2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "corpus_lda_test = [dict_lda.doc2bow(words) for words in clean_test_reviews_2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-04-20 03:13:38,250 : INFO : storing corpus in Matrix Market format to corpus_lda.mm\n",
      "2017-04-20 03:13:38,252 : INFO : saving sparse matrix to corpus_lda.mm\n",
      "2017-04-20 03:13:38,253 : INFO : PROGRESS: saving document #0\n",
      "2017-04-20 03:13:38,489 : INFO : PROGRESS: saving document #1000\n",
      "2017-04-20 03:13:38,663 : INFO : PROGRESS: saving document #2000\n",
      "2017-04-20 03:13:38,832 : INFO : PROGRESS: saving document #3000\n",
      "2017-04-20 03:13:39,000 : INFO : PROGRESS: saving document #4000\n",
      "2017-04-20 03:13:39,163 : INFO : PROGRESS: saving document #5000\n",
      "2017-04-20 03:13:39,323 : INFO : PROGRESS: saving document #6000\n",
      "2017-04-20 03:13:39,475 : INFO : PROGRESS: saving document #7000\n",
      "2017-04-20 03:13:39,630 : INFO : PROGRESS: saving document #8000\n",
      "2017-04-20 03:13:39,801 : INFO : PROGRESS: saving document #9000\n",
      "2017-04-20 03:13:39,979 : INFO : PROGRESS: saving document #10000\n",
      "2017-04-20 03:13:40,173 : INFO : PROGRESS: saving document #11000\n",
      "2017-04-20 03:13:40,343 : INFO : PROGRESS: saving document #12000\n",
      "2017-04-20 03:13:40,516 : INFO : PROGRESS: saving document #13000\n",
      "2017-04-20 03:13:40,690 : INFO : PROGRESS: saving document #14000\n",
      "2017-04-20 03:13:40,840 : INFO : PROGRESS: saving document #15000\n",
      "2017-04-20 03:13:40,995 : INFO : PROGRESS: saving document #16000\n",
      "2017-04-20 03:13:41,145 : INFO : PROGRESS: saving document #17000\n",
      "2017-04-20 03:13:41,324 : INFO : PROGRESS: saving document #18000\n",
      "2017-04-20 03:13:41,490 : INFO : PROGRESS: saving document #19000\n",
      "2017-04-20 03:13:41,681 : INFO : PROGRESS: saving document #20000\n",
      "2017-04-20 03:13:41,902 : INFO : PROGRESS: saving document #21000\n",
      "2017-04-20 03:13:42,080 : INFO : PROGRESS: saving document #22000\n",
      "2017-04-20 03:13:42,245 : INFO : PROGRESS: saving document #23000\n",
      "2017-04-20 03:13:42,443 : INFO : PROGRESS: saving document #24000\n",
      "2017-04-20 03:13:42,595 : INFO : saved 25000x74065 matrix, density=0.132% (2450404/1851625000)\n",
      "2017-04-20 03:13:42,597 : INFO : saving MmCorpus index to corpus_lda.mm.index\n"
     ]
    }
   ],
   "source": [
    "gensim.corpora.MmCorpus.serialize('corpus_lda.mm', corpus_lda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-04-21 12:45:57,606 : INFO : storing corpus in Matrix Market format to corpus_lda_test.mm\n",
      "2017-04-21 12:45:57,625 : INFO : saving sparse matrix to corpus_lda_test.mm\n",
      "2017-04-21 12:45:57,628 : INFO : PROGRESS: saving document #0\n",
      "2017-04-21 12:45:57,793 : INFO : PROGRESS: saving document #1000\n",
      "2017-04-21 12:45:57,942 : INFO : PROGRESS: saving document #2000\n",
      "2017-04-21 12:45:58,088 : INFO : PROGRESS: saving document #3000\n",
      "2017-04-21 12:45:58,234 : INFO : PROGRESS: saving document #4000\n",
      "2017-04-21 12:45:58,393 : INFO : PROGRESS: saving document #5000\n",
      "2017-04-21 12:45:58,549 : INFO : PROGRESS: saving document #6000\n",
      "2017-04-21 12:45:58,703 : INFO : PROGRESS: saving document #7000\n",
      "2017-04-21 12:45:58,854 : INFO : PROGRESS: saving document #8000\n",
      "2017-04-21 12:45:59,003 : INFO : PROGRESS: saving document #9000\n",
      "2017-04-21 12:45:59,158 : INFO : PROGRESS: saving document #10000\n",
      "2017-04-21 12:45:59,311 : INFO : PROGRESS: saving document #11000\n",
      "2017-04-21 12:45:59,466 : INFO : PROGRESS: saving document #12000\n",
      "2017-04-21 12:45:59,629 : INFO : PROGRESS: saving document #13000\n",
      "2017-04-21 12:45:59,812 : INFO : PROGRESS: saving document #14000\n",
      "2017-04-21 12:45:59,977 : INFO : PROGRESS: saving document #15000\n",
      "2017-04-21 12:46:00,136 : INFO : PROGRESS: saving document #16000\n",
      "2017-04-21 12:46:00,324 : INFO : PROGRESS: saving document #17000\n",
      "2017-04-21 12:46:00,514 : INFO : PROGRESS: saving document #18000\n",
      "2017-04-21 12:46:00,736 : INFO : PROGRESS: saving document #19000\n",
      "2017-04-21 12:46:00,922 : INFO : PROGRESS: saving document #20000\n",
      "2017-04-21 12:46:01,116 : INFO : PROGRESS: saving document #21000\n",
      "2017-04-21 12:46:01,293 : INFO : PROGRESS: saving document #22000\n",
      "2017-04-21 12:46:01,483 : INFO : PROGRESS: saving document #23000\n",
      "2017-04-21 12:46:01,678 : INFO : PROGRESS: saving document #24000\n",
      "2017-04-21 12:46:01,856 : INFO : saved 25000x74065 matrix, density=0.127% (2356774/1851625000)\n",
      "2017-04-21 12:46:01,867 : INFO : saving MmCorpus index to corpus_lda_test.mm.index\n"
     ]
    }
   ],
   "source": [
    "gensim.corpora.MmCorpus.serialize('corpus_lda_test.mm', corpus_lda_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-04-20 03:13:42,610 : INFO : loaded corpus index from corpus_lda.mm.index\n",
      "2017-04-20 03:13:42,612 : INFO : initializing corpus reader from corpus_lda.mm\n",
      "2017-04-20 03:13:42,614 : INFO : accepted corpus with 25000 documents, 74065 features, 2450404 non-zero entries\n"
     ]
    }
   ],
   "source": [
    "mm = gensim.corpora.MmCorpus('corpus_lda.mm')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-04-21 12:46:20,847 : INFO : loaded corpus index from corpus_lda_test.mm.index\n",
      "2017-04-21 12:46:20,850 : INFO : initializing corpus reader from corpus_lda_test.mm\n",
      "2017-04-21 12:46:20,853 : INFO : accepted corpus with 25000 documents, 74065 features, 2356774 non-zero entries\n"
     ]
    }
   ],
   "source": [
    "mm_test = gensim.corpora.MmCorpus('corpus_lda_test.mm')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-04-23 00:00:20,920 : INFO : using symmetric alpha at 0.1\n",
      "2017-04-23 00:00:20,937 : INFO : using symmetric eta at 1.3501653952609195e-05\n",
      "2017-04-23 00:00:20,962 : INFO : using serial LDA version on this node\n",
      "2017-04-23 00:00:25,590 : INFO : running batch LDA training, 10 topics, 10 passes over the supplied corpus of 25000 documents, updating model once every 25000 documents, evaluating perplexity every 20000 documents, iterating 50x with a convergence threshold of 0.001000\n",
      "2017-04-23 00:00:26,459 : INFO : PROGRESS: pass 0, at document #2000/25000\n",
      "2017-04-23 00:00:30,975 : INFO : PROGRESS: pass 0, at document #4000/25000\n",
      "2017-04-23 00:00:34,987 : INFO : PROGRESS: pass 0, at document #6000/25000\n",
      "2017-04-23 00:00:39,017 : INFO : PROGRESS: pass 0, at document #8000/25000\n",
      "2017-04-23 00:00:43,050 : INFO : PROGRESS: pass 0, at document #10000/25000\n",
      "2017-04-23 00:00:47,540 : INFO : PROGRESS: pass 0, at document #12000/25000\n",
      "2017-04-23 00:00:51,412 : INFO : PROGRESS: pass 0, at document #14000/25000\n",
      "2017-04-23 00:00:55,198 : INFO : PROGRESS: pass 0, at document #16000/25000\n",
      "2017-04-23 00:00:58,953 : INFO : PROGRESS: pass 0, at document #18000/25000\n",
      "2017-04-23 00:01:19,918 : INFO : -12.133 per-word bound, 4492.8 perplexity estimate based on a held-out corpus of 2000 documents with 233362 words\n",
      "2017-04-23 00:01:19,919 : INFO : PROGRESS: pass 0, at document #20000/25000\n",
      "2017-04-23 00:01:23,714 : INFO : PROGRESS: pass 0, at document #22000/25000\n",
      "2017-04-23 00:01:27,470 : INFO : PROGRESS: pass 0, at document #24000/25000\n",
      "2017-04-23 00:01:42,330 : INFO : -12.139 per-word bound, 4509.4 perplexity estimate based on a held-out corpus of 1000 documents with 114852 words\n",
      "2017-04-23 00:01:42,331 : INFO : PROGRESS: pass 0, at document #25000/25000\n",
      "2017-04-23 00:01:45,617 : INFO : topic #0 (0.100): 0.014*\"movie\" + 0.012*\"film\" + 0.007*\"one\" + 0.006*\"time\" + 0.005*\"would\" + 0.005*\"like\" + 0.005*\"even\" + 0.005*\"good\" + 0.005*\"story\" + 0.004*\"get\"\n",
      "2017-04-23 00:01:45,620 : INFO : topic #6 (0.100): 0.019*\"film\" + 0.010*\"movie\" + 0.009*\"like\" + 0.007*\"one\" + 0.006*\"good\" + 0.005*\"really\" + 0.005*\"story\" + 0.005*\"time\" + 0.004*\"well\" + 0.004*\"bad\"\n",
      "2017-04-23 00:01:45,623 : INFO : topic #5 (0.100): 0.015*\"movie\" + 0.010*\"film\" + 0.008*\"one\" + 0.006*\"like\" + 0.005*\"time\" + 0.005*\"would\" + 0.004*\"see\" + 0.004*\"first\" + 0.004*\"people\" + 0.004*\"even\"\n",
      "2017-04-23 00:01:45,626 : INFO : topic #3 (0.100): 0.016*\"movie\" + 0.014*\"film\" + 0.014*\"one\" + 0.006*\"good\" + 0.006*\"like\" + 0.004*\"would\" + 0.004*\"even\" + 0.004*\"really\" + 0.004*\"well\" + 0.003*\"story\"\n",
      "2017-04-23 00:01:45,628 : INFO : topic #7 (0.100): 0.015*\"movie\" + 0.015*\"film\" + 0.008*\"like\" + 0.007*\"one\" + 0.005*\"really\" + 0.005*\"good\" + 0.005*\"even\" + 0.004*\"would\" + 0.004*\"story\" + 0.004*\"well\"\n",
      "2017-04-23 00:01:45,632 : INFO : topic diff=4.763481, rho=1.000000\n",
      "2017-04-23 00:01:46,152 : INFO : PROGRESS: pass 1, at document #2000/25000\n",
      "2017-04-23 00:01:49,825 : INFO : PROGRESS: pass 1, at document #4000/25000\n",
      "2017-04-23 00:01:53,442 : INFO : PROGRESS: pass 1, at document #6000/25000\n",
      "2017-04-23 00:01:57,021 : INFO : PROGRESS: pass 1, at document #8000/25000\n",
      "2017-04-23 00:02:00,626 : INFO : PROGRESS: pass 1, at document #10000/25000\n",
      "2017-04-23 00:02:04,264 : INFO : PROGRESS: pass 1, at document #12000/25000\n",
      "2017-04-23 00:02:07,856 : INFO : PROGRESS: pass 1, at document #14000/25000\n",
      "2017-04-23 00:02:11,476 : INFO : PROGRESS: pass 1, at document #16000/25000\n",
      "2017-04-23 00:02:15,051 : INFO : PROGRESS: pass 1, at document #18000/25000\n",
      "2017-04-23 00:02:29,814 : INFO : -8.821 per-word bound, 452.2 perplexity estimate based on a held-out corpus of 2000 documents with 233362 words\n",
      "2017-04-23 00:02:29,815 : INFO : PROGRESS: pass 1, at document #20000/25000\n",
      "2017-04-23 00:02:33,430 : INFO : PROGRESS: pass 1, at document #22000/25000\n",
      "2017-04-23 00:02:37,031 : INFO : PROGRESS: pass 1, at document #24000/25000\n",
      "2017-04-23 00:02:46,217 : INFO : -8.802 per-word bound, 446.5 perplexity estimate based on a held-out corpus of 1000 documents with 114852 words\n",
      "2017-04-23 00:02:46,218 : INFO : PROGRESS: pass 1, at document #25000/25000\n",
      "2017-04-23 00:02:49,080 : INFO : topic #9 (0.100): 0.019*\"movie\" + 0.013*\"film\" + 0.009*\"good\" + 0.008*\"like\" + 0.007*\"one\" + 0.004*\"really\" + 0.004*\"even\" + 0.004*\"story\" + 0.004*\"would\" + 0.004*\"characters\"\n",
      "2017-04-23 00:02:49,082 : INFO : topic #2 (0.100): 0.010*\"film\" + 0.008*\"movie\" + 0.007*\"one\" + 0.005*\"like\" + 0.004*\"really\" + 0.004*\"show\" + 0.004*\"even\" + 0.003*\"much\" + 0.003*\"first\" + 0.003*\"made\"\n",
      "2017-04-23 00:02:49,084 : INFO : topic #5 (0.100): 0.016*\"movie\" + 0.010*\"film\" + 0.008*\"one\" + 0.006*\"like\" + 0.005*\"time\" + 0.005*\"would\" + 0.004*\"first\" + 0.004*\"see\" + 0.004*\"people\" + 0.004*\"even\"\n",
      "2017-04-23 00:02:49,086 : INFO : topic #7 (0.100): 0.015*\"film\" + 0.015*\"movie\" + 0.008*\"like\" + 0.006*\"one\" + 0.005*\"really\" + 0.005*\"good\" + 0.005*\"even\" + 0.004*\"would\" + 0.004*\"story\" + 0.004*\"well\"\n",
      "2017-04-23 00:02:49,088 : INFO : topic #8 (0.100): 0.016*\"movie\" + 0.013*\"film\" + 0.009*\"one\" + 0.007*\"see\" + 0.007*\"like\" + 0.005*\"time\" + 0.005*\"well\" + 0.005*\"even\" + 0.005*\"story\" + 0.004*\"would\"\n",
      "2017-04-23 00:02:49,092 : INFO : topic diff=0.355874, rho=0.262613\n",
      "2017-04-23 00:02:49,605 : INFO : PROGRESS: pass 2, at document #2000/25000\n",
      "2017-04-23 00:02:53,195 : INFO : PROGRESS: pass 2, at document #4000/25000\n",
      "2017-04-23 00:02:56,742 : INFO : PROGRESS: pass 2, at document #6000/25000\n",
      "2017-04-23 00:03:00,277 : INFO : PROGRESS: pass 2, at document #8000/25000\n",
      "2017-04-23 00:03:03,825 : INFO : PROGRESS: pass 2, at document #10000/25000\n",
      "2017-04-23 00:03:07,436 : INFO : PROGRESS: pass 2, at document #12000/25000\n",
      "2017-04-23 00:03:10,992 : INFO : PROGRESS: pass 2, at document #14000/25000\n",
      "2017-04-23 00:03:14,522 : INFO : PROGRESS: pass 2, at document #16000/25000\n",
      "2017-04-23 00:03:18,111 : INFO : PROGRESS: pass 2, at document #18000/25000\n",
      "2017-04-23 00:03:32,800 : INFO : -8.784 per-word bound, 440.7 perplexity estimate based on a held-out corpus of 2000 documents with 233362 words\n",
      "2017-04-23 00:03:32,801 : INFO : PROGRESS: pass 2, at document #20000/25000\n",
      "2017-04-23 00:03:36,312 : INFO : PROGRESS: pass 2, at document #22000/25000\n",
      "2017-04-23 00:03:39,896 : INFO : PROGRESS: pass 2, at document #24000/25000\n",
      "2017-04-23 00:03:49,003 : INFO : -8.765 per-word bound, 435.1 perplexity estimate based on a held-out corpus of 1000 documents with 114852 words\n",
      "2017-04-23 00:03:49,004 : INFO : PROGRESS: pass 2, at document #25000/25000\n",
      "2017-04-23 00:03:51,771 : INFO : topic #3 (0.100): 0.016*\"movie\" + 0.014*\"film\" + 0.014*\"one\" + 0.006*\"good\" + 0.006*\"like\" + 0.004*\"would\" + 0.004*\"even\" + 0.004*\"well\" + 0.004*\"great\" + 0.003*\"really\"\n",
      "2017-04-23 00:03:51,773 : INFO : topic #8 (0.100): 0.016*\"movie\" + 0.013*\"film\" + 0.009*\"one\" + 0.007*\"like\" + 0.007*\"see\" + 0.005*\"time\" + 0.005*\"well\" + 0.005*\"even\" + 0.005*\"story\" + 0.005*\"would\"\n",
      "2017-04-23 00:03:51,774 : INFO : topic #9 (0.100): 0.019*\"movie\" + 0.013*\"film\" + 0.010*\"good\" + 0.008*\"like\" + 0.007*\"one\" + 0.005*\"really\" + 0.004*\"even\" + 0.004*\"story\" + 0.004*\"characters\" + 0.004*\"would\"\n",
      "2017-04-23 00:03:51,776 : INFO : topic #7 (0.100): 0.015*\"film\" + 0.015*\"movie\" + 0.008*\"like\" + 0.006*\"one\" + 0.005*\"really\" + 0.005*\"good\" + 0.005*\"even\" + 0.004*\"would\" + 0.004*\"story\" + 0.004*\"well\"\n",
      "2017-04-23 00:03:51,778 : INFO : topic #2 (0.100): 0.010*\"film\" + 0.007*\"movie\" + 0.007*\"one\" + 0.005*\"show\" + 0.004*\"like\" + 0.004*\"really\" + 0.004*\"even\" + 0.003*\"much\" + 0.003*\"first\" + 0.003*\"get\"\n",
      "2017-04-23 00:03:51,782 : INFO : topic diff=0.341428, rho=0.254000\n",
      "2017-04-23 00:03:52,295 : INFO : PROGRESS: pass 3, at document #2000/25000\n",
      "2017-04-23 00:03:55,817 : INFO : PROGRESS: pass 3, at document #4000/25000\n",
      "2017-04-23 00:03:59,341 : INFO : PROGRESS: pass 3, at document #6000/25000\n",
      "2017-04-23 00:04:02,833 : INFO : PROGRESS: pass 3, at document #8000/25000\n",
      "2017-04-23 00:04:06,359 : INFO : PROGRESS: pass 3, at document #10000/25000\n",
      "2017-04-23 00:04:09,869 : INFO : PROGRESS: pass 3, at document #12000/25000\n",
      "2017-04-23 00:04:13,382 : INFO : PROGRESS: pass 3, at document #14000/25000\n",
      "2017-04-23 00:04:16,901 : INFO : PROGRESS: pass 3, at document #16000/25000\n",
      "2017-04-23 00:04:20,362 : INFO : PROGRESS: pass 3, at document #18000/25000\n",
      "2017-04-23 00:12:52,835 : INFO : -8.754 per-word bound, 431.7 perplexity estimate based on a held-out corpus of 2000 documents with 233362 words\n",
      "2017-04-23 00:12:52,836 : INFO : PROGRESS: pass 3, at document #20000/25000\n",
      "2017-04-23 00:12:56,374 : INFO : PROGRESS: pass 3, at document #22000/25000\n",
      "2017-04-23 00:12:59,938 : INFO : PROGRESS: pass 3, at document #24000/25000\n",
      "2017-04-23 00:13:09,540 : INFO : -8.736 per-word bound, 426.2 perplexity estimate based on a held-out corpus of 1000 documents with 114852 words\n",
      "2017-04-23 00:13:09,541 : INFO : PROGRESS: pass 3, at document #25000/25000\n",
      "2017-04-23 00:13:12,480 : INFO : topic #4 (0.100): 0.010*\"film\" + 0.009*\"one\" + 0.006*\"like\" + 0.006*\"movie\" + 0.003*\"also\" + 0.003*\"time\" + 0.003*\"way\" + 0.003*\"even\" + 0.003*\"series\" + 0.003*\"much\"\n",
      "2017-04-23 00:13:12,482 : INFO : topic #5 (0.100): 0.017*\"movie\" + 0.009*\"film\" + 0.008*\"one\" + 0.007*\"like\" + 0.005*\"time\" + 0.005*\"would\" + 0.004*\"people\" + 0.004*\"see\" + 0.004*\"first\" + 0.004*\"even\"\n",
      "2017-04-23 00:13:12,483 : INFO : topic #9 (0.100): 0.020*\"movie\" + 0.012*\"film\" + 0.010*\"good\" + 0.009*\"like\" + 0.007*\"one\" + 0.005*\"really\" + 0.004*\"even\" + 0.004*\"story\" + 0.004*\"characters\" + 0.004*\"would\"\n",
      "2017-04-23 00:13:12,485 : INFO : topic #3 (0.100): 0.015*\"movie\" + 0.014*\"film\" + 0.014*\"one\" + 0.006*\"good\" + 0.006*\"like\" + 0.004*\"would\" + 0.004*\"even\" + 0.004*\"great\" + 0.004*\"well\" + 0.003*\"story\"\n",
      "2017-04-23 00:13:12,487 : INFO : topic #6 (0.100): 0.021*\"film\" + 0.008*\"movie\" + 0.008*\"like\" + 0.007*\"one\" + 0.006*\"good\" + 0.005*\"story\" + 0.005*\"really\" + 0.004*\"time\" + 0.004*\"well\" + 0.004*\"great\"\n",
      "2017-04-23 00:13:12,490 : INFO : topic diff=0.319231, rho=0.246183\n",
      "2017-04-23 00:13:13,048 : INFO : PROGRESS: pass 4, at document #2000/25000\n",
      "2017-04-23 00:13:16,968 : INFO : PROGRESS: pass 4, at document #4000/25000\n",
      "2017-04-23 00:13:20,690 : INFO : PROGRESS: pass 4, at document #6000/25000\n",
      "2017-04-23 00:13:24,743 : INFO : PROGRESS: pass 4, at document #8000/25000\n",
      "2017-04-23 00:13:28,598 : INFO : PROGRESS: pass 4, at document #10000/25000\n",
      "2017-04-23 00:13:32,534 : INFO : PROGRESS: pass 4, at document #12000/25000\n",
      "2017-04-23 00:13:36,308 : INFO : PROGRESS: pass 4, at document #14000/25000\n",
      "2017-04-23 00:13:40,236 : INFO : PROGRESS: pass 4, at document #16000/25000\n",
      "2017-04-23 00:13:44,133 : INFO : PROGRESS: pass 4, at document #18000/25000\n",
      "2017-04-23 00:13:59,751 : INFO : -8.731 per-word bound, 424.8 perplexity estimate based on a held-out corpus of 2000 documents with 233362 words\n",
      "2017-04-23 00:13:59,752 : INFO : PROGRESS: pass 4, at document #20000/25000\n",
      "2017-04-23 00:14:03,412 : INFO : PROGRESS: pass 4, at document #22000/25000\n",
      "2017-04-23 00:14:07,112 : INFO : PROGRESS: pass 4, at document #24000/25000\n",
      "2017-04-23 00:14:16,532 : INFO : -8.713 per-word bound, 419.6 perplexity estimate based on a held-out corpus of 1000 documents with 114852 words\n",
      "2017-04-23 00:14:16,533 : INFO : PROGRESS: pass 4, at document #25000/25000\n",
      "2017-04-23 00:14:19,480 : INFO : topic #4 (0.100): 0.010*\"film\" + 0.009*\"one\" + 0.006*\"like\" + 0.005*\"movie\" + 0.003*\"series\" + 0.003*\"also\" + 0.003*\"time\" + 0.003*\"way\" + 0.003*\"even\" + 0.003*\"people\"\n",
      "2017-04-23 00:14:19,482 : INFO : topic #9 (0.100): 0.020*\"movie\" + 0.012*\"film\" + 0.010*\"good\" + 0.009*\"like\" + 0.007*\"one\" + 0.005*\"really\" + 0.004*\"even\" + 0.004*\"story\" + 0.004*\"would\" + 0.004*\"characters\"\n",
      "2017-04-23 00:14:19,484 : INFO : topic #0 (0.100): 0.013*\"film\" + 0.011*\"movie\" + 0.007*\"one\" + 0.005*\"time\" + 0.005*\"would\" + 0.005*\"like\" + 0.005*\"story\" + 0.004*\"even\" + 0.004*\"good\" + 0.003*\"also\"\n",
      "2017-04-23 00:14:19,486 : INFO : topic #3 (0.100): 0.015*\"movie\" + 0.014*\"film\" + 0.014*\"one\" + 0.006*\"good\" + 0.006*\"like\" + 0.004*\"would\" + 0.004*\"even\" + 0.004*\"great\" + 0.004*\"well\" + 0.003*\"story\"\n",
      "2017-04-23 00:14:19,488 : INFO : topic #6 (0.100): 0.021*\"film\" + 0.008*\"movie\" + 0.007*\"like\" + 0.007*\"one\" + 0.006*\"good\" + 0.005*\"story\" + 0.005*\"really\" + 0.004*\"time\" + 0.004*\"well\" + 0.004*\"great\"\n",
      "2017-04-23 00:14:19,491 : INFO : topic diff=0.295560, rho=0.239046\n",
      "2017-04-23 00:14:20,012 : INFO : PROGRESS: pass 5, at document #2000/25000\n",
      "2017-04-23 00:14:23,664 : INFO : PROGRESS: pass 5, at document #4000/25000\n",
      "2017-04-23 00:14:27,378 : INFO : PROGRESS: pass 5, at document #6000/25000\n",
      "2017-04-23 00:14:41,254 : INFO : PROGRESS: pass 5, at document #8000/25000\n",
      "2017-04-23 00:14:44,971 : INFO : PROGRESS: pass 5, at document #10000/25000\n",
      "2017-04-23 00:14:48,626 : INFO : PROGRESS: pass 5, at document #12000/25000\n",
      "2017-04-23 00:14:52,300 : INFO : PROGRESS: pass 5, at document #14000/25000\n",
      "2017-04-23 00:14:55,902 : INFO : PROGRESS: pass 5, at document #16000/25000\n",
      "2017-04-23 00:14:59,556 : INFO : PROGRESS: pass 5, at document #18000/25000\n",
      "2017-04-23 00:15:15,263 : INFO : -8.712 per-word bound, 419.4 perplexity estimate based on a held-out corpus of 2000 documents with 233362 words\n",
      "2017-04-23 00:15:15,264 : INFO : PROGRESS: pass 5, at document #20000/25000\n",
      "2017-04-23 00:15:19,017 : INFO : PROGRESS: pass 5, at document #22000/25000\n",
      "2017-04-23 00:15:22,717 : INFO : PROGRESS: pass 5, at document #24000/25000\n",
      "2017-04-23 00:15:32,426 : INFO : -8.694 per-word bound, 414.3 perplexity estimate based on a held-out corpus of 1000 documents with 114852 words\n",
      "2017-04-23 00:15:32,427 : INFO : PROGRESS: pass 5, at document #25000/25000\n",
      "2017-04-23 00:15:35,355 : INFO : topic #1 (0.100): 0.025*\"movie\" + 0.009*\"one\" + 0.007*\"film\" + 0.006*\"bad\" + 0.005*\"good\" + 0.005*\"would\" + 0.005*\"like\" + 0.005*\"time\" + 0.005*\"movies\" + 0.004*\"way\"\n",
      "2017-04-23 00:15:35,357 : INFO : topic #5 (0.100): 0.018*\"movie\" + 0.009*\"one\" + 0.008*\"film\" + 0.007*\"like\" + 0.005*\"time\" + 0.005*\"would\" + 0.005*\"even\" + 0.005*\"people\" + 0.004*\"see\" + 0.004*\"first\"\n",
      "2017-04-23 00:15:35,359 : INFO : topic #3 (0.100): 0.015*\"movie\" + 0.015*\"film\" + 0.014*\"one\" + 0.006*\"good\" + 0.006*\"like\" + 0.004*\"would\" + 0.004*\"even\" + 0.004*\"great\" + 0.004*\"well\" + 0.003*\"story\"\n",
      "2017-04-23 00:15:35,361 : INFO : topic #4 (0.100): 0.010*\"film\" + 0.009*\"one\" + 0.006*\"like\" + 0.005*\"movie\" + 0.004*\"series\" + 0.003*\"also\" + 0.003*\"time\" + 0.003*\"even\" + 0.003*\"people\" + 0.003*\"way\"\n",
      "2017-04-23 00:15:35,363 : INFO : topic #9 (0.100): 0.020*\"movie\" + 0.012*\"film\" + 0.011*\"good\" + 0.009*\"like\" + 0.007*\"one\" + 0.005*\"really\" + 0.004*\"story\" + 0.004*\"even\" + 0.004*\"see\" + 0.004*\"would\"\n",
      "2017-04-23 00:15:35,366 : INFO : topic diff=0.271841, rho=0.232495\n",
      "2017-04-23 00:15:35,888 : INFO : PROGRESS: pass 6, at document #2000/25000\n",
      "2017-04-23 00:15:39,634 : INFO : PROGRESS: pass 6, at document #4000/25000\n",
      "2017-04-23 00:15:43,318 : INFO : PROGRESS: pass 6, at document #6000/25000\n",
      "2017-04-23 00:15:47,123 : INFO : PROGRESS: pass 6, at document #8000/25000\n",
      "2017-04-23 00:15:50,890 : INFO : PROGRESS: pass 6, at document #10000/25000\n",
      "2017-04-23 00:15:54,526 : INFO : PROGRESS: pass 6, at document #12000/25000\n",
      "2017-04-23 00:15:58,068 : INFO : PROGRESS: pass 6, at document #14000/25000\n",
      "2017-04-23 00:16:02,006 : INFO : PROGRESS: pass 6, at document #16000/25000\n",
      "2017-04-23 00:16:05,737 : INFO : PROGRESS: pass 6, at document #18000/25000\n",
      "2017-04-23 00:16:21,189 : INFO : -8.697 per-word bound, 415.0 perplexity estimate based on a held-out corpus of 2000 documents with 233362 words\n",
      "2017-04-23 00:16:21,191 : INFO : PROGRESS: pass 6, at document #20000/25000\n",
      "2017-04-23 00:16:24,922 : INFO : PROGRESS: pass 6, at document #22000/25000\n",
      "2017-04-23 00:16:28,853 : INFO : PROGRESS: pass 6, at document #24000/25000\n",
      "2017-04-23 00:16:38,197 : INFO : -8.679 per-word bound, 409.9 perplexity estimate based on a held-out corpus of 1000 documents with 114852 words\n",
      "2017-04-23 00:16:38,198 : INFO : PROGRESS: pass 6, at document #25000/25000\n",
      "2017-04-23 00:16:41,230 : INFO : topic #8 (0.100): 0.017*\"movie\" + 0.014*\"film\" + 0.009*\"one\" + 0.007*\"like\" + 0.007*\"see\" + 0.005*\"time\" + 0.005*\"story\" + 0.005*\"well\" + 0.005*\"would\" + 0.005*\"even\"\n",
      "2017-04-23 00:16:41,232 : INFO : topic #0 (0.100): 0.013*\"film\" + 0.010*\"movie\" + 0.007*\"one\" + 0.005*\"time\" + 0.005*\"story\" + 0.005*\"would\" + 0.005*\"like\" + 0.004*\"even\" + 0.004*\"good\" + 0.003*\"also\"\n",
      "2017-04-23 00:16:41,234 : INFO : topic #2 (0.100): 0.008*\"film\" + 0.007*\"one\" + 0.005*\"movie\" + 0.005*\"show\" + 0.004*\"like\" + 0.003*\"really\" + 0.003*\"best\" + 0.003*\"two\" + 0.003*\"even\" + 0.003*\"get\"\n",
      "2017-04-23 00:16:41,235 : INFO : topic #3 (0.100): 0.015*\"film\" + 0.014*\"movie\" + 0.014*\"one\" + 0.006*\"good\" + 0.006*\"like\" + 0.004*\"would\" + 0.004*\"great\" + 0.004*\"even\" + 0.004*\"well\" + 0.003*\"story\"\n",
      "2017-04-23 00:16:41,237 : INFO : topic #7 (0.100): 0.016*\"film\" + 0.014*\"movie\" + 0.008*\"like\" + 0.007*\"one\" + 0.005*\"really\" + 0.005*\"good\" + 0.005*\"even\" + 0.005*\"story\" + 0.004*\"would\" + 0.004*\"well\"\n",
      "2017-04-23 00:16:41,241 : INFO : topic diff=0.248484, rho=0.226455\n",
      "2017-04-23 00:16:41,762 : INFO : PROGRESS: pass 7, at document #2000/25000\n",
      "2017-04-23 00:16:45,364 : INFO : PROGRESS: pass 7, at document #4000/25000\n",
      "2017-04-23 00:16:48,977 : INFO : PROGRESS: pass 7, at document #6000/25000\n",
      "2017-04-23 00:16:52,518 : INFO : PROGRESS: pass 7, at document #8000/25000\n",
      "2017-04-23 00:16:56,127 : INFO : PROGRESS: pass 7, at document #10000/25000\n",
      "2017-04-23 00:16:59,777 : INFO : PROGRESS: pass 7, at document #12000/25000\n",
      "2017-04-23 00:17:03,356 : INFO : PROGRESS: pass 7, at document #14000/25000\n",
      "2017-04-23 00:17:06,957 : INFO : PROGRESS: pass 7, at document #16000/25000\n",
      "2017-04-23 00:17:10,514 : INFO : PROGRESS: pass 7, at document #18000/25000\n",
      "2017-04-23 00:17:25,478 : INFO : -8.684 per-word bound, 411.4 perplexity estimate based on a held-out corpus of 2000 documents with 233362 words\n",
      "2017-04-23 00:17:25,479 : INFO : PROGRESS: pass 7, at document #20000/25000\n",
      "2017-04-23 00:17:29,020 : INFO : PROGRESS: pass 7, at document #22000/25000\n",
      "2017-04-23 00:17:32,570 : INFO : PROGRESS: pass 7, at document #24000/25000\n",
      "2017-04-23 00:17:42,564 : INFO : -8.666 per-word bound, 406.3 perplexity estimate based on a held-out corpus of 1000 documents with 114852 words\n",
      "2017-04-23 00:17:42,565 : INFO : PROGRESS: pass 7, at document #25000/25000\n",
      "2017-04-23 00:17:46,037 : INFO : topic #8 (0.100): 0.017*\"movie\" + 0.014*\"film\" + 0.009*\"one\" + 0.007*\"like\" + 0.007*\"see\" + 0.005*\"time\" + 0.005*\"story\" + 0.005*\"well\" + 0.005*\"would\" + 0.005*\"really\"\n",
      "2017-04-23 00:17:46,039 : INFO : topic #1 (0.100): 0.027*\"movie\" + 0.009*\"one\" + 0.007*\"bad\" + 0.007*\"film\" + 0.006*\"good\" + 0.005*\"like\" + 0.005*\"would\" + 0.005*\"movies\" + 0.005*\"time\" + 0.004*\"even\"\n",
      "2017-04-23 00:17:46,041 : INFO : topic #0 (0.100): 0.013*\"film\" + 0.010*\"movie\" + 0.007*\"one\" + 0.005*\"time\" + 0.005*\"story\" + 0.004*\"would\" + 0.004*\"like\" + 0.004*\"even\" + 0.004*\"good\" + 0.003*\"also\"\n",
      "2017-04-23 00:17:46,043 : INFO : topic #7 (0.100): 0.016*\"film\" + 0.013*\"movie\" + 0.008*\"like\" + 0.007*\"one\" + 0.005*\"really\" + 0.005*\"good\" + 0.005*\"even\" + 0.005*\"story\" + 0.004*\"would\" + 0.004*\"well\"\n",
      "2017-04-23 00:17:46,045 : INFO : topic #2 (0.100): 0.008*\"film\" + 0.007*\"one\" + 0.005*\"movie\" + 0.005*\"show\" + 0.004*\"like\" + 0.003*\"best\" + 0.003*\"two\" + 0.003*\"really\" + 0.003*\"get\" + 0.003*\"even\"\n",
      "2017-04-23 00:17:46,049 : INFO : topic diff=0.225799, rho=0.220863\n",
      "2017-04-23 00:17:46,635 : INFO : PROGRESS: pass 8, at document #2000/25000\n",
      "2017-04-23 00:17:50,593 : INFO : PROGRESS: pass 8, at document #4000/25000\n",
      "2017-04-23 00:17:54,420 : INFO : PROGRESS: pass 8, at document #6000/25000\n",
      "2017-04-23 00:17:57,992 : INFO : PROGRESS: pass 8, at document #8000/25000\n",
      "2017-04-23 00:18:01,831 : INFO : PROGRESS: pass 8, at document #10000/25000\n",
      "2017-04-23 00:18:05,758 : INFO : PROGRESS: pass 8, at document #12000/25000\n",
      "2017-04-23 00:18:09,675 : INFO : PROGRESS: pass 8, at document #14000/25000\n",
      "2017-04-23 00:18:13,638 : INFO : PROGRESS: pass 8, at document #16000/25000\n",
      "2017-04-23 00:18:17,538 : INFO : PROGRESS: pass 8, at document #18000/25000\n",
      "2017-04-23 00:18:33,005 : INFO : -8.674 per-word bound, 408.4 perplexity estimate based on a held-out corpus of 2000 documents with 233362 words\n",
      "2017-04-23 00:18:33,006 : INFO : PROGRESS: pass 8, at document #20000/25000\n",
      "2017-04-23 00:18:36,575 : INFO : PROGRESS: pass 8, at document #22000/25000\n",
      "2017-04-23 00:18:40,163 : INFO : PROGRESS: pass 8, at document #24000/25000\n",
      "2017-04-23 00:18:49,543 : INFO : -8.656 per-word bound, 403.4 perplexity estimate based on a held-out corpus of 1000 documents with 114852 words\n",
      "2017-04-23 00:18:49,544 : INFO : PROGRESS: pass 8, at document #25000/25000\n",
      "2017-04-23 00:18:52,789 : INFO : topic #0 (0.100): 0.013*\"film\" + 0.009*\"movie\" + 0.007*\"one\" + 0.005*\"time\" + 0.004*\"story\" + 0.004*\"would\" + 0.004*\"like\" + 0.004*\"even\" + 0.003*\"good\" + 0.003*\"also\"\n",
      "2017-04-23 00:18:52,791 : INFO : topic #1 (0.100): 0.028*\"movie\" + 0.009*\"one\" + 0.007*\"bad\" + 0.006*\"film\" + 0.006*\"good\" + 0.006*\"like\" + 0.005*\"would\" + 0.005*\"movies\" + 0.005*\"time\" + 0.004*\"even\"\n",
      "2017-04-23 00:18:52,793 : INFO : topic #5 (0.100): 0.020*\"movie\" + 0.009*\"one\" + 0.008*\"film\" + 0.008*\"like\" + 0.005*\"time\" + 0.005*\"even\" + 0.005*\"bad\" + 0.005*\"would\" + 0.005*\"people\" + 0.005*\"see\"\n",
      "2017-04-23 00:18:52,795 : INFO : topic #7 (0.100): 0.017*\"film\" + 0.013*\"movie\" + 0.008*\"like\" + 0.007*\"one\" + 0.005*\"really\" + 0.005*\"good\" + 0.005*\"even\" + 0.005*\"story\" + 0.004*\"would\" + 0.004*\"well\"\n",
      "2017-04-23 00:18:52,797 : INFO : topic #8 (0.100): 0.017*\"movie\" + 0.015*\"film\" + 0.009*\"one\" + 0.007*\"like\" + 0.007*\"see\" + 0.005*\"time\" + 0.005*\"story\" + 0.005*\"well\" + 0.005*\"would\" + 0.005*\"really\"\n",
      "2017-04-23 00:18:52,801 : INFO : topic diff=0.204335, rho=0.215666\n",
      "2017-04-23 00:18:53,322 : INFO : PROGRESS: pass 9, at document #2000/25000\n",
      "2017-04-23 00:18:56,901 : INFO : PROGRESS: pass 9, at document #4000/25000\n",
      "2017-04-23 00:19:00,657 : INFO : PROGRESS: pass 9, at document #6000/25000\n",
      "2017-04-23 00:19:04,234 : INFO : PROGRESS: pass 9, at document #8000/25000\n",
      "2017-04-23 00:19:07,801 : INFO : PROGRESS: pass 9, at document #10000/25000\n",
      "2017-04-23 00:19:11,386 : INFO : PROGRESS: pass 9, at document #12000/25000\n",
      "2017-04-23 00:19:14,933 : INFO : PROGRESS: pass 9, at document #14000/25000\n",
      "2017-04-23 00:19:18,505 : INFO : PROGRESS: pass 9, at document #16000/25000\n",
      "2017-04-23 00:19:22,087 : INFO : PROGRESS: pass 9, at document #18000/25000\n",
      "2017-04-23 00:19:37,227 : INFO : -8.665 per-word bound, 405.9 perplexity estimate based on a held-out corpus of 2000 documents with 233362 words\n",
      "2017-04-23 00:19:37,228 : INFO : PROGRESS: pass 9, at document #20000/25000\n",
      "2017-04-23 00:19:40,866 : INFO : PROGRESS: pass 9, at document #22000/25000\n",
      "2017-04-23 00:19:44,572 : INFO : PROGRESS: pass 9, at document #24000/25000\n",
      "2017-04-23 00:19:54,266 : INFO : -8.647 per-word bound, 400.8 perplexity estimate based on a held-out corpus of 1000 documents with 114852 words\n",
      "2017-04-23 00:19:54,267 : INFO : PROGRESS: pass 9, at document #25000/25000\n",
      "2017-04-23 00:19:57,431 : INFO : topic #9 (0.100): 0.021*\"movie\" + 0.012*\"film\" + 0.011*\"good\" + 0.009*\"like\" + 0.007*\"one\" + 0.005*\"really\" + 0.005*\"story\" + 0.004*\"even\" + 0.004*\"see\" + 0.003*\"would\"\n",
      "2017-04-23 00:19:57,433 : INFO : topic #2 (0.100): 0.008*\"film\" + 0.007*\"one\" + 0.005*\"show\" + 0.004*\"movie\" + 0.004*\"like\" + 0.003*\"two\" + 0.003*\"best\" + 0.003*\"man\" + 0.003*\"get\" + 0.003*\"life\"\n",
      "2017-04-23 00:19:57,435 : INFO : topic #6 (0.100): 0.021*\"film\" + 0.007*\"one\" + 0.006*\"like\" + 0.006*\"movie\" + 0.005*\"story\" + 0.005*\"good\" + 0.004*\"well\" + 0.004*\"really\" + 0.004*\"time\" + 0.004*\"great\"\n",
      "2017-04-23 00:19:57,437 : INFO : topic #0 (0.100): 0.013*\"film\" + 0.009*\"movie\" + 0.007*\"one\" + 0.005*\"time\" + 0.004*\"story\" + 0.004*\"would\" + 0.004*\"like\" + 0.004*\"even\" + 0.003*\"good\" + 0.003*\"also\"\n",
      "2017-04-23 00:19:57,439 : INFO : topic #4 (0.100): 0.009*\"film\" + 0.009*\"one\" + 0.006*\"like\" + 0.004*\"series\" + 0.004*\"movie\" + 0.003*\"also\" + 0.003*\"time\" + 0.003*\"show\" + 0.003*\"many\" + 0.003*\"people\"\n",
      "2017-04-23 00:19:57,442 : INFO : topic diff=0.184268, rho=0.210819\n"
     ]
    }
   ],
   "source": [
    "lda = gensim.models.ldamodel.LdaModel(corpus=mm, id2word=dict_lda, num_topics=10, update_every=0, passes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X3_trfcorp = lda.get_document_topics(corpus_lda, minimum_probability = 0) #creating a transformed corpus object containing tuples with topic probabilities\n",
    "X3 = np.zeros((25000,10)) #initializing a 2d version of the corpus object retaining only the probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#populating X3 by extracting probabilities from the tuples\n",
    "for i ,j in enumerate(X3_trfcorp):\n",
    "    probs = [item[1] for item in X3_trfcorp[i]]\n",
    "    X3[i] = probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#repeating above procedure for the test data (while reusing the LDA model)\n",
    "X3_test_trfcorp = lda.get_document_topics(corpus_lda_test, minimum_probability = 0) \n",
    "X3_test = np.zeros((25000,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i ,j in enumerate(X3_test_trfcorp):\n",
    "    probs = [item[1] for item in X3_test_trfcorp[i]]\n",
    "    X3_test[i] = probs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Part b\n",
    "\n",
    "\n",
    "ntopics = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-04-23 00:56:16,800 : INFO : using symmetric alpha at 0.05\n",
      "2017-04-23 00:56:16,802 : INFO : using symmetric eta at 1.3501653952609195e-05\n",
      "2017-04-23 00:56:16,827 : INFO : using serial LDA version on this node\n",
      "2017-04-23 00:56:26,057 : INFO : running batch LDA training, 20 topics, 10 passes over the supplied corpus of 25000 documents, updating model once every 25000 documents, evaluating perplexity every 20000 documents, iterating 50x with a convergence threshold of 0.001000\n",
      "2017-04-23 00:56:26,566 : INFO : PROGRESS: pass 0, at document #2000/25000\n",
      "2017-04-23 00:56:31,200 : INFO : PROGRESS: pass 0, at document #4000/25000\n",
      "2017-04-23 00:56:35,846 : INFO : PROGRESS: pass 0, at document #6000/25000\n",
      "2017-04-23 00:56:40,509 : INFO : PROGRESS: pass 0, at document #8000/25000\n",
      "2017-04-23 00:56:45,102 : INFO : PROGRESS: pass 0, at document #10000/25000\n",
      "2017-04-23 00:56:49,696 : INFO : PROGRESS: pass 0, at document #12000/25000\n",
      "2017-04-23 00:56:54,316 : INFO : PROGRESS: pass 0, at document #14000/25000\n",
      "2017-04-23 00:56:58,900 : INFO : PROGRESS: pass 0, at document #16000/25000\n",
      "2017-04-23 00:57:03,553 : INFO : PROGRESS: pass 0, at document #18000/25000\n",
      "2017-04-23 00:57:31,880 : INFO : -12.765 per-word bound, 6959.0 perplexity estimate based on a held-out corpus of 2000 documents with 233362 words\n",
      "2017-04-23 00:57:31,881 : INFO : PROGRESS: pass 0, at document #20000/25000\n",
      "2017-04-23 00:57:36,853 : INFO : PROGRESS: pass 0, at document #22000/25000\n",
      "2017-04-23 00:57:42,059 : INFO : PROGRESS: pass 0, at document #24000/25000\n",
      "2017-04-23 00:58:04,357 : INFO : -12.780 per-word bound, 7032.6 perplexity estimate based on a held-out corpus of 1000 documents with 114852 words\n",
      "2017-04-23 00:58:04,358 : INFO : PROGRESS: pass 0, at document #25000/25000\n",
      "2017-04-23 00:58:08,443 : INFO : topic #1 (0.050): 0.016*\"film\" + 0.012*\"one\" + 0.011*\"movie\" + 0.010*\"like\" + 0.006*\"time\" + 0.005*\"story\" + 0.005*\"even\" + 0.005*\"much\" + 0.004*\"well\" + 0.004*\"bad\"\n",
      "2017-04-23 00:58:08,445 : INFO : topic #8 (0.050): 0.015*\"movie\" + 0.013*\"film\" + 0.006*\"like\" + 0.005*\"one\" + 0.005*\"great\" + 0.005*\"see\" + 0.005*\"get\" + 0.004*\"would\" + 0.004*\"really\" + 0.004*\"time\"\n",
      "2017-04-23 00:58:08,447 : INFO : topic #15 (0.050): 0.013*\"movie\" + 0.011*\"one\" + 0.008*\"film\" + 0.007*\"good\" + 0.006*\"like\" + 0.005*\"show\" + 0.005*\"would\" + 0.004*\"time\" + 0.004*\"see\" + 0.004*\"character\"\n",
      "2017-04-23 00:58:08,449 : INFO : topic #14 (0.050): 0.016*\"film\" + 0.007*\"movie\" + 0.006*\"one\" + 0.005*\"would\" + 0.004*\"like\" + 0.004*\"see\" + 0.004*\"people\" + 0.004*\"really\" + 0.004*\"made\" + 0.004*\"time\"\n",
      "2017-04-23 00:58:08,451 : INFO : topic #19 (0.050): 0.017*\"movie\" + 0.012*\"film\" + 0.007*\"one\" + 0.006*\"story\" + 0.005*\"like\" + 0.005*\"even\" + 0.004*\"time\" + 0.004*\"good\" + 0.004*\"bad\" + 0.004*\"see\"\n",
      "2017-04-23 00:58:08,460 : INFO : topic diff=9.712132, rho=1.000000\n",
      "2017-04-23 00:58:08,993 : INFO : PROGRESS: pass 1, at document #2000/25000\n",
      "2017-04-23 00:58:13,343 : INFO : PROGRESS: pass 1, at document #4000/25000\n",
      "2017-04-23 00:58:17,725 : INFO : PROGRESS: pass 1, at document #6000/25000\n",
      "2017-04-23 00:58:22,410 : INFO : PROGRESS: pass 1, at document #8000/25000\n",
      "2017-04-23 00:58:26,762 : INFO : PROGRESS: pass 1, at document #10000/25000\n",
      "2017-04-23 00:58:31,441 : INFO : PROGRESS: pass 1, at document #12000/25000\n",
      "2017-04-23 00:58:36,020 : INFO : PROGRESS: pass 1, at document #14000/25000\n",
      "2017-04-23 00:58:40,462 : INFO : PROGRESS: pass 1, at document #16000/25000\n",
      "2017-04-23 00:58:45,036 : INFO : PROGRESS: pass 1, at document #18000/25000\n",
      "2017-04-23 00:59:02,976 : INFO : -9.032 per-word bound, 523.4 perplexity estimate based on a held-out corpus of 2000 documents with 233362 words\n",
      "2017-04-23 00:59:02,977 : INFO : PROGRESS: pass 1, at document #20000/25000\n",
      "2017-04-23 00:59:07,327 : INFO : PROGRESS: pass 1, at document #22000/25000\n",
      "2017-04-23 00:59:11,627 : INFO : PROGRESS: pass 1, at document #24000/25000\n",
      "2017-04-23 00:59:22,256 : INFO : -9.017 per-word bound, 518.0 perplexity estimate based on a held-out corpus of 1000 documents with 114852 words\n",
      "2017-04-23 00:59:22,257 : INFO : PROGRESS: pass 1, at document #25000/25000\n",
      "2017-04-23 00:59:26,062 : INFO : topic #19 (0.050): 0.017*\"movie\" + 0.012*\"film\" + 0.007*\"one\" + 0.006*\"story\" + 0.005*\"like\" + 0.005*\"even\" + 0.004*\"time\" + 0.004*\"good\" + 0.004*\"bad\" + 0.004*\"see\"\n",
      "2017-04-23 00:59:26,064 : INFO : topic #9 (0.050): 0.016*\"movie\" + 0.014*\"film\" + 0.010*\"one\" + 0.007*\"like\" + 0.007*\"time\" + 0.005*\"really\" + 0.004*\"even\" + 0.004*\"story\" + 0.004*\"well\" + 0.003*\"great\"\n",
      "2017-04-23 00:59:26,066 : INFO : topic #16 (0.050): 0.017*\"film\" + 0.011*\"movie\" + 0.007*\"one\" + 0.006*\"like\" + 0.005*\"first\" + 0.005*\"much\" + 0.005*\"story\" + 0.004*\"even\" + 0.004*\"would\" + 0.004*\"bad\"\n",
      "2017-04-23 00:59:26,067 : INFO : topic #3 (0.050): 0.012*\"movie\" + 0.012*\"film\" + 0.009*\"one\" + 0.006*\"would\" + 0.006*\"time\" + 0.005*\"like\" + 0.005*\"also\" + 0.005*\"well\" + 0.004*\"people\" + 0.004*\"good\"\n",
      "2017-04-23 00:59:26,069 : INFO : topic #1 (0.050): 0.016*\"film\" + 0.012*\"one\" + 0.011*\"movie\" + 0.010*\"like\" + 0.006*\"time\" + 0.005*\"even\" + 0.005*\"story\" + 0.005*\"much\" + 0.004*\"well\" + 0.004*\"bad\"\n",
      "2017-04-23 00:59:26,075 : INFO : topic diff=0.569035, rho=0.262613\n",
      "2017-04-23 00:59:26,615 : INFO : PROGRESS: pass 2, at document #2000/25000\n",
      "2017-04-23 00:59:30,858 : INFO : PROGRESS: pass 2, at document #4000/25000\n",
      "2017-04-23 00:59:35,027 : INFO : PROGRESS: pass 2, at document #6000/25000\n",
      "2017-04-23 00:59:39,167 : INFO : PROGRESS: pass 2, at document #8000/25000\n",
      "2017-04-23 00:59:43,347 : INFO : PROGRESS: pass 2, at document #10000/25000\n",
      "2017-04-23 00:59:47,576 : INFO : PROGRESS: pass 2, at document #12000/25000\n",
      "2017-04-23 00:59:51,759 : INFO : PROGRESS: pass 2, at document #14000/25000\n",
      "2017-04-23 00:59:55,937 : INFO : PROGRESS: pass 2, at document #16000/25000\n",
      "2017-04-23 01:00:00,125 : INFO : PROGRESS: pass 2, at document #18000/25000\n",
      "2017-04-23 01:00:16,578 : INFO : -8.966 per-word bound, 500.2 perplexity estimate based on a held-out corpus of 2000 documents with 233362 words\n",
      "2017-04-23 01:00:16,579 : INFO : PROGRESS: pass 2, at document #20000/25000\n",
      "2017-04-23 01:00:20,795 : INFO : PROGRESS: pass 2, at document #22000/25000\n",
      "2017-04-23 01:00:24,948 : INFO : PROGRESS: pass 2, at document #24000/25000\n",
      "2017-04-23 01:00:35,433 : INFO : -8.950 per-word bound, 494.4 perplexity estimate based on a held-out corpus of 1000 documents with 114852 words\n",
      "2017-04-23 01:00:35,434 : INFO : PROGRESS: pass 2, at document #25000/25000\n",
      "2017-04-23 01:00:39,120 : INFO : topic #1 (0.050): 0.016*\"film\" + 0.012*\"one\" + 0.010*\"movie\" + 0.010*\"like\" + 0.006*\"time\" + 0.005*\"even\" + 0.005*\"story\" + 0.004*\"much\" + 0.004*\"well\" + 0.004*\"bad\"\n",
      "2017-04-23 01:00:39,122 : INFO : topic #5 (0.050): 0.020*\"film\" + 0.009*\"one\" + 0.007*\"good\" + 0.005*\"movie\" + 0.004*\"like\" + 0.004*\"even\" + 0.004*\"would\" + 0.004*\"bad\" + 0.004*\"could\" + 0.004*\"see\"\n",
      "2017-04-23 01:00:39,124 : INFO : topic #16 (0.050): 0.018*\"film\" + 0.011*\"movie\" + 0.007*\"one\" + 0.006*\"like\" + 0.005*\"first\" + 0.005*\"much\" + 0.005*\"story\" + 0.004*\"even\" + 0.004*\"would\" + 0.004*\"see\"\n",
      "2017-04-23 01:00:39,126 : INFO : topic #3 (0.050): 0.012*\"film\" + 0.012*\"movie\" + 0.009*\"one\" + 0.005*\"would\" + 0.005*\"time\" + 0.005*\"like\" + 0.005*\"also\" + 0.004*\"well\" + 0.004*\"people\" + 0.004*\"good\"\n",
      "2017-04-23 01:00:39,128 : INFO : topic #7 (0.050): 0.013*\"movie\" + 0.012*\"one\" + 0.008*\"like\" + 0.007*\"really\" + 0.007*\"good\" + 0.006*\"film\" + 0.005*\"even\" + 0.005*\"would\" + 0.005*\"bad\" + 0.004*\"made\"\n",
      "2017-04-23 01:00:39,134 : INFO : topic diff=0.555797, rho=0.254000\n",
      "2017-04-23 01:00:39,655 : INFO : PROGRESS: pass 3, at document #2000/25000\n",
      "2017-04-23 01:00:43,789 : INFO : PROGRESS: pass 3, at document #4000/25000\n",
      "2017-04-23 01:00:47,912 : INFO : PROGRESS: pass 3, at document #6000/25000\n",
      "2017-04-23 01:00:52,066 : INFO : PROGRESS: pass 3, at document #8000/25000\n",
      "2017-04-23 01:00:56,344 : INFO : PROGRESS: pass 3, at document #10000/25000\n",
      "2017-04-23 01:01:00,521 : INFO : PROGRESS: pass 3, at document #12000/25000\n",
      "2017-04-23 01:01:04,803 : INFO : PROGRESS: pass 3, at document #14000/25000\n",
      "2017-04-23 01:01:09,240 : INFO : PROGRESS: pass 3, at document #16000/25000\n",
      "2017-04-23 01:01:13,705 : INFO : PROGRESS: pass 3, at document #18000/25000\n",
      "2017-04-23 01:01:30,446 : INFO : -8.916 per-word bound, 483.0 perplexity estimate based on a held-out corpus of 2000 documents with 233362 words\n",
      "2017-04-23 01:01:30,447 : INFO : PROGRESS: pass 3, at document #20000/25000\n",
      "2017-04-23 01:01:34,524 : INFO : PROGRESS: pass 3, at document #22000/25000\n",
      "2017-04-23 01:01:38,707 : INFO : PROGRESS: pass 3, at document #24000/25000\n",
      "2017-04-23 01:01:49,084 : INFO : -8.898 per-word bound, 477.2 perplexity estimate based on a held-out corpus of 1000 documents with 114852 words\n",
      "2017-04-23 01:01:49,085 : INFO : PROGRESS: pass 3, at document #25000/25000\n",
      "2017-04-23 01:01:52,659 : INFO : topic #14 (0.050): 0.015*\"film\" + 0.006*\"movie\" + 0.006*\"would\" + 0.005*\"one\" + 0.005*\"people\" + 0.004*\"see\" + 0.004*\"like\" + 0.004*\"made\" + 0.004*\"time\" + 0.003*\"really\"\n",
      "2017-04-23 01:01:52,661 : INFO : topic #9 (0.050): 0.016*\"movie\" + 0.013*\"film\" + 0.010*\"one\" + 0.007*\"like\" + 0.007*\"time\" + 0.005*\"really\" + 0.004*\"even\" + 0.004*\"story\" + 0.004*\"well\" + 0.003*\"great\"\n",
      "2017-04-23 01:01:52,662 : INFO : topic #4 (0.050): 0.017*\"movie\" + 0.009*\"one\" + 0.006*\"bad\" + 0.006*\"like\" + 0.004*\"even\" + 0.004*\"film\" + 0.004*\"think\" + 0.004*\"would\" + 0.004*\"could\" + 0.004*\"well\"\n",
      "2017-04-23 01:01:52,664 : INFO : topic #5 (0.050): 0.020*\"film\" + 0.009*\"one\" + 0.007*\"good\" + 0.005*\"movie\" + 0.004*\"even\" + 0.004*\"like\" + 0.004*\"would\" + 0.004*\"bad\" + 0.004*\"could\" + 0.004*\"see\"\n",
      "2017-04-23 01:01:52,666 : INFO : topic #2 (0.050): 0.013*\"film\" + 0.011*\"movie\" + 0.007*\"one\" + 0.006*\"like\" + 0.005*\"love\" + 0.004*\"good\" + 0.004*\"really\" + 0.004*\"also\" + 0.004*\"well\" + 0.004*\"story\"\n",
      "2017-04-23 01:01:52,672 : INFO : topic diff=0.536129, rho=0.246183\n",
      "2017-04-23 01:01:53,192 : INFO : PROGRESS: pass 4, at document #2000/25000\n",
      "2017-04-23 01:01:57,278 : INFO : PROGRESS: pass 4, at document #4000/25000\n",
      "2017-04-23 01:02:01,403 : INFO : PROGRESS: pass 4, at document #6000/25000\n",
      "2017-04-23 01:02:05,484 : INFO : PROGRESS: pass 4, at document #8000/25000\n",
      "2017-04-23 01:02:09,623 : INFO : PROGRESS: pass 4, at document #10000/25000\n",
      "2017-04-23 01:02:13,785 : INFO : PROGRESS: pass 4, at document #12000/25000\n",
      "2017-04-23 01:02:17,848 : INFO : PROGRESS: pass 4, at document #14000/25000\n",
      "2017-04-23 01:02:21,943 : INFO : PROGRESS: pass 4, at document #16000/25000\n",
      "2017-04-23 01:02:26,066 : INFO : PROGRESS: pass 4, at document #18000/25000\n",
      "2017-04-23 01:02:42,708 : INFO : -8.876 per-word bound, 469.8 perplexity estimate based on a held-out corpus of 2000 documents with 233362 words\n",
      "2017-04-23 01:02:42,709 : INFO : PROGRESS: pass 4, at document #20000/25000\n",
      "2017-04-23 01:02:46,807 : INFO : PROGRESS: pass 4, at document #22000/25000\n",
      "2017-04-23 01:02:50,870 : INFO : PROGRESS: pass 4, at document #24000/25000\n",
      "2017-04-23 01:03:01,716 : INFO : -8.858 per-word bound, 463.9 perplexity estimate based on a held-out corpus of 1000 documents with 114852 words\n",
      "2017-04-23 01:03:01,717 : INFO : PROGRESS: pass 4, at document #25000/25000\n",
      "2017-04-23 01:03:05,489 : INFO : topic #2 (0.050): 0.013*\"film\" + 0.010*\"movie\" + 0.007*\"one\" + 0.006*\"like\" + 0.005*\"love\" + 0.004*\"also\" + 0.004*\"well\" + 0.004*\"good\" + 0.004*\"story\" + 0.004*\"really\"\n",
      "2017-04-23 01:03:05,490 : INFO : topic #4 (0.050): 0.017*\"movie\" + 0.009*\"one\" + 0.006*\"bad\" + 0.006*\"like\" + 0.004*\"even\" + 0.004*\"film\" + 0.004*\"think\" + 0.004*\"would\" + 0.004*\"could\" + 0.004*\"well\"\n",
      "2017-04-23 01:03:05,492 : INFO : topic #3 (0.050): 0.012*\"film\" + 0.010*\"movie\" + 0.009*\"one\" + 0.005*\"time\" + 0.005*\"would\" + 0.005*\"like\" + 0.004*\"also\" + 0.004*\"well\" + 0.003*\"good\" + 0.003*\"people\"\n",
      "2017-04-23 01:03:05,494 : INFO : topic #1 (0.050): 0.016*\"film\" + 0.012*\"one\" + 0.010*\"like\" + 0.009*\"movie\" + 0.006*\"time\" + 0.005*\"even\" + 0.005*\"story\" + 0.004*\"much\" + 0.004*\"well\" + 0.004*\"way\"\n",
      "2017-04-23 01:03:05,495 : INFO : topic #5 (0.050): 0.021*\"film\" + 0.009*\"one\" + 0.007*\"good\" + 0.005*\"movie\" + 0.004*\"even\" + 0.004*\"like\" + 0.004*\"would\" + 0.004*\"could\" + 0.004*\"bad\" + 0.004*\"see\"\n",
      "2017-04-23 01:03:05,501 : INFO : topic diff=0.512522, rho=0.239046\n",
      "2017-04-23 01:03:06,093 : INFO : PROGRESS: pass 5, at document #2000/25000\n",
      "2017-04-23 01:03:10,441 : INFO : PROGRESS: pass 5, at document #4000/25000\n",
      "2017-04-23 01:03:14,789 : INFO : PROGRESS: pass 5, at document #6000/25000\n",
      "2017-04-23 01:03:19,177 : INFO : PROGRESS: pass 5, at document #8000/25000\n",
      "2017-04-23 01:03:23,687 : INFO : PROGRESS: pass 5, at document #10000/25000\n",
      "2017-04-23 01:03:27,969 : INFO : PROGRESS: pass 5, at document #12000/25000\n",
      "2017-04-23 01:03:32,302 : INFO : PROGRESS: pass 5, at document #14000/25000\n",
      "2017-04-23 01:03:36,454 : INFO : PROGRESS: pass 5, at document #16000/25000\n",
      "2017-04-23 01:03:40,508 : INFO : PROGRESS: pass 5, at document #18000/25000\n",
      "2017-04-23 01:03:56,772 : INFO : -8.843 per-word bound, 459.3 perplexity estimate based on a held-out corpus of 2000 documents with 233362 words\n",
      "2017-04-23 01:03:56,772 : INFO : PROGRESS: pass 5, at document #20000/25000\n",
      "2017-04-23 01:04:00,860 : INFO : PROGRESS: pass 5, at document #22000/25000\n",
      "2017-04-23 01:04:04,919 : INFO : PROGRESS: pass 5, at document #24000/25000\n",
      "2017-04-23 01:04:15,042 : INFO : -8.825 per-word bound, 453.6 perplexity estimate based on a held-out corpus of 1000 documents with 114852 words\n",
      "2017-04-23 01:04:15,043 : INFO : PROGRESS: pass 5, at document #25000/25000\n",
      "2017-04-23 01:04:18,633 : INFO : topic #0 (0.050): 0.013*\"film\" + 0.009*\"one\" + 0.008*\"movie\" + 0.005*\"also\" + 0.005*\"good\" + 0.005*\"well\" + 0.004*\"time\" + 0.004*\"like\" + 0.004*\"much\" + 0.004*\"see\"\n",
      "2017-04-23 01:04:18,635 : INFO : topic #12 (0.050): 0.023*\"movie\" + 0.010*\"one\" + 0.009*\"like\" + 0.007*\"good\" + 0.007*\"film\" + 0.006*\"would\" + 0.005*\"really\" + 0.005*\"movies\" + 0.005*\"even\" + 0.004*\"time\"\n",
      "2017-04-23 01:04:18,636 : INFO : topic #15 (0.050): 0.015*\"show\" + 0.011*\"one\" + 0.009*\"movie\" + 0.007*\"good\" + 0.006*\"like\" + 0.005*\"film\" + 0.005*\"would\" + 0.005*\"series\" + 0.005*\"time\" + 0.005*\"funny\"\n",
      "2017-04-23 01:04:18,640 : INFO : topic #6 (0.050): 0.009*\"film\" + 0.008*\"one\" + 0.006*\"movie\" + 0.005*\"story\" + 0.004*\"like\" + 0.004*\"time\" + 0.004*\"good\" + 0.003*\"also\" + 0.003*\"character\" + 0.003*\"best\"\n",
      "2017-04-23 01:04:18,642 : INFO : topic #13 (0.050): 0.014*\"film\" + 0.009*\"movie\" + 0.009*\"one\" + 0.008*\"like\" + 0.005*\"see\" + 0.004*\"good\" + 0.004*\"story\" + 0.004*\"people\" + 0.004*\"get\" + 0.003*\"even\"\n",
      "2017-04-23 01:04:18,650 : INFO : topic diff=0.485157, rho=0.232495\n",
      "2017-04-23 01:04:19,168 : INFO : PROGRESS: pass 6, at document #2000/25000\n",
      "2017-04-23 01:04:23,190 : INFO : PROGRESS: pass 6, at document #4000/25000\n",
      "2017-04-23 01:04:27,175 : INFO : PROGRESS: pass 6, at document #6000/25000\n",
      "2017-04-23 01:04:31,175 : INFO : PROGRESS: pass 6, at document #8000/25000\n",
      "2017-04-23 01:04:35,178 : INFO : PROGRESS: pass 6, at document #10000/25000\n",
      "2017-04-23 01:04:39,258 : INFO : PROGRESS: pass 6, at document #12000/25000\n",
      "2017-04-23 01:04:43,403 : INFO : PROGRESS: pass 6, at document #14000/25000\n",
      "2017-04-23 01:04:47,821 : INFO : PROGRESS: pass 6, at document #16000/25000\n",
      "2017-04-23 01:04:52,182 : INFO : PROGRESS: pass 6, at document #18000/25000\n",
      "2017-04-23 01:05:09,513 : INFO : -8.816 per-word bound, 450.8 perplexity estimate based on a held-out corpus of 2000 documents with 233362 words\n",
      "2017-04-23 01:05:09,514 : INFO : PROGRESS: pass 6, at document #20000/25000\n",
      "2017-04-23 01:05:13,968 : INFO : PROGRESS: pass 6, at document #22000/25000\n",
      "2017-04-23 01:05:18,156 : INFO : PROGRESS: pass 6, at document #24000/25000\n",
      "2017-04-23 01:05:28,278 : INFO : -8.798 per-word bound, 445.1 perplexity estimate based on a held-out corpus of 1000 documents with 114852 words\n",
      "2017-04-23 01:05:28,278 : INFO : PROGRESS: pass 6, at document #25000/25000\n",
      "2017-04-23 01:05:31,969 : INFO : topic #11 (0.050): 0.040*\"movie\" + 0.011*\"one\" + 0.009*\"film\" + 0.009*\"like\" + 0.008*\"good\" + 0.008*\"bad\" + 0.007*\"really\" + 0.006*\"would\" + 0.006*\"movies\" + 0.006*\"even\"\n",
      "2017-04-23 01:05:31,972 : INFO : topic #9 (0.050): 0.015*\"movie\" + 0.013*\"film\" + 0.010*\"one\" + 0.007*\"like\" + 0.007*\"time\" + 0.004*\"really\" + 0.004*\"even\" + 0.004*\"story\" + 0.004*\"well\" + 0.003*\"great\"\n",
      "2017-04-23 01:05:31,973 : INFO : topic #3 (0.050): 0.011*\"film\" + 0.009*\"movie\" + 0.008*\"one\" + 0.005*\"time\" + 0.005*\"would\" + 0.005*\"like\" + 0.004*\"also\" + 0.004*\"well\" + 0.003*\"good\" + 0.003*\"story\"\n",
      "2017-04-23 01:05:31,975 : INFO : topic #15 (0.050): 0.017*\"show\" + 0.011*\"one\" + 0.008*\"movie\" + 0.007*\"good\" + 0.006*\"like\" + 0.006*\"series\" + 0.005*\"would\" + 0.005*\"time\" + 0.005*\"film\" + 0.005*\"funny\"\n",
      "2017-04-23 01:05:31,977 : INFO : topic #1 (0.050): 0.017*\"film\" + 0.012*\"one\" + 0.009*\"like\" + 0.008*\"movie\" + 0.006*\"time\" + 0.005*\"even\" + 0.005*\"story\" + 0.004*\"much\" + 0.004*\"well\" + 0.004*\"way\"\n",
      "2017-04-23 01:05:31,983 : INFO : topic diff=0.454863, rho=0.226455\n",
      "2017-04-23 01:05:32,497 : INFO : PROGRESS: pass 7, at document #2000/25000\n",
      "2017-04-23 01:05:36,497 : INFO : PROGRESS: pass 7, at document #4000/25000\n",
      "2017-04-23 01:05:40,487 : INFO : PROGRESS: pass 7, at document #6000/25000\n",
      "2017-04-23 01:05:44,468 : INFO : PROGRESS: pass 7, at document #8000/25000\n",
      "2017-04-23 01:05:48,455 : INFO : PROGRESS: pass 7, at document #10000/25000\n",
      "2017-04-23 01:05:52,432 : INFO : PROGRESS: pass 7, at document #12000/25000\n",
      "2017-04-23 01:05:56,453 : INFO : PROGRESS: pass 7, at document #14000/25000\n",
      "2017-04-23 01:06:00,444 : INFO : PROGRESS: pass 7, at document #16000/25000\n",
      "2017-04-23 01:06:04,384 : INFO : PROGRESS: pass 7, at document #18000/25000\n",
      "2017-04-23 01:06:20,464 : INFO : -8.793 per-word bound, 443.7 perplexity estimate based on a held-out corpus of 2000 documents with 233362 words\n",
      "2017-04-23 01:06:20,464 : INFO : PROGRESS: pass 7, at document #20000/25000\n",
      "2017-04-23 01:06:24,726 : INFO : PROGRESS: pass 7, at document #22000/25000\n",
      "2017-04-23 01:06:28,996 : INFO : PROGRESS: pass 7, at document #24000/25000\n",
      "2017-04-23 01:06:39,342 : INFO : -8.776 per-word bound, 438.3 perplexity estimate based on a held-out corpus of 1000 documents with 114852 words\n",
      "2017-04-23 01:06:39,343 : INFO : PROGRESS: pass 7, at document #25000/25000\n",
      "2017-04-23 01:06:43,107 : INFO : topic #7 (0.050): 0.011*\"one\" + 0.011*\"movie\" + 0.008*\"like\" + 0.007*\"really\" + 0.007*\"good\" + 0.005*\"film\" + 0.005*\"even\" + 0.004*\"would\" + 0.004*\"see\" + 0.004*\"great\"\n",
      "2017-04-23 01:06:43,109 : INFO : topic #8 (0.050): 0.012*\"film\" + 0.011*\"movie\" + 0.006*\"like\" + 0.006*\"one\" + 0.005*\"great\" + 0.004*\"get\" + 0.004*\"see\" + 0.004*\"would\" + 0.004*\"time\" + 0.004*\"even\"\n",
      "2017-04-23 01:06:43,111 : INFO : topic #2 (0.050): 0.013*\"film\" + 0.009*\"movie\" + 0.007*\"one\" + 0.006*\"like\" + 0.005*\"love\" + 0.004*\"story\" + 0.004*\"well\" + 0.004*\"also\" + 0.004*\"good\" + 0.004*\"young\"\n",
      "2017-04-23 01:06:43,112 : INFO : topic #14 (0.050): 0.015*\"film\" + 0.005*\"would\" + 0.005*\"one\" + 0.005*\"people\" + 0.005*\"war\" + 0.005*\"movie\" + 0.004*\"world\" + 0.004*\"see\" + 0.004*\"like\" + 0.003*\"made\"\n",
      "2017-04-23 01:06:43,114 : INFO : topic #17 (0.050): 0.016*\"movie\" + 0.015*\"film\" + 0.007*\"one\" + 0.007*\"like\" + 0.005*\"good\" + 0.004*\"people\" + 0.004*\"would\" + 0.004*\"even\" + 0.004*\"movies\" + 0.003*\"really\"\n",
      "2017-04-23 01:06:43,121 : INFO : topic diff=0.422705, rho=0.220863\n",
      "2017-04-23 01:06:43,637 : INFO : PROGRESS: pass 8, at document #2000/25000\n",
      "2017-04-23 01:06:47,842 : INFO : PROGRESS: pass 8, at document #4000/25000\n",
      "2017-04-23 01:06:51,862 : INFO : PROGRESS: pass 8, at document #6000/25000\n",
      "2017-04-23 01:06:55,831 : INFO : PROGRESS: pass 8, at document #8000/25000\n",
      "2017-04-23 01:06:59,795 : INFO : PROGRESS: pass 8, at document #10000/25000\n",
      "2017-04-23 01:07:03,726 : INFO : PROGRESS: pass 8, at document #12000/25000\n",
      "2017-04-23 01:07:07,665 : INFO : PROGRESS: pass 8, at document #14000/25000\n",
      "2017-04-23 01:07:11,624 : INFO : PROGRESS: pass 8, at document #16000/25000\n",
      "2017-04-23 01:07:15,538 : INFO : PROGRESS: pass 8, at document #18000/25000\n",
      "2017-04-23 01:07:31,881 : INFO : -8.774 per-word bound, 437.8 perplexity estimate based on a held-out corpus of 2000 documents with 233362 words\n",
      "2017-04-23 01:07:31,882 : INFO : PROGRESS: pass 8, at document #20000/25000\n",
      "2017-04-23 01:07:36,176 : INFO : PROGRESS: pass 8, at document #22000/25000\n",
      "2017-04-23 01:07:40,442 : INFO : PROGRESS: pass 8, at document #24000/25000\n",
      "2017-04-23 01:07:50,755 : INFO : -8.757 per-word bound, 432.5 perplexity estimate based on a held-out corpus of 1000 documents with 114852 words\n",
      "2017-04-23 01:07:50,756 : INFO : PROGRESS: pass 8, at document #25000/25000\n",
      "2017-04-23 01:07:54,734 : INFO : topic #8 (0.050): 0.012*\"film\" + 0.011*\"movie\" + 0.006*\"one\" + 0.006*\"like\" + 0.005*\"great\" + 0.004*\"get\" + 0.004*\"see\" + 0.004*\"would\" + 0.004*\"time\" + 0.004*\"even\"\n",
      "2017-04-23 01:07:54,736 : INFO : topic #4 (0.050): 0.015*\"movie\" + 0.009*\"one\" + 0.005*\"like\" + 0.005*\"bad\" + 0.004*\"even\" + 0.004*\"would\" + 0.004*\"think\" + 0.004*\"film\" + 0.004*\"get\" + 0.003*\"well\"\n",
      "2017-04-23 01:07:54,738 : INFO : topic #5 (0.050): 0.023*\"film\" + 0.009*\"one\" + 0.006*\"good\" + 0.004*\"even\" + 0.004*\"like\" + 0.004*\"movie\" + 0.004*\"would\" + 0.004*\"story\" + 0.004*\"could\" + 0.003*\"great\"\n",
      "2017-04-23 01:07:54,740 : INFO : topic #9 (0.050): 0.014*\"movie\" + 0.013*\"film\" + 0.010*\"one\" + 0.007*\"time\" + 0.007*\"like\" + 0.004*\"really\" + 0.004*\"even\" + 0.004*\"story\" + 0.004*\"well\" + 0.003*\"great\"\n",
      "2017-04-23 01:07:54,741 : INFO : topic #14 (0.050): 0.015*\"film\" + 0.006*\"war\" + 0.005*\"would\" + 0.005*\"people\" + 0.005*\"one\" + 0.005*\"movie\" + 0.004*\"world\" + 0.004*\"see\" + 0.003*\"made\" + 0.003*\"like\"\n",
      "2017-04-23 01:07:54,748 : INFO : topic diff=0.389801, rho=0.215666\n",
      "2017-04-23 01:07:55,267 : INFO : PROGRESS: pass 9, at document #2000/25000\n",
      "2017-04-23 01:07:59,327 : INFO : PROGRESS: pass 9, at document #4000/25000\n",
      "2017-04-23 01:08:03,495 : INFO : PROGRESS: pass 9, at document #6000/25000\n",
      "2017-04-23 01:08:07,745 : INFO : PROGRESS: pass 9, at document #8000/25000\n",
      "2017-04-23 01:08:11,737 : INFO : PROGRESS: pass 9, at document #10000/25000\n",
      "2017-04-23 01:08:15,864 : INFO : PROGRESS: pass 9, at document #12000/25000\n",
      "2017-04-23 01:08:20,198 : INFO : PROGRESS: pass 9, at document #14000/25000\n",
      "2017-04-23 01:08:24,392 : INFO : PROGRESS: pass 9, at document #16000/25000\n",
      "2017-04-23 01:08:28,394 : INFO : PROGRESS: pass 9, at document #18000/25000\n",
      "2017-04-23 01:08:45,079 : INFO : -8.758 per-word bound, 432.9 perplexity estimate based on a held-out corpus of 2000 documents with 233362 words\n",
      "2017-04-23 01:08:45,080 : INFO : PROGRESS: pass 9, at document #20000/25000\n",
      "2017-04-23 01:08:49,092 : INFO : PROGRESS: pass 9, at document #22000/25000\n",
      "2017-04-23 01:08:53,055 : INFO : PROGRESS: pass 9, at document #24000/25000\n",
      "2017-04-23 01:09:03,360 : INFO : -8.741 per-word bound, 427.7 perplexity estimate based on a held-out corpus of 1000 documents with 114852 words\n",
      "2017-04-23 01:09:03,361 : INFO : PROGRESS: pass 9, at document #25000/25000\n",
      "2017-04-23 01:09:07,454 : INFO : topic #2 (0.050): 0.013*\"film\" + 0.008*\"movie\" + 0.007*\"one\" + 0.005*\"love\" + 0.005*\"like\" + 0.005*\"story\" + 0.004*\"well\" + 0.004*\"also\" + 0.004*\"young\" + 0.004*\"life\"\n",
      "2017-04-23 01:09:07,456 : INFO : topic #9 (0.050): 0.013*\"film\" + 0.013*\"movie\" + 0.010*\"one\" + 0.007*\"time\" + 0.007*\"like\" + 0.004*\"really\" + 0.004*\"even\" + 0.004*\"story\" + 0.004*\"well\" + 0.004*\"action\"\n",
      "2017-04-23 01:09:07,458 : INFO : topic #17 (0.050): 0.015*\"film\" + 0.014*\"movie\" + 0.007*\"one\" + 0.007*\"like\" + 0.005*\"good\" + 0.004*\"people\" + 0.004*\"even\" + 0.004*\"would\" + 0.003*\"movies\" + 0.003*\"really\"\n",
      "2017-04-23 01:09:07,459 : INFO : topic #18 (0.050): 0.029*\"movie\" + 0.010*\"like\" + 0.009*\"film\" + 0.005*\"good\" + 0.005*\"one\" + 0.005*\"see\" + 0.005*\"would\" + 0.004*\"much\" + 0.004*\"time\" + 0.004*\"movies\"\n",
      "2017-04-23 01:09:07,461 : INFO : topic #1 (0.050): 0.017*\"film\" + 0.011*\"one\" + 0.009*\"like\" + 0.007*\"movie\" + 0.005*\"time\" + 0.005*\"story\" + 0.005*\"even\" + 0.004*\"much\" + 0.004*\"well\" + 0.004*\"way\"\n",
      "2017-04-23 01:09:07,468 : INFO : topic diff=0.357097, rho=0.210819\n"
     ]
    }
   ],
   "source": [
    "lda2 = gensim.models.ldamodel.LdaModel(corpus=mm, id2word=dict_lda, num_topics=20, update_every=0, passes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X4_trfcorp = lda2.get_document_topics(corpus_lda, minimum_probability = 0) #creating a transformed corpus object containing tuples with topic probabilities\n",
    "X4 = np.zeros((25000,20)) #initializing a 2d version of the corpus object retaining only the probabilities\n",
    "#populating X3 by extracting probabilities from the tuples\n",
    "for i ,j in enumerate(X4_trfcorp):\n",
    "    probs = [item[1] for item in X4_trfcorp[i]]\n",
    "    X4[i] = probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X4_test_trfcorp = lda2.get_document_topics(corpus_lda_test, minimum_probability = 0) #creating a transformed corpus object containing tuples with topic probabilities\n",
    "X4_test = np.zeros((25000,20)) #initializing a 2d version of the corpus object retaining only the probabilities\n",
    "#populating X3 by extracting probabilities from the tuples\n",
    "for i ,j in enumerate(X4_test_trfcorp):\n",
    "    probs = [item[1] for item in X4_test_trfcorp[i]]\n",
    "    X4_test[i] = probs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Part c\n",
    "\n",
    "Printing tables of words for parts a) and b) respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-04-23 01:30:25,897 : INFO : topic #0 (0.100): 0.013*\"film\" + 0.009*\"movie\" + 0.007*\"one\" + 0.005*\"time\" + 0.004*\"story\" + 0.004*\"would\" + 0.004*\"like\" + 0.004*\"even\" + 0.003*\"good\" + 0.003*\"also\"\n",
      "2017-04-23 01:30:25,899 : INFO : topic #1 (0.100): 0.028*\"movie\" + 0.009*\"one\" + 0.007*\"bad\" + 0.006*\"film\" + 0.006*\"good\" + 0.006*\"like\" + 0.005*\"would\" + 0.005*\"movies\" + 0.005*\"time\" + 0.004*\"even\"\n",
      "2017-04-23 01:30:25,901 : INFO : topic #2 (0.100): 0.008*\"film\" + 0.007*\"one\" + 0.005*\"show\" + 0.004*\"movie\" + 0.004*\"like\" + 0.003*\"two\" + 0.003*\"best\" + 0.003*\"man\" + 0.003*\"get\" + 0.003*\"life\"\n",
      "2017-04-23 01:30:25,903 : INFO : topic #3 (0.100): 0.015*\"film\" + 0.013*\"one\" + 0.013*\"movie\" + 0.006*\"good\" + 0.006*\"like\" + 0.004*\"great\" + 0.004*\"would\" + 0.004*\"well\" + 0.004*\"even\" + 0.004*\"films\"\n",
      "2017-04-23 01:30:25,905 : INFO : topic #4 (0.100): 0.009*\"film\" + 0.009*\"one\" + 0.006*\"like\" + 0.004*\"series\" + 0.004*\"movie\" + 0.003*\"also\" + 0.003*\"time\" + 0.003*\"show\" + 0.003*\"many\" + 0.003*\"people\"\n",
      "2017-04-23 01:30:25,907 : INFO : topic #5 (0.100): 0.020*\"movie\" + 0.009*\"one\" + 0.008*\"like\" + 0.008*\"film\" + 0.006*\"bad\" + 0.006*\"even\" + 0.005*\"time\" + 0.005*\"would\" + 0.005*\"people\" + 0.005*\"see\"\n",
      "2017-04-23 01:30:25,908 : INFO : topic #6 (0.100): 0.021*\"film\" + 0.007*\"one\" + 0.006*\"like\" + 0.006*\"movie\" + 0.005*\"story\" + 0.005*\"good\" + 0.004*\"well\" + 0.004*\"really\" + 0.004*\"time\" + 0.004*\"great\"\n",
      "2017-04-23 01:30:25,911 : INFO : topic #7 (0.100): 0.017*\"film\" + 0.013*\"movie\" + 0.008*\"like\" + 0.007*\"one\" + 0.005*\"really\" + 0.005*\"good\" + 0.005*\"even\" + 0.005*\"story\" + 0.004*\"would\" + 0.004*\"well\"\n",
      "2017-04-23 01:30:25,912 : INFO : topic #8 (0.100): 0.018*\"movie\" + 0.015*\"film\" + 0.009*\"one\" + 0.007*\"like\" + 0.007*\"see\" + 0.005*\"time\" + 0.005*\"story\" + 0.005*\"well\" + 0.005*\"would\" + 0.005*\"really\"\n",
      "2017-04-23 01:30:25,914 : INFO : topic #9 (0.100): 0.021*\"movie\" + 0.012*\"film\" + 0.011*\"good\" + 0.009*\"like\" + 0.007*\"one\" + 0.005*\"really\" + 0.005*\"story\" + 0.004*\"even\" + 0.004*\"see\" + 0.003*\"would\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0,\n",
      "  '0.013*\"film\" + 0.009*\"movie\" + 0.007*\"one\" + 0.005*\"time\" + 0.004*\"story\" + '\n",
      "  '0.004*\"would\" + 0.004*\"like\" + 0.004*\"even\" + 0.003*\"good\" + 0.003*\"also\"'),\n",
      " (1,\n",
      "  '0.028*\"movie\" + 0.009*\"one\" + 0.007*\"bad\" + 0.006*\"film\" + 0.006*\"good\" + '\n",
      "  '0.006*\"like\" + 0.005*\"would\" + 0.005*\"movies\" + 0.005*\"time\" + '\n",
      "  '0.004*\"even\"'),\n",
      " (2,\n",
      "  '0.008*\"film\" + 0.007*\"one\" + 0.005*\"show\" + 0.004*\"movie\" + 0.004*\"like\" + '\n",
      "  '0.003*\"two\" + 0.003*\"best\" + 0.003*\"man\" + 0.003*\"get\" + 0.003*\"life\"'),\n",
      " (3,\n",
      "  '0.015*\"film\" + 0.013*\"one\" + 0.013*\"movie\" + 0.006*\"good\" + 0.006*\"like\" + '\n",
      "  '0.004*\"great\" + 0.004*\"would\" + 0.004*\"well\" + 0.004*\"even\" + '\n",
      "  '0.004*\"films\"'),\n",
      " (4,\n",
      "  '0.009*\"film\" + 0.009*\"one\" + 0.006*\"like\" + 0.004*\"series\" + 0.004*\"movie\" '\n",
      "  '+ 0.003*\"also\" + 0.003*\"time\" + 0.003*\"show\" + 0.003*\"many\" + '\n",
      "  '0.003*\"people\"'),\n",
      " (5,\n",
      "  '0.020*\"movie\" + 0.009*\"one\" + 0.008*\"like\" + 0.008*\"film\" + 0.006*\"bad\" + '\n",
      "  '0.006*\"even\" + 0.005*\"time\" + 0.005*\"would\" + 0.005*\"people\" + 0.005*\"see\"'),\n",
      " (6,\n",
      "  '0.021*\"film\" + 0.007*\"one\" + 0.006*\"like\" + 0.006*\"movie\" + 0.005*\"story\" + '\n",
      "  '0.005*\"good\" + 0.004*\"well\" + 0.004*\"really\" + 0.004*\"time\" + '\n",
      "  '0.004*\"great\"'),\n",
      " (7,\n",
      "  '0.017*\"film\" + 0.013*\"movie\" + 0.008*\"like\" + 0.007*\"one\" + 0.005*\"really\" '\n",
      "  '+ 0.005*\"good\" + 0.005*\"even\" + 0.005*\"story\" + 0.004*\"would\" + '\n",
      "  '0.004*\"well\"'),\n",
      " (8,\n",
      "  '0.018*\"movie\" + 0.015*\"film\" + 0.009*\"one\" + 0.007*\"like\" + 0.007*\"see\" + '\n",
      "  '0.005*\"time\" + 0.005*\"story\" + 0.005*\"well\" + 0.005*\"would\" + '\n",
      "  '0.005*\"really\"'),\n",
      " (9,\n",
      "  '0.021*\"movie\" + 0.012*\"film\" + 0.011*\"good\" + 0.009*\"like\" + 0.007*\"one\" + '\n",
      "  '0.005*\"really\" + 0.005*\"story\" + 0.004*\"even\" + 0.004*\"see\" + '\n",
      "  '0.003*\"would\"')]\n"
     ]
    }
   ],
   "source": [
    "#part a)\n",
    "from pprint import pprint \n",
    "pprint(lda.print_topics(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-04-23 01:30:38,417 : INFO : topic #0 (0.050): 0.013*\"film\" + 0.009*\"one\" + 0.007*\"movie\" + 0.005*\"also\" + 0.005*\"good\" + 0.005*\"well\" + 0.004*\"time\" + 0.004*\"story\" + 0.003*\"two\" + 0.003*\"much\"\n",
      "2017-04-23 01:30:38,418 : INFO : topic #1 (0.050): 0.017*\"film\" + 0.011*\"one\" + 0.009*\"like\" + 0.007*\"movie\" + 0.005*\"time\" + 0.005*\"story\" + 0.005*\"even\" + 0.004*\"much\" + 0.004*\"well\" + 0.004*\"way\"\n",
      "2017-04-23 01:30:38,420 : INFO : topic #2 (0.050): 0.013*\"film\" + 0.008*\"movie\" + 0.007*\"one\" + 0.005*\"love\" + 0.005*\"like\" + 0.005*\"story\" + 0.004*\"well\" + 0.004*\"also\" + 0.004*\"young\" + 0.004*\"life\"\n",
      "2017-04-23 01:30:38,421 : INFO : topic #3 (0.050): 0.011*\"film\" + 0.008*\"one\" + 0.008*\"movie\" + 0.005*\"time\" + 0.004*\"would\" + 0.004*\"also\" + 0.004*\"like\" + 0.004*\"well\" + 0.003*\"story\" + 0.003*\"good\"\n",
      "2017-04-23 01:30:38,423 : INFO : topic #4 (0.050): 0.015*\"movie\" + 0.009*\"one\" + 0.005*\"like\" + 0.005*\"bad\" + 0.004*\"even\" + 0.004*\"would\" + 0.004*\"think\" + 0.004*\"film\" + 0.003*\"get\" + 0.003*\"well\"\n",
      "2017-04-23 01:30:38,425 : INFO : topic #5 (0.050): 0.023*\"film\" + 0.009*\"one\" + 0.006*\"good\" + 0.004*\"even\" + 0.004*\"like\" + 0.004*\"story\" + 0.004*\"would\" + 0.004*\"movie\" + 0.003*\"could\" + 0.003*\"great\"\n",
      "2017-04-23 01:30:38,426 : INFO : topic #6 (0.050): 0.009*\"film\" + 0.008*\"one\" + 0.005*\"movie\" + 0.005*\"story\" + 0.004*\"jane\" + 0.004*\"like\" + 0.004*\"time\" + 0.004*\"love\" + 0.004*\"good\" + 0.003*\"also\"\n",
      "2017-04-23 01:30:38,429 : INFO : topic #7 (0.050): 0.011*\"one\" + 0.010*\"movie\" + 0.008*\"like\" + 0.007*\"really\" + 0.007*\"good\" + 0.005*\"film\" + 0.005*\"even\" + 0.004*\"would\" + 0.004*\"great\" + 0.004*\"see\"\n",
      "2017-04-23 01:30:38,430 : INFO : topic #8 (0.050): 0.012*\"film\" + 0.010*\"movie\" + 0.006*\"one\" + 0.006*\"like\" + 0.005*\"great\" + 0.004*\"get\" + 0.004*\"see\" + 0.004*\"would\" + 0.004*\"time\" + 0.004*\"even\"\n",
      "2017-04-23 01:30:38,432 : INFO : topic #9 (0.050): 0.013*\"film\" + 0.013*\"movie\" + 0.010*\"one\" + 0.007*\"time\" + 0.007*\"like\" + 0.004*\"really\" + 0.004*\"even\" + 0.004*\"story\" + 0.004*\"well\" + 0.004*\"action\"\n",
      "2017-04-23 01:30:38,434 : INFO : topic #10 (0.050): 0.021*\"film\" + 0.010*\"movie\" + 0.008*\"one\" + 0.007*\"like\" + 0.006*\"story\" + 0.006*\"good\" + 0.005*\"well\" + 0.005*\"even\" + 0.004*\"films\" + 0.004*\"see\"\n",
      "2017-04-23 01:30:38,436 : INFO : topic #11 (0.050): 0.042*\"movie\" + 0.011*\"one\" + 0.010*\"like\" + 0.010*\"film\" + 0.009*\"bad\" + 0.009*\"good\" + 0.008*\"really\" + 0.007*\"would\" + 0.007*\"movies\" + 0.007*\"even\"\n",
      "2017-04-23 01:30:38,438 : INFO : topic #12 (0.050): 0.022*\"movie\" + 0.010*\"one\" + 0.009*\"like\" + 0.007*\"good\" + 0.007*\"film\" + 0.005*\"would\" + 0.005*\"really\" + 0.005*\"even\" + 0.005*\"movies\" + 0.004*\"see\"\n",
      "2017-04-23 01:30:38,439 : INFO : topic #13 (0.050): 0.013*\"film\" + 0.009*\"one\" + 0.008*\"movie\" + 0.007*\"like\" + 0.004*\"see\" + 0.004*\"people\" + 0.004*\"story\" + 0.004*\"life\" + 0.004*\"good\" + 0.004*\"get\"\n",
      "2017-04-23 01:30:38,441 : INFO : topic #14 (0.050): 0.014*\"film\" + 0.007*\"war\" + 0.005*\"people\" + 0.005*\"would\" + 0.005*\"one\" + 0.004*\"world\" + 0.004*\"movie\" + 0.004*\"see\" + 0.003*\"made\" + 0.003*\"like\"\n",
      "2017-04-23 01:30:38,443 : INFO : topic #15 (0.050): 0.022*\"show\" + 0.010*\"one\" + 0.008*\"series\" + 0.007*\"good\" + 0.006*\"like\" + 0.006*\"movie\" + 0.005*\"funny\" + 0.005*\"time\" + 0.005*\"would\" + 0.005*\"episode\"\n",
      "2017-04-23 01:30:38,445 : INFO : topic #16 (0.050): 0.019*\"film\" + 0.008*\"movie\" + 0.007*\"one\" + 0.006*\"like\" + 0.005*\"first\" + 0.004*\"story\" + 0.004*\"much\" + 0.004*\"would\" + 0.004*\"even\" + 0.004*\"see\"\n",
      "2017-04-23 01:30:38,447 : INFO : topic #17 (0.050): 0.015*\"film\" + 0.014*\"movie\" + 0.007*\"one\" + 0.007*\"like\" + 0.005*\"good\" + 0.004*\"people\" + 0.004*\"even\" + 0.004*\"would\" + 0.003*\"movies\" + 0.003*\"really\"\n",
      "2017-04-23 01:30:38,448 : INFO : topic #18 (0.050): 0.029*\"movie\" + 0.010*\"like\" + 0.009*\"film\" + 0.005*\"good\" + 0.005*\"one\" + 0.005*\"see\" + 0.005*\"would\" + 0.004*\"much\" + 0.004*\"time\" + 0.004*\"movies\"\n",
      "2017-04-23 01:30:38,450 : INFO : topic #19 (0.050): 0.014*\"movie\" + 0.012*\"film\" + 0.007*\"one\" + 0.007*\"story\" + 0.005*\"like\" + 0.004*\"time\" + 0.004*\"even\" + 0.004*\"good\" + 0.003*\"see\" + 0.003*\"new\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0,\n",
      "  '0.013*\"film\" + 0.009*\"one\" + 0.007*\"movie\" + 0.005*\"also\" + 0.005*\"good\" + '\n",
      "  '0.005*\"well\" + 0.004*\"time\" + 0.004*\"story\" + 0.003*\"two\" + 0.003*\"much\"'),\n",
      " (1,\n",
      "  '0.017*\"film\" + 0.011*\"one\" + 0.009*\"like\" + 0.007*\"movie\" + 0.005*\"time\" + '\n",
      "  '0.005*\"story\" + 0.005*\"even\" + 0.004*\"much\" + 0.004*\"well\" + 0.004*\"way\"'),\n",
      " (2,\n",
      "  '0.013*\"film\" + 0.008*\"movie\" + 0.007*\"one\" + 0.005*\"love\" + 0.005*\"like\" + '\n",
      "  '0.005*\"story\" + 0.004*\"well\" + 0.004*\"also\" + 0.004*\"young\" + 0.004*\"life\"'),\n",
      " (3,\n",
      "  '0.011*\"film\" + 0.008*\"one\" + 0.008*\"movie\" + 0.005*\"time\" + 0.004*\"would\" + '\n",
      "  '0.004*\"also\" + 0.004*\"like\" + 0.004*\"well\" + 0.003*\"story\" + 0.003*\"good\"'),\n",
      " (4,\n",
      "  '0.015*\"movie\" + 0.009*\"one\" + 0.005*\"like\" + 0.005*\"bad\" + 0.004*\"even\" + '\n",
      "  '0.004*\"would\" + 0.004*\"think\" + 0.004*\"film\" + 0.003*\"get\" + 0.003*\"well\"'),\n",
      " (5,\n",
      "  '0.023*\"film\" + 0.009*\"one\" + 0.006*\"good\" + 0.004*\"even\" + 0.004*\"like\" + '\n",
      "  '0.004*\"story\" + 0.004*\"would\" + 0.004*\"movie\" + 0.003*\"could\" + '\n",
      "  '0.003*\"great\"'),\n",
      " (6,\n",
      "  '0.009*\"film\" + 0.008*\"one\" + 0.005*\"movie\" + 0.005*\"story\" + 0.004*\"jane\" + '\n",
      "  '0.004*\"like\" + 0.004*\"time\" + 0.004*\"love\" + 0.004*\"good\" + 0.003*\"also\"'),\n",
      " (7,\n",
      "  '0.011*\"one\" + 0.010*\"movie\" + 0.008*\"like\" + 0.007*\"really\" + 0.007*\"good\" '\n",
      "  '+ 0.005*\"film\" + 0.005*\"even\" + 0.004*\"would\" + 0.004*\"great\" + '\n",
      "  '0.004*\"see\"'),\n",
      " (8,\n",
      "  '0.012*\"film\" + 0.010*\"movie\" + 0.006*\"one\" + 0.006*\"like\" + 0.005*\"great\" + '\n",
      "  '0.004*\"get\" + 0.004*\"see\" + 0.004*\"would\" + 0.004*\"time\" + 0.004*\"even\"'),\n",
      " (9,\n",
      "  '0.013*\"film\" + 0.013*\"movie\" + 0.010*\"one\" + 0.007*\"time\" + 0.007*\"like\" + '\n",
      "  '0.004*\"really\" + 0.004*\"even\" + 0.004*\"story\" + 0.004*\"well\" + '\n",
      "  '0.004*\"action\"'),\n",
      " (10,\n",
      "  '0.021*\"film\" + 0.010*\"movie\" + 0.008*\"one\" + 0.007*\"like\" + 0.006*\"story\" + '\n",
      "  '0.006*\"good\" + 0.005*\"well\" + 0.005*\"even\" + 0.004*\"films\" + 0.004*\"see\"'),\n",
      " (11,\n",
      "  '0.042*\"movie\" + 0.011*\"one\" + 0.010*\"like\" + 0.010*\"film\" + 0.009*\"bad\" + '\n",
      "  '0.009*\"good\" + 0.008*\"really\" + 0.007*\"would\" + 0.007*\"movies\" + '\n",
      "  '0.007*\"even\"'),\n",
      " (12,\n",
      "  '0.022*\"movie\" + 0.010*\"one\" + 0.009*\"like\" + 0.007*\"good\" + 0.007*\"film\" + '\n",
      "  '0.005*\"would\" + 0.005*\"really\" + 0.005*\"even\" + 0.005*\"movies\" + '\n",
      "  '0.004*\"see\"'),\n",
      " (13,\n",
      "  '0.013*\"film\" + 0.009*\"one\" + 0.008*\"movie\" + 0.007*\"like\" + 0.004*\"see\" + '\n",
      "  '0.004*\"people\" + 0.004*\"story\" + 0.004*\"life\" + 0.004*\"good\" + 0.004*\"get\"'),\n",
      " (14,\n",
      "  '0.014*\"film\" + 0.007*\"war\" + 0.005*\"people\" + 0.005*\"would\" + 0.005*\"one\" + '\n",
      "  '0.004*\"world\" + 0.004*\"movie\" + 0.004*\"see\" + 0.003*\"made\" + 0.003*\"like\"'),\n",
      " (15,\n",
      "  '0.022*\"show\" + 0.010*\"one\" + 0.008*\"series\" + 0.007*\"good\" + 0.006*\"like\" + '\n",
      "  '0.006*\"movie\" + 0.005*\"funny\" + 0.005*\"time\" + 0.005*\"would\" + '\n",
      "  '0.005*\"episode\"'),\n",
      " (16,\n",
      "  '0.019*\"film\" + 0.008*\"movie\" + 0.007*\"one\" + 0.006*\"like\" + 0.005*\"first\" + '\n",
      "  '0.004*\"story\" + 0.004*\"much\" + 0.004*\"would\" + 0.004*\"even\" + 0.004*\"see\"'),\n",
      " (17,\n",
      "  '0.015*\"film\" + 0.014*\"movie\" + 0.007*\"one\" + 0.007*\"like\" + 0.005*\"good\" + '\n",
      "  '0.004*\"people\" + 0.004*\"even\" + 0.004*\"would\" + 0.003*\"movies\" + '\n",
      "  '0.003*\"really\"'),\n",
      " (18,\n",
      "  '0.029*\"movie\" + 0.010*\"like\" + 0.009*\"film\" + 0.005*\"good\" + 0.005*\"one\" + '\n",
      "  '0.005*\"see\" + 0.005*\"would\" + 0.004*\"much\" + 0.004*\"time\" + 0.004*\"movies\"'),\n",
      " (19,\n",
      "  '0.014*\"movie\" + 0.012*\"film\" + 0.007*\"one\" + 0.007*\"story\" + 0.005*\"like\" + '\n",
      "  '0.004*\"time\" + 0.004*\"even\" + 0.004*\"good\" + 0.003*\"see\" + 0.003*\"new\"')]\n"
     ]
    }
   ],
   "source": [
    "#part b\n",
    "pprint(lda2.print_topics(20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Question3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Part a\n",
    "\n",
    "To create the classifiers, we need to tune parameters. We will be using a grid of parameter values and using GridSearchCV to perform the tuning. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "y = train[\"sentiment\"]\n",
    "X1_tr, X1_ts, y_tr, y_ts = train_test_split(X1, y, test_size=0.2, random_state=0)\n",
    "X2_tr, X2_ts, y_tr, y_ts = train_test_split(X2, y, test_size=0.2, random_state=0)\n",
    "X3_tr, X3_ts, y_tr, y_ts = train_test_split(X3, y, test_size=0.2, random_state=0)\n",
    "X4_tr, X4_ts, y_tr, y_ts = train_test_split(X4, y, test_size=0.2, random_state=0)\n",
    "\n",
    "\n",
    "param_grid = {\"criterion\": [\"gini\", \"entropy\"],\n",
    "              #\"max_depth\": [None, 2, 5, 10],\n",
    "              \"n_estimators\": range(10,100,10) ,\n",
    "              \"min_samples_leaf\": range(10,100,10)\n",
    "             }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Classifier 1 done \n",
      "\n",
      "\n",
      " Classifier 2 done \n",
      "\n",
      "\n",
      " Classifier 3 done \n",
      "\n",
      "\n",
      " Classifier 4 done \n",
      "\n",
      "Time taken for GridSearchCV:  3638.4281301498413 seconds.\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "rf = RandomForestClassifier()\n",
    "rf_clf1 = GridSearchCV(rf, param_grid=  param_grid, scoring = 'roc_auc' ,cv = 5 )\n",
    "rf_clf1.fit(X1_tr , y_tr )\n",
    "print (\"\\n Classifier 1 done \\n\")\n",
    "rf_clf2 = GridSearchCV(rf, param_grid=  param_grid, scoring = 'roc_auc' ,cv = 5 )\n",
    "rf_clf2.fit(X2_tr  , y_tr )\n",
    "print (\"\\n Classifier 2 done \\n\")\n",
    "\n",
    "rf_clf3 = GridSearchCV(rf, param_grid=  param_grid, scoring = 'roc_auc' ,cv = 5 )\n",
    "rf_clf3.fit(X3_tr  , y_tr )\n",
    "print (\"\\n Classifier 3 done \\n\")\n",
    "rf_clf4 = GridSearchCV(rf, param_grid=  param_grid, scoring = 'roc_auc' ,cv = 5 )\n",
    "rf_clf4.fit(X4_tr , y_tr )\n",
    "\n",
    "print (\"\\n Classifier 4 done \\n\")\n",
    "\n",
    "\n",
    "# Get the end time and print how long the process took\n",
    "end = time.time()\n",
    "elapsed = end - start\n",
    "print (\"Time taken for GridSearchCV: \", elapsed, \"seconds.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Best estimator for classifier 1 \n",
      "\n",
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='entropy',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=20,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            n_estimators=80, n_jobs=1, oob_score=False, random_state=None,\n",
      "            verbose=0, warm_start=False)\n",
      "\n",
      " Best estimator for classifier 2 \n",
      "\n",
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='entropy',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=10,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            n_estimators=90, n_jobs=1, oob_score=False, random_state=None,\n",
      "            verbose=0, warm_start=False)\n",
      "\n",
      " Best estimator for classifier 3 \n",
      "\n",
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='entropy',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=80,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            n_estimators=90, n_jobs=1, oob_score=False, random_state=None,\n",
      "            verbose=0, warm_start=False)\n",
      "\n",
      " Best estimator for classifier 4 \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='entropy',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_split=1e-07, min_samples_leaf=60,\n",
       "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "            n_estimators=80, n_jobs=1, oob_score=False, random_state=None,\n",
       "            verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print (\"\\n Best estimator for classifier 1 \\n\")\n",
    "print(rf_clf1.best_estimator_)\n",
    "print (\"\\n Best estimator for classifier 2 \\n\")\n",
    "print(rf_clf2.best_estimator_)\n",
    "print (\"\\n Best estimator for classifier 3 \\n\")\n",
    "print(rf_clf3.best_estimator_)\n",
    "print (\"\\n Best estimator for classifier 4 \\n\")\n",
    "rf_clf4.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "We will now use the optimal parameters to build M1, M2, M3 and M4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "M1 = RandomForestClassifier(bootstrap=True, class_weight=None, criterion='entropy',\n",
    "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
    "            min_impurity_split=1e-07, min_samples_leaf=20,\n",
    "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
    "            n_estimators=80, n_jobs=1, oob_score=False, random_state=None,\n",
    "            verbose=0, warm_start=False)\n",
    "\n",
    "M2 = RandomForestClassifier(bootstrap=True, class_weight=None, criterion='entropy',\n",
    "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
    "            min_impurity_split=1e-07, min_samples_leaf=10,\n",
    "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
    "            n_estimators=90, n_jobs=1, oob_score=False, random_state=None,\n",
    "            verbose=0, warm_start=False)\n",
    "\n",
    "M3 = RandomForestClassifier(bootstrap=True, class_weight=None, criterion='entropy',\n",
    "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
    "            min_impurity_split=1e-07, min_samples_leaf=80,\n",
    "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
    "            n_estimators=90, n_jobs=1, oob_score=False, random_state=None,\n",
    "            verbose=0, warm_start=False)\n",
    "\n",
    "\n",
    "M4 = RandomForestClassifier(bootstrap=True, class_weight=None, criterion='entropy',\n",
    "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
    "            min_impurity_split=1e-07, min_samples_leaf=60,\n",
    "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
    "            n_estimators=80, n_jobs=1, oob_score=False, random_state=None,\n",
    "            verbose=0, warm_start=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Part b\n",
    "\n",
    "Using the trained classifiers to predict values from the holdout set from the train_test_splits made earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "M1.fit(X1_tr , y_tr)\n",
    "y_pred1 = M1.predict_proba(X1_ts)[:,1]\n",
    "\n",
    "M2.fit(X2_tr , y_tr)\n",
    "y_pred2 = M2.predict_proba(X2_ts)[:,1]\n",
    "\n",
    "M3.fit(X3_tr , y_tr)\n",
    "y_pred3 = M3.predict_proba(X3_ts)[:,1]\n",
    "\n",
    "\n",
    "M4.fit(X4_tr , y_tr)\n",
    "y_pred4 = M4.predict_proba(X4_ts)[:,1]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Obtaining ROC metrics by comparing actual vs predicted y values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "fpr1, tpr1, _ = roc_curve(y_ts ,y_pred1 )\n",
    "\n",
    "fpr2, tpr2, _ = roc_curve(y_ts ,y_pred2 )\n",
    "\n",
    "fpr3, tpr3, _ = roc_curve(y_ts ,y_pred3 )\n",
    "\n",
    "fpr4, tpr4, _ = roc_curve(y_ts ,y_pred4 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "score1 = auc(fpr1, tpr1)\n",
    "score2 = auc(fpr2, tpr2)\n",
    "score3 = auc(fpr3, tpr3)\n",
    "score4 = auc(fpr4, tpr4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC Scores: \n",
      "\n",
      "Classifier 1:  0.683511489676 \n",
      "\n",
      "Classifier 2:  0.720719446017 \n",
      "\n",
      "Classifier 3:  0.751752726125 \n",
      "\n",
      "Classifier 4:  0.742088043336 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print (\"ROC AUC Scores: \\n\")\n",
    "print(\"Classifier 1: \", score1, \"\\n\")\n",
    "print(\"Classifier 2: \", score2, \"\\n\")\n",
    "print(\"Classifier 3: \", score3, \"\\n\")\n",
    "print(\"Classifier 4: \", score4, \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def ROC_plotter(roc_metrics, name = None):\n",
    "    fpr, tpr, roc_auc = roc_metrics\n",
    "    plt.plot(fpr,tpr, lw = 1.5, color='blue', label='AUC = %0.2f' % roc_auc)\n",
    "    plt.plot([0, 1], [0, 1], color='red', lw=1.5, linestyle='--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.title('ROC for %s' %(name))\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.legend(loc=\"lower right\")    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYoAAAEWCAYAAAB42tAoAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x304aa7080>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ROC_plotter( (fpr1, tpr1, score1), name = \"X1\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYoAAAEWCAYAAAB42tAoAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2eb290e80>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ROC_plotter( (fpr2, tpr2, score2), name = \"X2\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYoAAAEWCAYAAAB42tAoAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2e17a8ac8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ROC_plotter( (fpr3, tpr3, score3), name = \"X3\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYoAAAEWCAYAAAB42tAoAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\niP4fPhCp4hcx3ZQAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2e0b967b8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ROC_plotter( (fpr4, tpr4, score4), name = \"X4\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Rebuilding the simple Bag of Words model from Part 1 of the tutorial as a baseline for comparison:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Initialize the \"CountVectorizer\" object, which is scikit-learn's\n",
    "# bag of words tool.  \n",
    "vectorizer = CountVectorizer(analyzer = \"word\",   \\\n",
    "                             tokenizer = None,    \\\n",
    "                             preprocessor = None, \\\n",
    "                             stop_words = None,   \\\n",
    "                             max_features = 5000) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def review_to_words( raw_review ):\n",
    "    # Function to convert a raw review to a string of words\n",
    "    # The input is a single string (a raw movie review), and \n",
    "    # the output is a single string (a preprocessed movie review)\n",
    "    #\n",
    "    # 1. Remove HTML\n",
    "    review_text = BeautifulSoup(raw_review, \"html.parser\").get_text() \n",
    "    #\n",
    "    # 2. Remove non-letters        \n",
    "    letters_only = re.sub(\"[^a-zA-Z]\", \" \", review_text) \n",
    "    #\n",
    "    # 3. Convert to lower case, split into individual words\n",
    "    words = letters_only.lower().split()                             \n",
    "    #\n",
    "    # 4. In Python, searching a set is much faster than searching\n",
    "    #   a list, so convert the stop words to a set\n",
    "    stops = set(stopwords.words(\"english\"))                  \n",
    "    # \n",
    "    # 5. Remove stop words\n",
    "    meaningful_words = [w for w in words if not w in stops]   \n",
    "    #\n",
    "    # 6. Join the words back into one string separated by space, \n",
    "    # and return the result.\n",
    "    return( \" \".join( meaningful_words ))   \n",
    "    \n",
    "\n",
    "\n",
    "num_reviews = train[\"review\"].size\n",
    "\n",
    "clean_train_reviews3 = []\n",
    "clean_test_reviews3 = []\n",
    "\n",
    "for i in range( 0, num_reviews ):\n",
    "    # Call our function for each one, and add the result to the list of\n",
    "    # clean reviews\n",
    "    clean_train_reviews3.append( review_to_words( train[\"review\"][i] ) )\n",
    "    clean_test_reviews3.append( review_to_words( test[\"review\"][i] ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "\n",
    "X_counts = vectorizer.fit_transform(clean_train_reviews3)\n",
    "\n",
    "X_counts = X_counts.toarray()\n",
    "\n",
    "vocab = vectorizer.get_feature_names()\n",
    "\n",
    "dist = np.sum(X_counts, axis=0)\n",
    "\n",
    "X_counts2 = vectorizer.fit_transform(clean_test_reviews3)\n",
    "\n",
    "X_counts2 = X_counts2.toarray()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "X5_tr, X5_ts, y_tr, y_ts = train_test_split(X_counts, y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "param_grid = {\"max_depth\": [None, 2, 5, 10],\n",
    "              \"n_estimators\": range(80,100,10) ,\n",
    "              \"min_samples_leaf\": range(50,100,10)\n",
    "             }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 40 candidates, totalling 200 fits\n",
      "[CV] min_samples_leaf=50, max_depth=None, n_estimators=80 ............\n",
      "[CV] min_samples_leaf=50, max_depth=None, n_estimators=80 ............\n",
      "[CV] min_samples_leaf=50, max_depth=None, n_estimators=80 ............\n",
      "[CV] min_samples_leaf=50, max_depth=None, n_estimators=80 ............\n",
      "[CV] min_samples_leaf=50, max_depth=None, n_estimators=80 ............\n",
      "[CV] min_samples_leaf=50, max_depth=None, n_estimators=90 ............\n",
      "[CV] min_samples_leaf=50, max_depth=None, n_estimators=90 ............\n",
      "[CV] min_samples_leaf=50, max_depth=None, n_estimators=90 ............\n",
      "[CV]  min_samples_leaf=50, max_depth=None, n_estimators=80, score=0.900632, total= 1.0min\n",
      "[CV] min_samples_leaf=50, max_depth=None, n_estimators=90 ............\n",
      "[CV]  min_samples_leaf=50, max_depth=None, n_estimators=80, score=0.911038, total= 1.1min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:  1.1min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  min_samples_leaf=50, max_depth=None, n_estimators=80, score=0.911857, total= 1.0min\n",
      "[CV] min_samples_leaf=50, max_depth=None, n_estimators=90 ............\n",
      "[CV]  min_samples_leaf=50, max_depth=None, n_estimators=80, score=0.906579, total= 1.1min\n",
      "[CV] min_samples_leaf=60, max_depth=None, n_estimators=80 ............\n",
      "[CV]  min_samples_leaf=50, max_depth=None, n_estimators=80, score=0.896330, total= 1.1min\n",
      "[CV] min_samples_leaf=60, max_depth=None, n_estimators=80 ............\n",
      "[CV] min_samples_leaf=60, max_depth=None, n_estimators=80 ............\n",
      "[CV]  min_samples_leaf=50, max_depth=None, n_estimators=90, score=0.910737, total= 1.2min\n",
      "[CV]  min_samples_leaf=50, max_depth=None, n_estimators=90, score=0.900333, total= 1.1min\n",
      "[CV] min_samples_leaf=60, max_depth=None, n_estimators=80 ............\n",
      "[CV]  min_samples_leaf=50, max_depth=None, n_estimators=90, score=0.912037, total= 1.1min\n",
      "[CV] min_samples_leaf=60, max_depth=None, n_estimators=80 ............\n",
      "[CV] min_samples_leaf=60, max_depth=None, n_estimators=90 ............\n",
      "[CV]  min_samples_leaf=60, max_depth=None, n_estimators=80, score=0.903792, total=  49.6s\n",
      "[CV] min_samples_leaf=60, max_depth=None, n_estimators=90 ............\n",
      "[CV]  min_samples_leaf=60, max_depth=None, n_estimators=80, score=0.896029, total=  50.8s\n",
      "[CV] min_samples_leaf=60, max_depth=None, n_estimators=90 ............\n",
      "[CV]  min_samples_leaf=50, max_depth=None, n_estimators=90, score=0.905191, total= 1.0min\n",
      "[CV] min_samples_leaf=60, max_depth=None, n_estimators=90 ............\n",
      "[CV]  min_samples_leaf=60, max_depth=None, n_estimators=80, score=0.907639, total=  52.8s\n",
      "[CV] min_samples_leaf=60, max_depth=None, n_estimators=90 ............\n",
      "[CV]  min_samples_leaf=50, max_depth=None, n_estimators=90, score=0.897970, total=  59.6s\n",
      "[CV] min_samples_leaf=70, max_depth=None, n_estimators=80 ............\n",
      "[CV]  min_samples_leaf=60, max_depth=None, n_estimators=80, score=0.906009, total=  52.7s\n",
      "[CV] min_samples_leaf=70, max_depth=None, n_estimators=80 ............\n",
      "[CV]  min_samples_leaf=60, max_depth=None, n_estimators=80, score=0.896829, total=  53.6s\n",
      "[CV] min_samples_leaf=70, max_depth=None, n_estimators=80 ............\n",
      "[CV]  min_samples_leaf=60, max_depth=None, n_estimators=90, score=0.905370, total=  59.9s\n",
      "[CV] min_samples_leaf=70, max_depth=None, n_estimators=80 ............\n",
      "[CV]  min_samples_leaf=60, max_depth=None, n_estimators=90, score=0.898961, total= 1.1min\n",
      "[CV] min_samples_leaf=70, max_depth=None, n_estimators=80 ............\n",
      "[CV]  min_samples_leaf=70, max_depth=None, n_estimators=80, score=0.905266, total= 1.0min\n",
      "[CV] min_samples_leaf=70, max_depth=None, n_estimators=90 ............\n",
      "[CV]  min_samples_leaf=70, max_depth=None, n_estimators=80, score=0.898079, total=  60.0s\n",
      "[CV] min_samples_leaf=70, max_depth=None, n_estimators=90 ............\n",
      "[CV]  min_samples_leaf=60, max_depth=None, n_estimators=90, score=0.912732, total= 1.2min\n",
      "[CV] min_samples_leaf=70, max_depth=None, n_estimators=90 ............\n",
      "[CV]  min_samples_leaf=60, max_depth=None, n_estimators=90, score=0.906949, total= 1.2min\n",
      "[CV]  min_samples_leaf=70, max_depth=None, n_estimators=80, score=0.911563, total= 1.0min\n",
      "[CV] min_samples_leaf=70, max_depth=None, n_estimators=90 ............\n",
      "[CV]  min_samples_leaf=60, max_depth=None, n_estimators=90, score=0.898960, total= 1.2min\n",
      "[CV] min_samples_leaf=70, max_depth=None, n_estimators=90 ............\n",
      "[CV]  min_samples_leaf=70, max_depth=None, n_estimators=80, score=0.905879, total=  58.2s\n",
      "[CV] min_samples_leaf=80, max_depth=None, n_estimators=80 ............\n",
      "[CV] min_samples_leaf=80, max_depth=None, n_estimators=80 ............\n",
      "[CV]  min_samples_leaf=70, max_depth=None, n_estimators=80, score=0.898230, total=  52.1s\n",
      "[CV] min_samples_leaf=80, max_depth=None, n_estimators=80 ............\n",
      "[CV]  min_samples_leaf=70, max_depth=None, n_estimators=90, score=0.910578, total=  58.4s\n",
      "[CV] min_samples_leaf=80, max_depth=None, n_estimators=80 ............\n",
      "[CV]  min_samples_leaf=70, max_depth=None, n_estimators=90, score=0.899057, total=  57.4s\n",
      "[CV] min_samples_leaf=80, max_depth=None, n_estimators=80 ............\n",
      "[CV]  min_samples_leaf=80, max_depth=None, n_estimators=80, score=0.908143, total=  52.7s\n",
      "[CV] min_samples_leaf=80, max_depth=None, n_estimators=90 ............\n",
      "[CV]  min_samples_leaf=70, max_depth=None, n_estimators=90, score=0.912883, total=  58.7s\n",
      "[CV]  min_samples_leaf=80, max_depth=None, n_estimators=80, score=0.897597, total=  52.6s\n",
      "[CV] min_samples_leaf=80, max_depth=None, n_estimators=90 ............\n",
      "[CV]  min_samples_leaf=70, max_depth=None, n_estimators=90, score=0.899029, total=  57.9s\n",
      "[CV] min_samples_leaf=80, max_depth=None, n_estimators=90 ............\n",
      "[CV]  min_samples_leaf=70, max_depth=None, n_estimators=90, score=0.905880, total=  59.2s\n",
      "[CV] min_samples_leaf=80, max_depth=None, n_estimators=90 ............\n",
      "[CV] min_samples_leaf=80, max_depth=None, n_estimators=90 ............\n",
      "[CV]  min_samples_leaf=80, max_depth=None, n_estimators=80, score=0.911582, total=  48.0s\n",
      "[CV] min_samples_leaf=90, max_depth=None, n_estimators=80 ............\n",
      "[CV]  min_samples_leaf=80, max_depth=None, n_estimators=80, score=0.901634, total=  47.1s\n",
      "[CV] min_samples_leaf=90, max_depth=None, n_estimators=80 ............\n",
      "[CV]  min_samples_leaf=80, max_depth=None, n_estimators=80, score=0.898659, total=  47.5s\n",
      "[CV] min_samples_leaf=90, max_depth=None, n_estimators=80 ............\n",
      "[CV]  min_samples_leaf=80, max_depth=None, n_estimators=90, score=0.909754, total=  52.7s\n",
      "[CV] min_samples_leaf=90, max_depth=None, n_estimators=80 ............\n",
      "[CV]  min_samples_leaf=80, max_depth=None, n_estimators=90, score=0.898321, total=  52.4s\n",
      "[CV] min_samples_leaf=90, max_depth=None, n_estimators=80 ............\n",
      "[CV]  min_samples_leaf=80, max_depth=None, n_estimators=90, score=0.910012, total=  54.8s\n",
      "[CV] min_samples_leaf=90, max_depth=None, n_estimators=90 ............\n",
      "[CV]  min_samples_leaf=80, max_depth=None, n_estimators=90, score=0.902328, total=  56.5s\n",
      "[CV]  min_samples_leaf=80, max_depth=None, n_estimators=90, score=0.898778, total=  55.1s\n",
      "[CV] min_samples_leaf=90, max_depth=None, n_estimators=90 ............\n",
      "[CV] min_samples_leaf=90, max_depth=None, n_estimators=90 ............\n",
      "[CV]  min_samples_leaf=90, max_depth=None, n_estimators=80, score=0.903755, total=  42.7s\n",
      "[CV] min_samples_leaf=90, max_depth=None, n_estimators=90 ............\n",
      "[CV]  min_samples_leaf=90, max_depth=None, n_estimators=80, score=0.893460, total=  42.9s\n",
      "[CV] min_samples_leaf=90, max_depth=None, n_estimators=90 ............\n",
      "[CV]  min_samples_leaf=90, max_depth=None, n_estimators=80, score=0.909500, total=  44.2s\n",
      "[CV] min_samples_leaf=50, max_depth=2, n_estimators=80 ...............\n",
      "[CV]  min_samples_leaf=90, max_depth=None, n_estimators=80, score=0.901512, total=  44.2s\n",
      "[CV] min_samples_leaf=50, max_depth=2, n_estimators=80 ...............\n",
      "[CV]  min_samples_leaf=90, max_depth=None, n_estimators=80, score=0.894830, total=  43.8s\n",
      "[CV] min_samples_leaf=50, max_depth=2, n_estimators=80 ...............\n",
      "[CV]  min_samples_leaf=50, max_depth=2, n_estimators=80, score=0.871108, total=  10.6s\n",
      "[CV] min_samples_leaf=50, max_depth=2, n_estimators=80 ...............\n",
      "[CV]  min_samples_leaf=90, max_depth=None, n_estimators=90, score=0.906251, total=  47.7s\n",
      "[CV] min_samples_leaf=50, max_depth=2, n_estimators=80 ...............\n",
      "[CV]  min_samples_leaf=50, max_depth=2, n_estimators=80, score=0.865103, total=  11.4s\n",
      "[CV]  min_samples_leaf=90, max_depth=None, n_estimators=90, score=0.894237, total=  48.1s\n",
      "[CV] min_samples_leaf=50, max_depth=2, n_estimators=90 ...............\n",
      "[CV]  min_samples_leaf=50, max_depth=2, n_estimators=80, score=0.872503, total=  11.8s\n",
      "[CV] min_samples_leaf=50, max_depth=2, n_estimators=90 ...............\n",
      "[CV]  min_samples_leaf=90, max_depth=None, n_estimators=90, score=0.909133, total=  49.4s\n",
      "[CV] min_samples_leaf=50, max_depth=2, n_estimators=90 ...............\n",
      "[CV]  min_samples_leaf=50, max_depth=2, n_estimators=80, score=0.880388, total=  11.3s\n",
      "[CV] min_samples_leaf=50, max_depth=2, n_estimators=90 ...............\n",
      "[CV] min_samples_leaf=50, max_depth=2, n_estimators=90 ...............\n",
      "[CV]  min_samples_leaf=50, max_depth=2, n_estimators=80, score=0.864897, total=  10.1s\n",
      "[CV] min_samples_leaf=60, max_depth=2, n_estimators=80 ...............\n",
      "[CV]  min_samples_leaf=50, max_depth=2, n_estimators=90, score=0.884698, total=  11.8s\n",
      "[CV] min_samples_leaf=60, max_depth=2, n_estimators=80 ...............\n",
      "[CV]  min_samples_leaf=50, max_depth=2, n_estimators=90, score=0.875299, total=  12.5s\n",
      "[CV] min_samples_leaf=60, max_depth=2, n_estimators=80 ...............\n",
      "[CV]  min_samples_leaf=90, max_depth=None, n_estimators=90, score=0.903864, total=  47.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  56 tasks      | elapsed:  6.5min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] min_samples_leaf=60, max_depth=2, n_estimators=80 ...............\n",
      "[CV]  min_samples_leaf=50, max_depth=2, n_estimators=90, score=0.888650, total=  13.9s\n",
      "[CV] min_samples_leaf=60, max_depth=2, n_estimators=80 ...............\n",
      "[CV]  min_samples_leaf=50, max_depth=2, n_estimators=90, score=0.881583, total=  15.6s\n",
      "[CV] min_samples_leaf=60, max_depth=2, n_estimators=90 ...............\n",
      "[CV]  min_samples_leaf=50, max_depth=2, n_estimators=90, score=0.872572, total=  15.7s\n",
      "[CV]  min_samples_leaf=60, max_depth=2, n_estimators=80, score=0.878244, total=  13.6s\n",
      "[CV] min_samples_leaf=60, max_depth=2, n_estimators=90 ...............\n",
      "[CV]  min_samples_leaf=90, max_depth=None, n_estimators=90, score=0.894899, total=  47.9s\n",
      "[CV] min_samples_leaf=60, max_depth=2, n_estimators=90 ...............\n",
      "[CV]  min_samples_leaf=60, max_depth=2, n_estimators=80, score=0.869451, total=  12.6s\n",
      "[CV] min_samples_leaf=60, max_depth=2, n_estimators=90 ...............\n",
      "[CV]  min_samples_leaf=60, max_depth=2, n_estimators=80, score=0.881740, total=  12.2s\n",
      "[CV] min_samples_leaf=60, max_depth=2, n_estimators=90 ...............\n",
      "[CV]  min_samples_leaf=60, max_depth=2, n_estimators=80, score=0.880509, total=  11.6s\n",
      "[CV] min_samples_leaf=70, max_depth=2, n_estimators=80 ...............\n",
      "[CV]  min_samples_leaf=60, max_depth=2, n_estimators=80, score=0.862064, total=  10.8s\n",
      "[CV] min_samples_leaf=70, max_depth=2, n_estimators=80 ...............\n",
      "[CV]  min_samples_leaf=60, max_depth=2, n_estimators=90, score=0.884882, total=  11.2s\n",
      "[CV] min_samples_leaf=70, max_depth=2, n_estimators=80 ...............\n",
      "[CV]  min_samples_leaf=60, max_depth=2, n_estimators=90, score=0.876654, total=  10.9s\n",
      "[CV] min_samples_leaf=70, max_depth=2, n_estimators=80 ...............\n",
      "[CV]  min_samples_leaf=60, max_depth=2, n_estimators=90, score=0.885187, total=  10.8s\n",
      "[CV] min_samples_leaf=70, max_depth=2, n_estimators=80 ...............\n",
      "[CV]  min_samples_leaf=60, max_depth=2, n_estimators=90, score=0.882807, total=  10.4s\n",
      "[CV] min_samples_leaf=70, max_depth=2, n_estimators=90 ...............\n",
      "[CV]  min_samples_leaf=60, max_depth=2, n_estimators=90, score=0.878145, total=  10.6s\n",
      "[CV] min_samples_leaf=70, max_depth=2, n_estimators=90 ...............\n",
      "[CV]  min_samples_leaf=70, max_depth=2, n_estimators=80, score=0.876165, total=   9.8s\n",
      "[CV] min_samples_leaf=70, max_depth=2, n_estimators=90 ...............\n",
      "[CV]  min_samples_leaf=70, max_depth=2, n_estimators=80, score=0.869360, total=   9.6s\n",
      "[CV] min_samples_leaf=70, max_depth=2, n_estimators=90 ...............\n",
      "[CV]  min_samples_leaf=70, max_depth=2, n_estimators=80, score=0.886892, total=   9.2s\n",
      "[CV] min_samples_leaf=70, max_depth=2, n_estimators=90 ...............\n",
      "[CV]  min_samples_leaf=70, max_depth=2, n_estimators=80, score=0.866324, total=   9.5s\n",
      "[CV] min_samples_leaf=80, max_depth=2, n_estimators=80 ...............\n",
      "[CV]  min_samples_leaf=70, max_depth=2, n_estimators=80, score=0.870058, total=   9.4s\n",
      "[CV] min_samples_leaf=80, max_depth=2, n_estimators=80 ...............\n",
      "[CV]  min_samples_leaf=70, max_depth=2, n_estimators=90, score=0.885941, total=   9.8s\n",
      "[CV] min_samples_leaf=80, max_depth=2, n_estimators=80 ...............\n",
      "[CV]  min_samples_leaf=70, max_depth=2, n_estimators=90, score=0.867734, total=   9.7s\n",
      "[CV] min_samples_leaf=80, max_depth=2, n_estimators=80 ...............\n",
      "[CV]  min_samples_leaf=70, max_depth=2, n_estimators=90, score=0.879665, total=   9.7s\n",
      "[CV] min_samples_leaf=80, max_depth=2, n_estimators=80 ...............\n",
      "[CV]  min_samples_leaf=70, max_depth=2, n_estimators=90, score=0.876645, total=   9.5s\n",
      "[CV] min_samples_leaf=80, max_depth=2, n_estimators=90 ...............\n",
      "[CV]  min_samples_leaf=70, max_depth=2, n_estimators=90, score=0.877641, total=   9.8s\n",
      "[CV] min_samples_leaf=80, max_depth=2, n_estimators=90 ...............\n",
      "[CV]  min_samples_leaf=80, max_depth=2, n_estimators=80, score=0.875803, total=   9.1s\n",
      "[CV] min_samples_leaf=80, max_depth=2, n_estimators=90 ...............\n",
      "[CV]  min_samples_leaf=80, max_depth=2, n_estimators=80, score=0.876531, total=   9.5s\n",
      "[CV] min_samples_leaf=80, max_depth=2, n_estimators=90 ...............\n",
      "[CV]  min_samples_leaf=80, max_depth=2, n_estimators=80, score=0.867115, total=   9.7s\n",
      "[CV] min_samples_leaf=80, max_depth=2, n_estimators=90 ...............\n",
      "[CV]  min_samples_leaf=80, max_depth=2, n_estimators=80, score=0.867239, total=   9.6s\n",
      "[CV] min_samples_leaf=90, max_depth=2, n_estimators=80 ...............\n",
      "[CV]  min_samples_leaf=80, max_depth=2, n_estimators=80, score=0.876925, total=   9.4s\n",
      "[CV] min_samples_leaf=90, max_depth=2, n_estimators=80 ...............\n",
      "[CV]  min_samples_leaf=80, max_depth=2, n_estimators=90, score=0.868347, total=   9.6s\n",
      "[CV] min_samples_leaf=90, max_depth=2, n_estimators=80 ...............\n",
      "[CV]  min_samples_leaf=80, max_depth=2, n_estimators=90, score=0.870884, total=   9.5s\n",
      "[CV] min_samples_leaf=90, max_depth=2, n_estimators=80 ...............\n",
      "[CV]  min_samples_leaf=80, max_depth=2, n_estimators=90, score=0.873456, total=   9.4s\n",
      "[CV] min_samples_leaf=90, max_depth=2, n_estimators=80 ...............\n",
      "[CV]  min_samples_leaf=80, max_depth=2, n_estimators=90, score=0.869561, total=   9.1s\n",
      "[CV] min_samples_leaf=90, max_depth=2, n_estimators=90 ...............\n",
      "[CV]  min_samples_leaf=80, max_depth=2, n_estimators=90, score=0.866666, total=   9.3s\n",
      "[CV] min_samples_leaf=90, max_depth=2, n_estimators=90 ...............\n",
      "[CV]  min_samples_leaf=90, max_depth=2, n_estimators=80, score=0.885620, total=   8.7s\n",
      "[CV] min_samples_leaf=90, max_depth=2, n_estimators=90 ...............\n",
      "[CV]  min_samples_leaf=90, max_depth=2, n_estimators=80, score=0.865589, total=   8.6s\n",
      "[CV]  min_samples_leaf=90, max_depth=2, n_estimators=80, score=0.868165, total=   8.4s\n",
      "[CV] min_samples_leaf=90, max_depth=2, n_estimators=90 ...............\n",
      "[CV]  min_samples_leaf=90, max_depth=2, n_estimators=80, score=0.875664, total=   8.5s\n",
      "[CV] min_samples_leaf=90, max_depth=2, n_estimators=90 ...............\n",
      "[CV]  min_samples_leaf=90, max_depth=2, n_estimators=80, score=0.872400, total=   8.3s\n",
      "[CV] min_samples_leaf=50, max_depth=5, n_estimators=80 ...............\n",
      "[CV] min_samples_leaf=50, max_depth=5, n_estimators=80 ...............\n",
      "[CV]  min_samples_leaf=90, max_depth=2, n_estimators=90, score=0.871241, total=   9.0s\n",
      "[CV] min_samples_leaf=50, max_depth=5, n_estimators=80 ...............\n",
      "[CV]  min_samples_leaf=90, max_depth=2, n_estimators=90, score=0.879748, total=   8.9s\n",
      "[CV] min_samples_leaf=50, max_depth=5, n_estimators=80 ...............\n",
      "[CV]  min_samples_leaf=90, max_depth=2, n_estimators=90, score=0.890727, total=   9.1s\n",
      "[CV] min_samples_leaf=50, max_depth=5, n_estimators=80 ...............\n",
      "[CV]  min_samples_leaf=90, max_depth=2, n_estimators=90, score=0.883880, total=   9.8s\n",
      "[CV] min_samples_leaf=50, max_depth=5, n_estimators=90 ...............\n",
      "[CV]  min_samples_leaf=90, max_depth=2, n_estimators=90, score=0.876032, total=  10.2s\n",
      "[CV] min_samples_leaf=50, max_depth=5, n_estimators=90 ...............\n",
      "[CV] min_samples_leaf=50, max_depth=5, n_estimators=90 ...............\n",
      "[CV]  min_samples_leaf=50, max_depth=5, n_estimators=80, score=0.896491, total=  18.8s\n",
      "[CV] min_samples_leaf=50, max_depth=5, n_estimators=90 ...............\n",
      "[CV]  min_samples_leaf=50, max_depth=5, n_estimators=80, score=0.890286, total=  20.1s\n",
      "[CV] min_samples_leaf=50, max_depth=5, n_estimators=90 ...............\n",
      "[CV]  min_samples_leaf=50, max_depth=5, n_estimators=80, score=0.899375, total=  20.2s\n",
      "[CV] min_samples_leaf=60, max_depth=5, n_estimators=80 ...............\n",
      "[CV]  min_samples_leaf=50, max_depth=5, n_estimators=80, score=0.890180, total=  20.6s\n",
      "[CV] min_samples_leaf=60, max_depth=5, n_estimators=80 ...............\n",
      "[CV]  min_samples_leaf=50, max_depth=5, n_estimators=80, score=0.893258, total=  20.7s\n",
      "[CV] min_samples_leaf=60, max_depth=5, n_estimators=80 ...............\n",
      "[CV]  min_samples_leaf=50, max_depth=5, n_estimators=90, score=0.895399, total=  22.8s\n",
      "[CV] min_samples_leaf=60, max_depth=5, n_estimators=80 ...............\n",
      "[CV]  min_samples_leaf=50, max_depth=5, n_estimators=90, score=0.894367, total=  24.0s\n",
      "[CV] min_samples_leaf=60, max_depth=5, n_estimators=80 ...............\n",
      "[CV]  min_samples_leaf=50, max_depth=5, n_estimators=90, score=0.897475, total=  23.9s\n",
      "[CV] min_samples_leaf=60, max_depth=5, n_estimators=90 ...............\n",
      "[CV]  min_samples_leaf=50, max_depth=5, n_estimators=90, score=0.893317, total=  21.6s\n",
      "[CV] min_samples_leaf=60, max_depth=5, n_estimators=90 ...............\n",
      "[CV]  min_samples_leaf=50, max_depth=5, n_estimators=90, score=0.897998, total=  22.0s\n",
      "[CV]  min_samples_leaf=60, max_depth=5, n_estimators=80, score=0.891715, total=  20.3s\n",
      "[CV] min_samples_leaf=60, max_depth=5, n_estimators=90 ...............\n",
      "[CV] min_samples_leaf=60, max_depth=5, n_estimators=90 ...............\n",
      "[CV]  min_samples_leaf=60, max_depth=5, n_estimators=80, score=0.891585, total=  21.1s\n",
      "[CV] min_samples_leaf=60, max_depth=5, n_estimators=90 ...............\n",
      "[CV]  min_samples_leaf=60, max_depth=5, n_estimators=80, score=0.902095, total=  20.0s\n",
      "[CV] min_samples_leaf=70, max_depth=5, n_estimators=80 ...............\n",
      "[CV]  min_samples_leaf=60, max_depth=5, n_estimators=80, score=0.893759, total=  19.8s\n",
      "[CV] min_samples_leaf=70, max_depth=5, n_estimators=80 ...............\n",
      "[CV]  min_samples_leaf=60, max_depth=5, n_estimators=80, score=0.892909, total=  20.4s\n",
      "[CV] min_samples_leaf=70, max_depth=5, n_estimators=80 ...............\n",
      "[CV]  min_samples_leaf=60, max_depth=5, n_estimators=90, score=0.902482, total=  22.3s\n",
      "[CV] min_samples_leaf=70, max_depth=5, n_estimators=80 ...............\n",
      "[CV]  min_samples_leaf=60, max_depth=5, n_estimators=90, score=0.889804, total=  22.3s\n",
      "[CV] min_samples_leaf=70, max_depth=5, n_estimators=80 ...............\n",
      "[CV]  min_samples_leaf=60, max_depth=5, n_estimators=90, score=0.900834, total=  23.4s\n",
      "[CV] min_samples_leaf=70, max_depth=5, n_estimators=90 ...............\n",
      "[CV]  min_samples_leaf=60, max_depth=5, n_estimators=90, score=0.896394, total=  23.3s\n",
      "[CV] min_samples_leaf=70, max_depth=5, n_estimators=90 ...............\n",
      "[CV]  min_samples_leaf=70, max_depth=5, n_estimators=80, score=0.897386, total=  21.1s\n",
      "[CV]  min_samples_leaf=60, max_depth=5, n_estimators=90, score=0.896616, total=  23.1s\n",
      "[CV] min_samples_leaf=70, max_depth=5, n_estimators=90 ...............\n",
      "[CV] min_samples_leaf=70, max_depth=5, n_estimators=90 ...............\n",
      "[CV]  min_samples_leaf=70, max_depth=5, n_estimators=80, score=0.893369, total=  21.0s\n",
      "[CV] min_samples_leaf=70, max_depth=5, n_estimators=90 ...............\n",
      "[CV]  min_samples_leaf=70, max_depth=5, n_estimators=80, score=0.896994, total=  20.3s\n",
      "[CV] min_samples_leaf=80, max_depth=5, n_estimators=80 ...............\n",
      "[CV]  min_samples_leaf=70, max_depth=5, n_estimators=80, score=0.892548, total=  18.8s\n",
      "[CV] min_samples_leaf=80, max_depth=5, n_estimators=80 ...............\n",
      "[CV]  min_samples_leaf=70, max_depth=5, n_estimators=80, score=0.896902, total=  17.8s\n",
      "[CV] min_samples_leaf=80, max_depth=5, n_estimators=80 ...............\n",
      "[CV]  min_samples_leaf=70, max_depth=5, n_estimators=90, score=0.901610, total=  20.9s\n",
      "[CV] min_samples_leaf=80, max_depth=5, n_estimators=80 ...............\n",
      "[CV]  min_samples_leaf=70, max_depth=5, n_estimators=90, score=0.892537, total=  20.5s\n",
      "[CV] min_samples_leaf=80, max_depth=5, n_estimators=80 ...............\n",
      "[CV]  min_samples_leaf=70, max_depth=5, n_estimators=90, score=0.901859, total=  20.5s\n",
      "[CV] min_samples_leaf=80, max_depth=5, n_estimators=90 ...............\n",
      "[CV]  min_samples_leaf=70, max_depth=5, n_estimators=90, score=0.899625, total=  21.1s\n",
      "[CV] min_samples_leaf=80, max_depth=5, n_estimators=90 ...............\n",
      "[CV]  min_samples_leaf=80, max_depth=5, n_estimators=80, score=0.900031, total=  19.5s\n",
      "[CV]  min_samples_leaf=70, max_depth=5, n_estimators=90, score=0.883550, total=  21.4s\n",
      "[CV] min_samples_leaf=80, max_depth=5, n_estimators=90 ...............\n",
      "[CV]  min_samples_leaf=80, max_depth=5, n_estimators=80, score=0.883345, total=  19.4s\n",
      "[CV] min_samples_leaf=80, max_depth=5, n_estimators=90 ...............\n",
      "[CV] min_samples_leaf=80, max_depth=5, n_estimators=90 ...............\n",
      "[CV]  min_samples_leaf=80, max_depth=5, n_estimators=80, score=0.902914, total=  19.3s\n",
      "[CV] min_samples_leaf=90, max_depth=5, n_estimators=80 ...............\n",
      "[CV]  min_samples_leaf=80, max_depth=5, n_estimators=80, score=0.890998, total=  18.7s\n",
      "[CV] min_samples_leaf=90, max_depth=5, n_estimators=80 ...............\n",
      "[CV]  min_samples_leaf=80, max_depth=5, n_estimators=80, score=0.889858, total=  19.6s\n",
      "[CV] min_samples_leaf=90, max_depth=5, n_estimators=80 ...............\n",
      "[CV]  min_samples_leaf=80, max_depth=5, n_estimators=90, score=0.898346, total=  22.1s\n",
      "[CV] min_samples_leaf=90, max_depth=5, n_estimators=80 ...............\n",
      "[CV]  min_samples_leaf=80, max_depth=5, n_estimators=90, score=0.890866, total=  22.9s\n",
      "[CV] min_samples_leaf=90, max_depth=5, n_estimators=80 ...............\n",
      "[CV]  min_samples_leaf=80, max_depth=5, n_estimators=90, score=0.893422, total=  22.5s\n",
      "[CV] min_samples_leaf=90, max_depth=5, n_estimators=90 ...............\n",
      "[CV]  min_samples_leaf=80, max_depth=5, n_estimators=90, score=0.895593, total=  22.8s\n",
      "[CV] min_samples_leaf=90, max_depth=5, n_estimators=90 ...............\n",
      "[CV]  min_samples_leaf=80, max_depth=5, n_estimators=90, score=0.886340, total=  22.8s\n",
      "[CV] min_samples_leaf=90, max_depth=5, n_estimators=90 ...............\n",
      "[CV]  min_samples_leaf=90, max_depth=5, n_estimators=80, score=0.897462, total=  20.4s\n",
      "[CV] min_samples_leaf=90, max_depth=5, n_estimators=90 ...............\n",
      "[CV]  min_samples_leaf=90, max_depth=5, n_estimators=80, score=0.874002, total=  18.5s\n",
      "[CV] min_samples_leaf=90, max_depth=5, n_estimators=90 ...............\n",
      "[CV]  min_samples_leaf=90, max_depth=5, n_estimators=80, score=0.895158, total=  18.2s\n",
      "[CV] min_samples_leaf=50, max_depth=10, n_estimators=80 ..............\n",
      "[CV]  min_samples_leaf=90, max_depth=5, n_estimators=80, score=0.883691, total=  18.1s\n",
      "[CV] min_samples_leaf=50, max_depth=10, n_estimators=80 ..............\n",
      "[CV]  min_samples_leaf=90, max_depth=5, n_estimators=80, score=0.884153, total=  18.3s\n",
      "[CV] min_samples_leaf=50, max_depth=10, n_estimators=80 ..............\n",
      "[CV]  min_samples_leaf=90, max_depth=5, n_estimators=90, score=0.887273, total=  20.8s\n",
      "[CV] min_samples_leaf=50, max_depth=10, n_estimators=80 ..............\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 146 tasks      | elapsed: 10.0min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  min_samples_leaf=90, max_depth=5, n_estimators=90, score=0.884920, total=  21.6s\n",
      "[CV] min_samples_leaf=50, max_depth=10, n_estimators=80 ..............\n",
      "[CV]  min_samples_leaf=90, max_depth=5, n_estimators=90, score=0.887111, total=  21.8s\n",
      "[CV] min_samples_leaf=50, max_depth=10, n_estimators=90 ..............\n",
      "[CV]  min_samples_leaf=90, max_depth=5, n_estimators=90, score=0.891011, total=  21.4s\n",
      "[CV] min_samples_leaf=50, max_depth=10, n_estimators=90 ..............\n",
      "[CV]  min_samples_leaf=90, max_depth=5, n_estimators=90, score=0.886272, total=  21.5s\n",
      "[CV] min_samples_leaf=50, max_depth=10, n_estimators=90 ..............\n",
      "[CV]  min_samples_leaf=50, max_depth=10, n_estimators=80, score=0.903256, total=  32.2s\n",
      "[CV] min_samples_leaf=50, max_depth=10, n_estimators=90 ..............\n",
      "[CV]  min_samples_leaf=50, max_depth=10, n_estimators=80, score=0.896181, total=  32.5s\n",
      "[CV] min_samples_leaf=50, max_depth=10, n_estimators=90 ..............\n",
      "[CV]  min_samples_leaf=50, max_depth=10, n_estimators=80, score=0.899464, total=  32.6s\n",
      "[CV] min_samples_leaf=60, max_depth=10, n_estimators=80 ..............\n",
      "[CV]  min_samples_leaf=50, max_depth=10, n_estimators=80, score=0.903189, total=  33.7s\n",
      "[CV] min_samples_leaf=60, max_depth=10, n_estimators=80 ..............\n",
      "[CV]  min_samples_leaf=50, max_depth=10, n_estimators=80, score=0.891821, total=  33.1s\n",
      "[CV] min_samples_leaf=60, max_depth=10, n_estimators=80 ..............\n",
      "[CV]  min_samples_leaf=50, max_depth=10, n_estimators=90, score=0.907369, total=  37.1s\n",
      "[CV] min_samples_leaf=60, max_depth=10, n_estimators=80 ..............\n",
      "[CV]  min_samples_leaf=50, max_depth=10, n_estimators=90, score=0.892337, total=  36.5s\n",
      "[CV] min_samples_leaf=60, max_depth=10, n_estimators=80 ..............\n",
      "[CV]  min_samples_leaf=50, max_depth=10, n_estimators=90, score=0.905833, total=  36.6s\n",
      "[CV] min_samples_leaf=60, max_depth=10, n_estimators=90 ..............\n",
      "[CV]  min_samples_leaf=50, max_depth=10, n_estimators=90, score=0.903433, total=  34.5s\n",
      "[CV] min_samples_leaf=60, max_depth=10, n_estimators=90 ..............\n",
      "[CV]  min_samples_leaf=60, max_depth=10, n_estimators=80, score=0.904246, total=  30.6s\n",
      "[CV]  min_samples_leaf=50, max_depth=10, n_estimators=90, score=0.894964, total=  33.7s\n",
      "[CV] min_samples_leaf=60, max_depth=10, n_estimators=90 ..............\n",
      "[CV] min_samples_leaf=60, max_depth=10, n_estimators=90 ..............\n",
      "[CV]  min_samples_leaf=60, max_depth=10, n_estimators=80, score=0.896303, total=  29.5s\n",
      "[CV] min_samples_leaf=60, max_depth=10, n_estimators=90 ..............\n",
      "[CV]  min_samples_leaf=60, max_depth=10, n_estimators=80, score=0.908222, total=  30.0s\n",
      "[CV] min_samples_leaf=70, max_depth=10, n_estimators=80 ..............\n",
      "[CV]  min_samples_leaf=60, max_depth=10, n_estimators=80, score=0.899353, total=  30.5s\n",
      "[CV] min_samples_leaf=70, max_depth=10, n_estimators=80 ..............\n",
      "[CV]  min_samples_leaf=60, max_depth=10, n_estimators=80, score=0.896114, total=  31.0s\n",
      "[CV] min_samples_leaf=70, max_depth=10, n_estimators=80 ..............\n",
      "[CV]  min_samples_leaf=60, max_depth=10, n_estimators=90, score=0.904439, total=  34.5s\n",
      "[CV] min_samples_leaf=70, max_depth=10, n_estimators=80 ..............\n",
      "[CV]  min_samples_leaf=60, max_depth=10, n_estimators=90, score=0.900057, total=  36.1s\n",
      "[CV] min_samples_leaf=70, max_depth=10, n_estimators=80 ..............\n",
      "[CV]  min_samples_leaf=60, max_depth=10, n_estimators=90, score=0.904322, total=  37.8s\n",
      "[CV] min_samples_leaf=70, max_depth=10, n_estimators=90 ..............\n",
      "[CV]  min_samples_leaf=60, max_depth=10, n_estimators=90, score=0.905677, total=  37.6s\n",
      "[CV] min_samples_leaf=70, max_depth=10, n_estimators=90 ..............\n",
      "[CV]  min_samples_leaf=70, max_depth=10, n_estimators=80, score=0.896446, total=  33.9s\n",
      "[CV] min_samples_leaf=70, max_depth=10, n_estimators=90 ..............\n",
      "[CV]  min_samples_leaf=60, max_depth=10, n_estimators=90, score=0.897595, total=  37.6s\n",
      "[CV] min_samples_leaf=70, max_depth=10, n_estimators=90 ..............\n",
      "[CV]  min_samples_leaf=70, max_depth=10, n_estimators=80, score=0.899156, total=  32.6s\n",
      "[CV] min_samples_leaf=70, max_depth=10, n_estimators=90 ..............\n",
      "[CV]  min_samples_leaf=70, max_depth=10, n_estimators=80, score=0.904365, total=  33.1s\n",
      "[CV] min_samples_leaf=80, max_depth=10, n_estimators=80 ..............\n",
      "[CV]  min_samples_leaf=70, max_depth=10, n_estimators=80, score=0.894508, total=  31.9s\n",
      "[CV] min_samples_leaf=80, max_depth=10, n_estimators=80 ..............\n",
      "[CV]  min_samples_leaf=70, max_depth=10, n_estimators=80, score=0.900993, total=  32.3s\n",
      "[CV] min_samples_leaf=80, max_depth=10, n_estimators=80 ..............\n",
      "[CV]  min_samples_leaf=70, max_depth=10, n_estimators=90, score=0.907656, total=  35.9s\n",
      "[CV] min_samples_leaf=80, max_depth=10, n_estimators=80 ..............\n",
      "[CV]  min_samples_leaf=70, max_depth=10, n_estimators=90, score=0.894244, total=  36.4s\n",
      "[CV] min_samples_leaf=80, max_depth=10, n_estimators=80 ..............\n",
      "[CV]  min_samples_leaf=70, max_depth=10, n_estimators=90, score=0.908999, total=  37.4s\n",
      "[CV] min_samples_leaf=80, max_depth=10, n_estimators=90 ..............\n",
      "[CV]  min_samples_leaf=70, max_depth=10, n_estimators=90, score=0.897425, total=  37.1s\n",
      "[CV] min_samples_leaf=80, max_depth=10, n_estimators=90 ..............\n",
      "[CV]  min_samples_leaf=80, max_depth=10, n_estimators=80, score=0.905854, total=  33.4s\n",
      "[CV] min_samples_leaf=80, max_depth=10, n_estimators=90 ..............\n",
      "[CV]  min_samples_leaf=70, max_depth=10, n_estimators=90, score=0.892964, total=  36.5s\n",
      "[CV] min_samples_leaf=80, max_depth=10, n_estimators=90 ..............\n",
      "[CV]  min_samples_leaf=80, max_depth=10, n_estimators=80, score=0.896348, total=  32.4s\n",
      "[CV] min_samples_leaf=80, max_depth=10, n_estimators=90 ..............\n",
      "[CV]  min_samples_leaf=80, max_depth=10, n_estimators=80, score=0.901011, total=  34.0s\n",
      "[CV] min_samples_leaf=90, max_depth=10, n_estimators=80 ..............\n",
      "[CV]  min_samples_leaf=80, max_depth=10, n_estimators=80, score=0.894442, total=  35.8s\n",
      "[CV] min_samples_leaf=90, max_depth=10, n_estimators=80 ..............\n",
      "[CV]  min_samples_leaf=80, max_depth=10, n_estimators=80, score=0.893652, total=  34.6s\n",
      "[CV] min_samples_leaf=90, max_depth=10, n_estimators=80 ..............\n",
      "[CV]  min_samples_leaf=80, max_depth=10, n_estimators=90, score=0.899762, total=  38.2s\n",
      "[CV] min_samples_leaf=90, max_depth=10, n_estimators=80 ..............\n",
      "[CV]  min_samples_leaf=80, max_depth=10, n_estimators=90, score=0.901034, total=  38.2s\n",
      "[CV] min_samples_leaf=90, max_depth=10, n_estimators=80 ..............\n",
      "[CV]  min_samples_leaf=80, max_depth=10, n_estimators=90, score=0.905534, total=  38.2s\n",
      "[CV] min_samples_leaf=90, max_depth=10, n_estimators=90 ..............\n",
      "[CV]  min_samples_leaf=80, max_depth=10, n_estimators=90, score=0.899171, total=  38.3s\n",
      "[CV] min_samples_leaf=90, max_depth=10, n_estimators=90 ..............\n",
      "[CV]  min_samples_leaf=80, max_depth=10, n_estimators=90, score=0.898734, total=  36.3s\n",
      "[CV] min_samples_leaf=90, max_depth=10, n_estimators=90 ..............\n",
      "[CV]  min_samples_leaf=90, max_depth=10, n_estimators=80, score=0.900575, total=  29.2s\n",
      "[CV] min_samples_leaf=90, max_depth=10, n_estimators=90 ..............\n",
      "[CV]  min_samples_leaf=90, max_depth=10, n_estimators=80, score=0.893332, total=  29.3s\n",
      "[CV] min_samples_leaf=90, max_depth=10, n_estimators=90 ..............\n",
      "[CV]  min_samples_leaf=90, max_depth=10, n_estimators=80, score=0.904443, total=  29.5s\n",
      "[CV]  min_samples_leaf=90, max_depth=10, n_estimators=80, score=0.895053, total=  30.3s\n",
      "[CV]  min_samples_leaf=90, max_depth=10, n_estimators=80, score=0.892102, total=  30.3s\n",
      "[CV]  min_samples_leaf=90, max_depth=10, n_estimators=90, score=0.899572, total=  32.5s\n",
      "[CV]  min_samples_leaf=90, max_depth=10, n_estimators=90, score=0.898729, total=  32.2s\n",
      "[CV]  min_samples_leaf=90, max_depth=10, n_estimators=90, score=0.905577, total=  31.2s\n",
      "[CV]  min_samples_leaf=90, max_depth=10, n_estimators=90, score=0.900515, total=  29.0s\n",
      "[CV]  min_samples_leaf=90, max_depth=10, n_estimators=90, score=0.899474, total=  23.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 200 out of 200 | elapsed: 13.8min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "            n_estimators=10, n_jobs=1, oob_score=False, random_state=None,\n",
       "            verbose=0, warm_start=False),\n",
       "       fit_params={}, iid=True, n_jobs=-1,\n",
       "       param_grid={'min_samples_leaf': range(50, 100, 10), 'max_depth': [None, 2, 5, 10], 'n_estimators': range(80, 100, 10)},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       scoring='roc_auc', verbose=5)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_clf5 = GridSearchCV(rf, param_grid=  param_grid, verbose = 5, scoring = 'roc_auc' ,cv = 5 , n_jobs = -1 )\n",
    "rf_clf5.fit(X5_tr , y_tr )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_split=1e-07, min_samples_leaf=70,\n",
       "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "            n_estimators=90, n_jobs=1, oob_score=False, random_state=None,\n",
       "            verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_clf5.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "\n",
    "M5 = RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
    "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
    "            min_impurity_split=1e-07, min_samples_leaf=70,\n",
    "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
    "            n_estimators=90, n_jobs=1, oob_score=False, random_state=None,\n",
    "            verbose=0, warm_start=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "M5.fit(X5_tr , y_tr)\n",
    "y_pred5 = M5.predict_proba(X5_ts)[:,1]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "\n",
    "fpr5, tpr5, _ = roc_curve(y_ts ,y_pred5 )\n",
    "\n",
    "score5 = auc(fpr5, tpr5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYoAAAEWCAYAAAB42tAoAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nOReRJwrnnHMR/T+0CETv+/vcOQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2882b31d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ROC_plotter( (fpr5, tpr5, score5), name = \"X5\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Kaggle submissions\n",
    "\n",
    "Predicting y values based on the Kaggle test sets.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken for X1 predictions:  716.4940731525421 seconds.\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "y_score1 = rf_clf1.fit(X1, y).predict(X1_test)\n",
    "\n",
    "\n",
    "\n",
    "# Get the end time and print how long the process took\n",
    "end = time.time()\n",
    "elapsed = end - start\n",
    "print (\"Time taken for X1 predictions: \", elapsed, \"seconds.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken for X2 predictions:  667.0361881256104 seconds.\n"
     ]
    }
   ],
   "source": [
    "start =  time.time()\n",
    "y_score2 = rf_clf2.fit(X2, y).predict(X2_test)\n",
    "\n",
    "\n",
    "# Get the end time and print how long the process took\n",
    "end = time.time()\n",
    "elapsed = end - start\n",
    "print (\"Time taken for X2 predictions: \", elapsed, \"seconds.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken for X3 predictions:  1659.5089130401611 seconds.\n"
     ]
    }
   ],
   "source": [
    "start =  time.time()\n",
    "y_score3 = rf_clf3.fit(X3, y).predict(X3_test)\n",
    "\n",
    "\n",
    "# Get the end time and print how long the process took\n",
    "end = time.time()\n",
    "elapsed = end - start\n",
    "print (\"Time taken for X3 predictions: \", elapsed, \"seconds.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken for X4 predictions:  1646.3665499687195 seconds.\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "y_score4 = rf_clf4.fit(X4, y).predict(X4_test)\n",
    "\n",
    "\n",
    "# Get the end time and print how long the process took\n",
    "end = time.time()\n",
    "elapsed = end - start\n",
    "print (\"Time taken for X4 predictions: \", elapsed, \"seconds.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 40 candidates, totalling 200 fits\n",
      "[CV] min_samples_leaf=50, max_depth=None, n_estimators=80 ............\n",
      "[CV] min_samples_leaf=50, max_depth=None, n_estimators=80 ............\n",
      "[CV] min_samples_leaf=50, max_depth=None, n_estimators=80 ............\n",
      "[CV] min_samples_leaf=50, max_depth=None, n_estimators=80 ............\n",
      "[CV] min_samples_leaf=50, max_depth=None, n_estimators=80 ............\n",
      "[CV] min_samples_leaf=50, max_depth=None, n_estimators=90 ............\n",
      "[CV] min_samples_leaf=50, max_depth=None, n_estimators=90 ............\n",
      "[CV] min_samples_leaf=50, max_depth=None, n_estimators=90 ............\n",
      "[CV]  min_samples_leaf=50, max_depth=None, n_estimators=80, score=0.905636, total= 1.4min\n",
      "[CV]  min_samples_leaf=50, max_depth=None, n_estimators=80, score=0.911825, total= 1.4min\n",
      "[CV] min_samples_leaf=50, max_depth=None, n_estimators=90 ............\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:  1.5min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] min_samples_leaf=50, max_depth=None, n_estimators=90 ............\n",
      "[CV]  min_samples_leaf=50, max_depth=None, n_estimators=80, score=0.901735, total= 1.5min\n",
      "[CV] min_samples_leaf=60, max_depth=None, n_estimators=80 ............\n",
      "[CV]  min_samples_leaf=50, max_depth=None, n_estimators=80, score=0.913012, total= 1.5min\n",
      "[CV]  min_samples_leaf=50, max_depth=None, n_estimators=80, score=0.906887, total= 1.5min\n",
      "[CV] min_samples_leaf=60, max_depth=None, n_estimators=80 ............\n",
      "[CV] min_samples_leaf=60, max_depth=None, n_estimators=80 ............\n",
      "[CV]  min_samples_leaf=50, max_depth=None, n_estimators=90, score=0.906962, total= 1.6min\n",
      "[CV] min_samples_leaf=60, max_depth=None, n_estimators=80 ............\n",
      "[CV]  min_samples_leaf=50, max_depth=None, n_estimators=90, score=0.912808, total= 1.6min\n",
      "[CV] min_samples_leaf=60, max_depth=None, n_estimators=80 ............\n",
      "[CV]  min_samples_leaf=50, max_depth=None, n_estimators=90, score=0.902542, total= 1.5min\n",
      "[CV] min_samples_leaf=60, max_depth=None, n_estimators=90 ............\n",
      "[CV]  min_samples_leaf=60, max_depth=None, n_estimators=80, score=0.907233, total= 1.2min\n",
      "[CV] min_samples_leaf=60, max_depth=None, n_estimators=90 ............\n",
      "[CV]  min_samples_leaf=60, max_depth=None, n_estimators=80, score=0.912590, total= 1.2min\n",
      "[CV] min_samples_leaf=60, max_depth=None, n_estimators=90 ............\n",
      "[CV]  min_samples_leaf=50, max_depth=None, n_estimators=90, score=0.914954, total= 1.4min\n",
      "[CV]  min_samples_leaf=50, max_depth=None, n_estimators=90, score=0.908791, total= 1.4min\n",
      "[CV]  min_samples_leaf=60, max_depth=None, n_estimators=80, score=0.904958, total= 1.2min\n",
      "[CV] min_samples_leaf=60, max_depth=None, n_estimators=90 ............\n",
      "[CV] min_samples_leaf=60, max_depth=None, n_estimators=90 ............\n",
      "[CV] min_samples_leaf=70, max_depth=None, n_estimators=80 ............\n",
      "[CV]  min_samples_leaf=60, max_depth=None, n_estimators=80, score=0.914727, total= 1.2min\n",
      "[CV] min_samples_leaf=70, max_depth=None, n_estimators=80 ............\n",
      "[CV]  min_samples_leaf=60, max_depth=None, n_estimators=80, score=0.908403, total= 1.2min\n",
      "[CV] min_samples_leaf=70, max_depth=None, n_estimators=80 ............\n",
      "[CV]  min_samples_leaf=60, max_depth=None, n_estimators=90, score=0.907325, total= 1.3min\n",
      "[CV] min_samples_leaf=70, max_depth=None, n_estimators=80 ............\n",
      "[CV]  min_samples_leaf=70, max_depth=None, n_estimators=80, score=0.902000, total= 1.1min\n",
      "[CV] min_samples_leaf=70, max_depth=None, n_estimators=80 ............\n",
      "[CV]  min_samples_leaf=60, max_depth=None, n_estimators=90, score=0.910411, total= 1.3min\n",
      "[CV] min_samples_leaf=70, max_depth=None, n_estimators=90 ............\n",
      "[CV]  min_samples_leaf=70, max_depth=None, n_estimators=80, score=0.907725, total= 1.2min\n",
      "[CV] min_samples_leaf=70, max_depth=None, n_estimators=90 ............\n",
      "[CV]  min_samples_leaf=60, max_depth=None, n_estimators=90, score=0.900215, total= 1.3min\n",
      "[CV]  min_samples_leaf=70, max_depth=None, n_estimators=80, score=0.900418, total= 1.2min\n",
      "[CV] min_samples_leaf=70, max_depth=None, n_estimators=90 ............\n",
      "[CV]  min_samples_leaf=60, max_depth=None, n_estimators=90, score=0.914872, total= 1.4min\n",
      "[CV] min_samples_leaf=70, max_depth=None, n_estimators=90 ............\n",
      "[CV]  min_samples_leaf=60, max_depth=None, n_estimators=90, score=0.908330, total= 1.4min\n",
      "[CV] min_samples_leaf=70, max_depth=None, n_estimators=90 ............\n",
      "[CV] min_samples_leaf=80, max_depth=None, n_estimators=80 ............\n",
      "[CV]  min_samples_leaf=70, max_depth=None, n_estimators=80, score=0.911197, total= 1.2min\n",
      "[CV] min_samples_leaf=80, max_depth=None, n_estimators=80 ............\n",
      "[CV]  min_samples_leaf=70, max_depth=None, n_estimators=80, score=0.903377, total= 1.2min\n",
      "[CV] min_samples_leaf=80, max_depth=None, n_estimators=80 ............\n",
      "[CV]  min_samples_leaf=70, max_depth=None, n_estimators=90, score=0.906172, total= 1.3min\n",
      "[CV] min_samples_leaf=80, max_depth=None, n_estimators=80 ............\n",
      "[CV]  min_samples_leaf=80, max_depth=None, n_estimators=80, score=0.903707, total= 1.1min\n",
      "[CV] min_samples_leaf=80, max_depth=None, n_estimators=80 ............\n",
      "[CV]  min_samples_leaf=70, max_depth=None, n_estimators=90, score=0.910652, total= 1.3min\n",
      "[CV] min_samples_leaf=80, max_depth=None, n_estimators=90 ............\n",
      "[CV]  min_samples_leaf=80, max_depth=None, n_estimators=80, score=0.908111, total= 1.1min\n",
      "[CV]  min_samples_leaf=70, max_depth=None, n_estimators=90, score=0.900512, total= 1.3min\n",
      "[CV] min_samples_leaf=80, max_depth=None, n_estimators=90 ............\n",
      "[CV]  min_samples_leaf=70, max_depth=None, n_estimators=90, score=0.912741, total= 1.3min\n",
      "[CV] min_samples_leaf=80, max_depth=None, n_estimators=90 ............\n",
      "[CV]  min_samples_leaf=70, max_depth=None, n_estimators=90, score=0.902965, total= 1.3min\n",
      "[CV] min_samples_leaf=80, max_depth=None, n_estimators=90 ............\n",
      "[CV] min_samples_leaf=80, max_depth=None, n_estimators=90 ............\n",
      "[CV]  min_samples_leaf=80, max_depth=None, n_estimators=80, score=0.897499, total=  59.8s\n",
      "[CV] min_samples_leaf=90, max_depth=None, n_estimators=80 ............\n",
      "[CV]  min_samples_leaf=80, max_depth=None, n_estimators=80, score=0.907280, total=  59.3s\n",
      "[CV] min_samples_leaf=90, max_depth=None, n_estimators=80 ............\n",
      "[CV]  min_samples_leaf=80, max_depth=None, n_estimators=80, score=0.898576, total=  58.9s\n",
      "[CV] min_samples_leaf=90, max_depth=None, n_estimators=80 ............\n",
      "[CV]  min_samples_leaf=80, max_depth=None, n_estimators=90, score=0.900767, total= 1.1min\n",
      "[CV] min_samples_leaf=90, max_depth=None, n_estimators=80 ............\n",
      "[CV]  min_samples_leaf=80, max_depth=None, n_estimators=90, score=0.908115, total= 1.2min\n",
      "[CV] min_samples_leaf=90, max_depth=None, n_estimators=80 ............\n",
      "[CV]  min_samples_leaf=80, max_depth=None, n_estimators=90, score=0.897153, total= 1.2min\n",
      "[CV]  min_samples_leaf=80, max_depth=None, n_estimators=90, score=0.908376, total= 1.2min\n",
      "[CV] min_samples_leaf=90, max_depth=None, n_estimators=90 ............\n",
      "[CV]  min_samples_leaf=80, max_depth=None, n_estimators=90, score=0.899632, total= 1.2min\n",
      "[CV] min_samples_leaf=90, max_depth=None, n_estimators=90 ............\n",
      "[CV] min_samples_leaf=90, max_depth=None, n_estimators=90 ............\n",
      "[CV]  min_samples_leaf=90, max_depth=None, n_estimators=80, score=0.899855, total=  59.5s\n",
      "[CV] min_samples_leaf=90, max_depth=None, n_estimators=90 ............\n",
      "[CV]  min_samples_leaf=90, max_depth=None, n_estimators=80, score=0.908729, total=  59.6s\n",
      "[CV] min_samples_leaf=90, max_depth=None, n_estimators=90 ............\n",
      "[CV]  min_samples_leaf=90, max_depth=None, n_estimators=80, score=0.900790, total=  59.9s\n",
      "[CV] min_samples_leaf=50, max_depth=2, n_estimators=80 ...............\n",
      "[CV]  min_samples_leaf=90, max_depth=None, n_estimators=80, score=0.910652, total=  59.7s\n",
      "[CV] min_samples_leaf=50, max_depth=2, n_estimators=80 ...............\n",
      "[CV]  min_samples_leaf=50, max_depth=2, n_estimators=80, score=0.873079, total=  13.9s\n",
      "[CV] min_samples_leaf=50, max_depth=2, n_estimators=80 ...............\n",
      "[CV]  min_samples_leaf=90, max_depth=None, n_estimators=80, score=0.903479, total=  59.9s\n",
      "[CV] min_samples_leaf=50, max_depth=2, n_estimators=80 ...............\n",
      "[CV]  min_samples_leaf=50, max_depth=2, n_estimators=80, score=0.885492, total=  13.2s\n",
      "[CV] min_samples_leaf=50, max_depth=2, n_estimators=80 ...............\n",
      "[CV]  min_samples_leaf=90, max_depth=None, n_estimators=90, score=0.907393, total= 1.1min\n",
      "[CV]  min_samples_leaf=90, max_depth=None, n_estimators=90, score=0.902472, total= 1.1min\n",
      "[CV]  min_samples_leaf=90, max_depth=None, n_estimators=90, score=0.901532, total= 1.1min\n",
      "[CV] min_samples_leaf=50, max_depth=2, n_estimators=90 ...............\n",
      "[CV] min_samples_leaf=50, max_depth=2, n_estimators=90 ...............\n",
      "[CV]  min_samples_leaf=50, max_depth=2, n_estimators=80, score=0.850573, total=  14.2s\n",
      "[CV]  min_samples_leaf=50, max_depth=2, n_estimators=80, score=0.886502, total=  13.5s\n",
      "[CV] min_samples_leaf=50, max_depth=2, n_estimators=90 ...............\n",
      "[CV] min_samples_leaf=50, max_depth=2, n_estimators=90 ...............\n",
      "[CV] min_samples_leaf=50, max_depth=2, n_estimators=90 ...............\n",
      "[CV]  min_samples_leaf=50, max_depth=2, n_estimators=80, score=0.867789, total=  11.6s\n",
      "[CV] min_samples_leaf=60, max_depth=2, n_estimators=80 ...............\n",
      "[CV]  min_samples_leaf=50, max_depth=2, n_estimators=90, score=0.886269, total=  13.0s\n",
      "[CV] min_samples_leaf=60, max_depth=2, n_estimators=80 ...............\n",
      "[CV]  min_samples_leaf=50, max_depth=2, n_estimators=90, score=0.890579, total=  13.3s\n",
      "[CV] min_samples_leaf=60, max_depth=2, n_estimators=80 ...............\n",
      "[CV]  min_samples_leaf=50, max_depth=2, n_estimators=90, score=0.875534, total=  13.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  56 tasks      | elapsed:  8.5min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] min_samples_leaf=60, max_depth=2, n_estimators=80 ...............\n",
      "[CV]  min_samples_leaf=50, max_depth=2, n_estimators=90, score=0.877004, total=  14.3s\n",
      "[CV] min_samples_leaf=60, max_depth=2, n_estimators=80 ...............\n",
      "[CV]  min_samples_leaf=50, max_depth=2, n_estimators=90, score=0.871858, total=  14.6s\n",
      "[CV] min_samples_leaf=60, max_depth=2, n_estimators=90 ...............\n",
      "[CV]  min_samples_leaf=90, max_depth=None, n_estimators=90, score=0.911434, total= 1.0min\n",
      "[CV]  min_samples_leaf=60, max_depth=2, n_estimators=80, score=0.868473, total=  12.8s\n",
      "[CV] min_samples_leaf=60, max_depth=2, n_estimators=90 ...............\n",
      "[CV]  min_samples_leaf=60, max_depth=2, n_estimators=80, score=0.887330, total=  12.4s\n",
      "[CV] min_samples_leaf=60, max_depth=2, n_estimators=90 ...............\n",
      "[CV]  min_samples_leaf=60, max_depth=2, n_estimators=80, score=0.867376, total=  11.9s\n",
      "[CV] min_samples_leaf=60, max_depth=2, n_estimators=90 ...............\n",
      "[CV]  min_samples_leaf=90, max_depth=None, n_estimators=90, score=0.906324, total= 1.0min\n",
      "[CV] min_samples_leaf=60, max_depth=2, n_estimators=90 ...............\n",
      "[CV]  min_samples_leaf=60, max_depth=2, n_estimators=80, score=0.878558, total=  12.3s\n",
      "[CV] min_samples_leaf=70, max_depth=2, n_estimators=80 ...............\n",
      "[CV]  min_samples_leaf=60, max_depth=2, n_estimators=80, score=0.862428, total=  12.2s\n",
      "[CV] min_samples_leaf=70, max_depth=2, n_estimators=80 ...............\n",
      "[CV]  min_samples_leaf=60, max_depth=2, n_estimators=90, score=0.870222, total=  11.9s\n",
      "[CV] min_samples_leaf=70, max_depth=2, n_estimators=80 ...............\n",
      "[CV]  min_samples_leaf=60, max_depth=2, n_estimators=90, score=0.882886, total=  12.0s\n",
      "[CV] min_samples_leaf=70, max_depth=2, n_estimators=80 ...............\n",
      "[CV]  min_samples_leaf=60, max_depth=2, n_estimators=90, score=0.864199, total=  12.1s\n",
      "[CV] min_samples_leaf=70, max_depth=2, n_estimators=80 ...............\n",
      "[CV]  min_samples_leaf=60, max_depth=2, n_estimators=90, score=0.869504, total=  12.1s\n",
      "[CV] min_samples_leaf=70, max_depth=2, n_estimators=90 ...............\n",
      "[CV]  min_samples_leaf=60, max_depth=2, n_estimators=90, score=0.866918, total=  11.8s\n",
      "[CV] min_samples_leaf=70, max_depth=2, n_estimators=90 ...............\n",
      "[CV]  min_samples_leaf=70, max_depth=2, n_estimators=80, score=0.870516, total=  11.0s\n",
      "[CV] min_samples_leaf=70, max_depth=2, n_estimators=90 ...............\n",
      "[CV]  min_samples_leaf=70, max_depth=2, n_estimators=80, score=0.876942, total=  10.8s\n",
      "[CV]  min_samples_leaf=70, max_depth=2, n_estimators=80, score=0.845361, total=  10.4s\n",
      "[CV] min_samples_leaf=70, max_depth=2, n_estimators=90 ...............\n",
      "[CV] min_samples_leaf=70, max_depth=2, n_estimators=90 ...............\n",
      "[CV]  min_samples_leaf=70, max_depth=2, n_estimators=80, score=0.873645, total=  10.5s\n",
      "[CV] min_samples_leaf=80, max_depth=2, n_estimators=80 ...............\n",
      "[CV]  min_samples_leaf=70, max_depth=2, n_estimators=80, score=0.868448, total=  10.6s\n",
      "[CV] min_samples_leaf=80, max_depth=2, n_estimators=80 ...............\n",
      "[CV]  min_samples_leaf=70, max_depth=2, n_estimators=90, score=0.859345, total=  11.3s\n",
      "[CV] min_samples_leaf=80, max_depth=2, n_estimators=80 ...............\n",
      "[CV]  min_samples_leaf=70, max_depth=2, n_estimators=90, score=0.874250, total=  11.3s\n",
      "[CV] min_samples_leaf=80, max_depth=2, n_estimators=80 ...............\n",
      "[CV]  min_samples_leaf=70, max_depth=2, n_estimators=90, score=0.861214, total=  11.5s\n",
      "[CV] min_samples_leaf=80, max_depth=2, n_estimators=80 ...............\n",
      "[CV]  min_samples_leaf=70, max_depth=2, n_estimators=90, score=0.876049, total=  11.4s\n",
      "[CV] min_samples_leaf=80, max_depth=2, n_estimators=90 ...............\n",
      "[CV]  min_samples_leaf=70, max_depth=2, n_estimators=90, score=0.861756, total=  11.7s\n",
      "[CV] min_samples_leaf=80, max_depth=2, n_estimators=90 ...............\n",
      "[CV]  min_samples_leaf=80, max_depth=2, n_estimators=80, score=0.860975, total=  11.1s\n",
      "[CV] min_samples_leaf=80, max_depth=2, n_estimators=90 ...............\n",
      "[CV]  min_samples_leaf=80, max_depth=2, n_estimators=80, score=0.854864, total=  11.3s\n",
      "[CV] min_samples_leaf=80, max_depth=2, n_estimators=90 ...............\n",
      "[CV]  min_samples_leaf=80, max_depth=2, n_estimators=80, score=0.863845, total=  11.0s\n",
      "[CV] min_samples_leaf=80, max_depth=2, n_estimators=90 ...............\n",
      "[CV]  min_samples_leaf=80, max_depth=2, n_estimators=80, score=0.880701, total=  11.0s\n",
      "[CV] min_samples_leaf=90, max_depth=2, n_estimators=80 ...............\n",
      "[CV]  min_samples_leaf=80, max_depth=2, n_estimators=80, score=0.856194, total=  10.9s\n",
      "[CV] min_samples_leaf=90, max_depth=2, n_estimators=80 ...............\n",
      "[CV]  min_samples_leaf=80, max_depth=2, n_estimators=90, score=0.863643, total=  11.4s\n",
      "[CV] min_samples_leaf=90, max_depth=2, n_estimators=80 ...............\n",
      "[CV]  min_samples_leaf=80, max_depth=2, n_estimators=90, score=0.872637, total=  11.1s\n",
      "[CV] min_samples_leaf=90, max_depth=2, n_estimators=80 ...............\n",
      "[CV]  min_samples_leaf=80, max_depth=2, n_estimators=90, score=0.853399, total=  11.0s\n",
      "[CV] min_samples_leaf=90, max_depth=2, n_estimators=80 ...............\n",
      "[CV]  min_samples_leaf=80, max_depth=2, n_estimators=90, score=0.881258, total=  11.1s\n",
      "[CV] min_samples_leaf=90, max_depth=2, n_estimators=90 ...............\n",
      "[CV] min_samples_leaf=90, max_depth=2, n_estimators=90 ...............\n",
      "[CV]  min_samples_leaf=80, max_depth=2, n_estimators=90, score=0.875059, total=  12.4s\n",
      "[CV]  min_samples_leaf=90, max_depth=2, n_estimators=80, score=0.866557, total=  11.6s\n",
      "[CV] min_samples_leaf=90, max_depth=2, n_estimators=90 ...............\n",
      "[CV]  min_samples_leaf=90, max_depth=2, n_estimators=80, score=0.867777, total=  12.0s\n",
      "[CV] min_samples_leaf=90, max_depth=2, n_estimators=90 ...............\n",
      "[CV]  min_samples_leaf=90, max_depth=2, n_estimators=80, score=0.858450, total=  11.5s\n",
      "[CV] min_samples_leaf=90, max_depth=2, n_estimators=90 ...............\n",
      "[CV]  min_samples_leaf=90, max_depth=2, n_estimators=80, score=0.878163, total=  12.3s\n",
      "[CV] min_samples_leaf=50, max_depth=5, n_estimators=80 ...............\n",
      "[CV]  min_samples_leaf=90, max_depth=2, n_estimators=80, score=0.843846, total=  12.0s\n",
      "[CV] min_samples_leaf=50, max_depth=5, n_estimators=80 ...............\n",
      "[CV] min_samples_leaf=50, max_depth=5, n_estimators=80 ...............\n",
      "[CV]  min_samples_leaf=90, max_depth=2, n_estimators=90, score=0.882148, total=  13.4s\n",
      "[CV] min_samples_leaf=50, max_depth=5, n_estimators=80 ...............\n",
      "[CV]  min_samples_leaf=90, max_depth=2, n_estimators=90, score=0.875709, total=  13.3s\n",
      "[CV]  min_samples_leaf=90, max_depth=2, n_estimators=90, score=0.862299, total=  12.5s\n",
      "[CV] min_samples_leaf=50, max_depth=5, n_estimators=80 ...............\n",
      "[CV]  min_samples_leaf=90, max_depth=2, n_estimators=90, score=0.876671, total=  12.4s\n",
      "[CV] min_samples_leaf=50, max_depth=5, n_estimators=90 ...............\n",
      "[CV]  min_samples_leaf=90, max_depth=2, n_estimators=90, score=0.865556, total=  12.7s\n",
      "[CV] min_samples_leaf=50, max_depth=5, n_estimators=90 ...............\n",
      "[CV] min_samples_leaf=50, max_depth=5, n_estimators=90 ...............\n",
      "[CV]  min_samples_leaf=50, max_depth=5, n_estimators=80, score=0.890042, total=  22.4s\n",
      "[CV] min_samples_leaf=50, max_depth=5, n_estimators=90 ...............\n",
      "[CV]  min_samples_leaf=50, max_depth=5, n_estimators=80, score=0.890680, total=  23.3s\n",
      "[CV] min_samples_leaf=50, max_depth=5, n_estimators=90 ...............\n",
      "[CV]  min_samples_leaf=50, max_depth=5, n_estimators=80, score=0.889680, total=  22.4s\n",
      "[CV] min_samples_leaf=60, max_depth=5, n_estimators=80 ...............\n",
      "[CV]  min_samples_leaf=50, max_depth=5, n_estimators=80, score=0.893315, total=  21.9s\n",
      "[CV] min_samples_leaf=60, max_depth=5, n_estimators=80 ...............\n",
      "[CV]  min_samples_leaf=50, max_depth=5, n_estimators=80, score=0.891036, total=  22.7s\n",
      "[CV] min_samples_leaf=60, max_depth=5, n_estimators=80 ...............\n",
      "[CV]  min_samples_leaf=50, max_depth=5, n_estimators=90, score=0.893192, total=  26.5s\n",
      "[CV] min_samples_leaf=60, max_depth=5, n_estimators=80 ...............\n",
      "[CV]  min_samples_leaf=50, max_depth=5, n_estimators=90, score=0.898591, total=  27.6s\n",
      "[CV] min_samples_leaf=60, max_depth=5, n_estimators=80 ...............\n",
      "[CV]  min_samples_leaf=50, max_depth=5, n_estimators=90, score=0.885648, total=  27.2s\n",
      "[CV] min_samples_leaf=60, max_depth=5, n_estimators=90 ...............\n",
      "[CV]  min_samples_leaf=50, max_depth=5, n_estimators=90, score=0.899113, total=  26.3s\n",
      "[CV] min_samples_leaf=60, max_depth=5, n_estimators=90 ...............\n",
      "[CV]  min_samples_leaf=50, max_depth=5, n_estimators=90, score=0.889977, total=  28.0s\n",
      "[CV] min_samples_leaf=60, max_depth=5, n_estimators=90 ...............\n",
      "[CV]  min_samples_leaf=60, max_depth=5, n_estimators=80, score=0.884838, total=  26.7s\n",
      "[CV]  min_samples_leaf=60, max_depth=5, n_estimators=80, score=0.894428, total=  26.7s\n",
      "[CV] min_samples_leaf=60, max_depth=5, n_estimators=90 ...............\n",
      "[CV] min_samples_leaf=60, max_depth=5, n_estimators=90 ...............\n",
      "[CV]  min_samples_leaf=60, max_depth=5, n_estimators=80, score=0.890970, total=  25.0s\n",
      "[CV] min_samples_leaf=70, max_depth=5, n_estimators=80 ...............\n",
      "[CV]  min_samples_leaf=60, max_depth=5, n_estimators=80, score=0.899189, total=  25.8s\n",
      "[CV] min_samples_leaf=70, max_depth=5, n_estimators=80 ...............\n",
      "[CV]  min_samples_leaf=60, max_depth=5, n_estimators=80, score=0.888980, total=  26.2s\n",
      "[CV] min_samples_leaf=70, max_depth=5, n_estimators=80 ...............\n",
      "[CV]  min_samples_leaf=60, max_depth=5, n_estimators=90, score=0.895070, total=  28.7s\n",
      "[CV] min_samples_leaf=70, max_depth=5, n_estimators=80 ...............\n",
      "[CV]  min_samples_leaf=60, max_depth=5, n_estimators=90, score=0.900896, total=  26.9s\n",
      "[CV] min_samples_leaf=70, max_depth=5, n_estimators=80 ...............\n",
      "[CV]  min_samples_leaf=60, max_depth=5, n_estimators=90, score=0.888670, total=  27.5s\n",
      "[CV] min_samples_leaf=70, max_depth=5, n_estimators=90 ...............\n",
      "[CV]  min_samples_leaf=60, max_depth=5, n_estimators=90, score=0.901242, total=  27.9s\n",
      "[CV] min_samples_leaf=70, max_depth=5, n_estimators=90 ...............\n",
      "[CV]  min_samples_leaf=70, max_depth=5, n_estimators=80, score=0.891894, total=  25.8s\n",
      "[CV] min_samples_leaf=70, max_depth=5, n_estimators=90 ...............\n",
      "[CV]  min_samples_leaf=60, max_depth=5, n_estimators=90, score=0.891757, total=  28.6s\n",
      "[CV] min_samples_leaf=70, max_depth=5, n_estimators=90 ...............\n",
      "[CV]  min_samples_leaf=70, max_depth=5, n_estimators=80, score=0.898992, total=  24.1s\n",
      "[CV] min_samples_leaf=70, max_depth=5, n_estimators=90 ...............\n",
      "[CV]  min_samples_leaf=70, max_depth=5, n_estimators=80, score=0.884954, total=  23.4s\n",
      "[CV] min_samples_leaf=80, max_depth=5, n_estimators=80 ...............\n",
      "[CV]  min_samples_leaf=70, max_depth=5, n_estimators=80, score=0.903624, total=  23.1s\n",
      "[CV] min_samples_leaf=80, max_depth=5, n_estimators=80 ...............\n",
      "[CV]  min_samples_leaf=70, max_depth=5, n_estimators=80, score=0.890818, total=  23.6s\n",
      "[CV] min_samples_leaf=80, max_depth=5, n_estimators=80 ...............\n",
      "[CV]  min_samples_leaf=70, max_depth=5, n_estimators=90, score=0.897871, total=  25.9s\n",
      "[CV] min_samples_leaf=80, max_depth=5, n_estimators=80 ...............\n",
      "[CV]  min_samples_leaf=70, max_depth=5, n_estimators=90, score=0.897704, total=  26.6s\n",
      "[CV] min_samples_leaf=80, max_depth=5, n_estimators=80 ...............\n",
      "[CV]  min_samples_leaf=70, max_depth=5, n_estimators=90, score=0.875675, total=  27.1s\n",
      "[CV] min_samples_leaf=80, max_depth=5, n_estimators=90 ...............\n",
      "[CV]  min_samples_leaf=70, max_depth=5, n_estimators=90, score=0.898081, total=  28.7s\n",
      "[CV] min_samples_leaf=80, max_depth=5, n_estimators=90 ...............\n",
      "[CV]  min_samples_leaf=70, max_depth=5, n_estimators=90, score=0.895989, total=  30.2s\n",
      "[CV] min_samples_leaf=80, max_depth=5, n_estimators=90 ...............\n",
      "[CV]  min_samples_leaf=80, max_depth=5, n_estimators=80, score=0.894472, total=  29.8s\n",
      "[CV] min_samples_leaf=80, max_depth=5, n_estimators=90 ...............\n",
      "[CV]  min_samples_leaf=80, max_depth=5, n_estimators=80, score=0.893399, total=  28.2s\n",
      "[CV] min_samples_leaf=80, max_depth=5, n_estimators=90 ...............\n",
      "[CV]  min_samples_leaf=80, max_depth=5, n_estimators=80, score=0.883510, total=  28.2s\n",
      "[CV] min_samples_leaf=90, max_depth=5, n_estimators=80 ...............\n",
      "[CV]  min_samples_leaf=80, max_depth=5, n_estimators=80, score=0.898573, total=  28.0s\n",
      "[CV] min_samples_leaf=90, max_depth=5, n_estimators=80 ...............\n",
      "[CV]  min_samples_leaf=80, max_depth=5, n_estimators=80, score=0.888776, total=  27.9s\n",
      "[CV] min_samples_leaf=90, max_depth=5, n_estimators=80 ...............\n",
      "[CV]  min_samples_leaf=80, max_depth=5, n_estimators=90, score=0.893961, total=  28.0s\n",
      "[CV] min_samples_leaf=90, max_depth=5, n_estimators=80 ...............\n",
      "[CV]  min_samples_leaf=80, max_depth=5, n_estimators=90, score=0.903143, total=  29.3s\n",
      "[CV] min_samples_leaf=90, max_depth=5, n_estimators=80 ...............\n",
      "[CV]  min_samples_leaf=80, max_depth=5, n_estimators=90, score=0.877244, total=  29.2s\n",
      "[CV] min_samples_leaf=90, max_depth=5, n_estimators=90 ...............\n",
      "[CV]  min_samples_leaf=80, max_depth=5, n_estimators=90, score=0.899347, total=  29.0s\n",
      "[CV] min_samples_leaf=90, max_depth=5, n_estimators=90 ...............\n",
      "[CV]  min_samples_leaf=80, max_depth=5, n_estimators=90, score=0.895757, total=  26.8s\n",
      "[CV] min_samples_leaf=90, max_depth=5, n_estimators=90 ...............\n",
      "[CV]  min_samples_leaf=90, max_depth=5, n_estimators=80, score=0.888039, total=  23.7s\n",
      "[CV] min_samples_leaf=90, max_depth=5, n_estimators=90 ...............\n",
      "[CV]  min_samples_leaf=90, max_depth=5, n_estimators=80, score=0.897184, total=  24.1s\n",
      "[CV] min_samples_leaf=90, max_depth=5, n_estimators=90 ...............\n",
      "[CV]  min_samples_leaf=90, max_depth=5, n_estimators=80, score=0.885516, total=  23.4s\n",
      "[CV] min_samples_leaf=50, max_depth=10, n_estimators=80 ..............\n",
      "[CV]  min_samples_leaf=90, max_depth=5, n_estimators=80, score=0.896279, total=  23.8s\n",
      "[CV] min_samples_leaf=50, max_depth=10, n_estimators=80 ..............\n",
      "[CV]  min_samples_leaf=90, max_depth=5, n_estimators=80, score=0.882565, total=  23.4s\n",
      "[CV] min_samples_leaf=50, max_depth=10, n_estimators=80 ..............\n",
      "[CV]  min_samples_leaf=90, max_depth=5, n_estimators=90, score=0.898470, total=  27.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 146 tasks      | elapsed: 12.9min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] min_samples_leaf=50, max_depth=10, n_estimators=80 ..............\n",
      "[CV]  min_samples_leaf=90, max_depth=5, n_estimators=90, score=0.898265, total=  27.4s\n",
      "[CV] min_samples_leaf=50, max_depth=10, n_estimators=80 ..............\n",
      "[CV]  min_samples_leaf=90, max_depth=5, n_estimators=90, score=0.883362, total=  28.9s\n",
      "[CV] min_samples_leaf=50, max_depth=10, n_estimators=90 ..............\n",
      "[CV]  min_samples_leaf=90, max_depth=5, n_estimators=90, score=0.900658, total=  28.4s\n",
      "[CV] min_samples_leaf=50, max_depth=10, n_estimators=90 ..............\n",
      "[CV]  min_samples_leaf=90, max_depth=5, n_estimators=90, score=0.896738, total=  27.4s\n",
      "[CV] min_samples_leaf=50, max_depth=10, n_estimators=90 ..............\n",
      "[CV]  min_samples_leaf=50, max_depth=10, n_estimators=80, score=0.903339, total=  39.9s\n",
      "[CV] min_samples_leaf=50, max_depth=10, n_estimators=90 ..............\n",
      "[CV]  min_samples_leaf=50, max_depth=10, n_estimators=80, score=0.907231, total=  39.5s\n",
      "[CV] min_samples_leaf=50, max_depth=10, n_estimators=90 ..............\n",
      "[CV]  min_samples_leaf=50, max_depth=10, n_estimators=80, score=0.898999, total=  40.3s\n",
      "[CV] min_samples_leaf=60, max_depth=10, n_estimators=80 ..............\n",
      "[CV]  min_samples_leaf=50, max_depth=10, n_estimators=80, score=0.908847, total=  39.6s\n",
      "[CV] min_samples_leaf=60, max_depth=10, n_estimators=80 ..............\n",
      "[CV]  min_samples_leaf=50, max_depth=10, n_estimators=80, score=0.902836, total=  40.5s\n",
      "[CV] min_samples_leaf=60, max_depth=10, n_estimators=80 ..............\n",
      "[CV]  min_samples_leaf=50, max_depth=10, n_estimators=90, score=0.901274, total=  44.9s\n",
      "[CV] min_samples_leaf=60, max_depth=10, n_estimators=80 ..............\n",
      "[CV]  min_samples_leaf=50, max_depth=10, n_estimators=90, score=0.911314, total=  44.8s\n",
      "[CV] min_samples_leaf=60, max_depth=10, n_estimators=80 ..............\n",
      "[CV]  min_samples_leaf=50, max_depth=10, n_estimators=90, score=0.893564, total=  44.1s\n",
      "[CV] min_samples_leaf=60, max_depth=10, n_estimators=90 ..............\n",
      "[CV]  min_samples_leaf=50, max_depth=10, n_estimators=90, score=0.913570, total=  44.4s\n",
      "[CV] min_samples_leaf=60, max_depth=10, n_estimators=90 ..............\n",
      "[CV]  min_samples_leaf=60, max_depth=10, n_estimators=80, score=0.899535, total=  40.8s\n",
      "[CV] min_samples_leaf=60, max_depth=10, n_estimators=90 ..............\n",
      "[CV]  min_samples_leaf=50, max_depth=10, n_estimators=90, score=0.901219, total=  45.7s\n",
      "[CV] min_samples_leaf=60, max_depth=10, n_estimators=90 ..............\n",
      "[CV]  min_samples_leaf=60, max_depth=10, n_estimators=80, score=0.903482, total=  40.9s\n",
      "[CV] min_samples_leaf=60, max_depth=10, n_estimators=90 ..............\n",
      "[CV]  min_samples_leaf=60, max_depth=10, n_estimators=80, score=0.898406, total=  41.3s\n",
      "[CV] min_samples_leaf=70, max_depth=10, n_estimators=80 ..............\n",
      "[CV]  min_samples_leaf=60, max_depth=10, n_estimators=80, score=0.907929, total=  41.9s\n",
      "[CV] min_samples_leaf=70, max_depth=10, n_estimators=80 ..............\n",
      "[CV]  min_samples_leaf=60, max_depth=10, n_estimators=80, score=0.901458, total=  42.6s\n",
      "[CV] min_samples_leaf=70, max_depth=10, n_estimators=80 ..............\n",
      "[CV]  min_samples_leaf=60, max_depth=10, n_estimators=90, score=0.900746, total=  46.2s\n",
      "[CV] min_samples_leaf=70, max_depth=10, n_estimators=80 ..............\n",
      "[CV]  min_samples_leaf=60, max_depth=10, n_estimators=90, score=0.911279, total=  44.9s\n",
      "[CV] min_samples_leaf=70, max_depth=10, n_estimators=80 ..............\n",
      "[CV]  min_samples_leaf=60, max_depth=10, n_estimators=90, score=0.893567, total=  46.1s\n",
      "[CV] min_samples_leaf=70, max_depth=10, n_estimators=90 ..............\n",
      "[CV]  min_samples_leaf=60, max_depth=10, n_estimators=90, score=0.903357, total=  45.5s\n",
      "[CV] min_samples_leaf=70, max_depth=10, n_estimators=90 ..............\n",
      "[CV]  min_samples_leaf=70, max_depth=10, n_estimators=80, score=0.898021, total=  39.6s\n",
      "[CV] min_samples_leaf=70, max_depth=10, n_estimators=90 ..............\n",
      "[CV]  min_samples_leaf=60, max_depth=10, n_estimators=90, score=0.898502, total=  44.4s\n",
      "[CV] min_samples_leaf=70, max_depth=10, n_estimators=90 ..............\n",
      "[CV]  min_samples_leaf=70, max_depth=10, n_estimators=80, score=0.903437, total=  38.7s\n",
      "[CV] min_samples_leaf=70, max_depth=10, n_estimators=90 ..............\n",
      "[CV]  min_samples_leaf=70, max_depth=10, n_estimators=80, score=0.896343, total=  39.1s\n",
      "[CV] min_samples_leaf=80, max_depth=10, n_estimators=80 ..............\n",
      "[CV]  min_samples_leaf=70, max_depth=10, n_estimators=80, score=0.901930, total=  38.1s\n",
      "[CV] min_samples_leaf=80, max_depth=10, n_estimators=80 ..............\n",
      "[CV]  min_samples_leaf=70, max_depth=10, n_estimators=80, score=0.902107, total=  37.9s\n",
      "[CV] min_samples_leaf=80, max_depth=10, n_estimators=80 ..............\n",
      "[CV]  min_samples_leaf=70, max_depth=10, n_estimators=90, score=0.900738, total=  44.4s\n",
      "[CV] min_samples_leaf=80, max_depth=10, n_estimators=80 ..............\n",
      "[CV]  min_samples_leaf=70, max_depth=10, n_estimators=90, score=0.910635, total=  44.0s\n",
      "[CV] min_samples_leaf=80, max_depth=10, n_estimators=80 ..............\n",
      "[CV]  min_samples_leaf=70, max_depth=10, n_estimators=90, score=0.896450, total=  44.0s\n",
      "[CV] min_samples_leaf=80, max_depth=10, n_estimators=90 ..............\n",
      "[CV]  min_samples_leaf=70, max_depth=10, n_estimators=90, score=0.906166, total=  44.5s\n",
      "[CV] min_samples_leaf=80, max_depth=10, n_estimators=90 ..............\n",
      "[CV]  min_samples_leaf=80, max_depth=10, n_estimators=80, score=0.895404, total=  39.3s\n",
      "[CV] min_samples_leaf=80, max_depth=10, n_estimators=90 ..............\n",
      "[CV]  min_samples_leaf=70, max_depth=10, n_estimators=90, score=0.902155, total=  43.5s\n",
      "[CV] min_samples_leaf=80, max_depth=10, n_estimators=90 ..............\n",
      "[CV]  min_samples_leaf=80, max_depth=10, n_estimators=80, score=0.907963, total=  39.3s\n",
      "[CV] min_samples_leaf=80, max_depth=10, n_estimators=90 ..............\n",
      "[CV]  min_samples_leaf=80, max_depth=10, n_estimators=80, score=0.892812, total=  37.5s\n",
      "[CV] min_samples_leaf=90, max_depth=10, n_estimators=80 ..............\n",
      "[CV]  min_samples_leaf=80, max_depth=10, n_estimators=80, score=0.908486, total=  39.0s\n",
      "[CV] min_samples_leaf=90, max_depth=10, n_estimators=80 ..............\n",
      "[CV]  min_samples_leaf=80, max_depth=10, n_estimators=80, score=0.897841, total=  39.8s\n",
      "[CV] min_samples_leaf=90, max_depth=10, n_estimators=80 ..............\n",
      "[CV]  min_samples_leaf=80, max_depth=10, n_estimators=90, score=0.898377, total=  43.7s\n",
      "[CV] min_samples_leaf=90, max_depth=10, n_estimators=80 ..............\n",
      "[CV]  min_samples_leaf=80, max_depth=10, n_estimators=90, score=0.907446, total=  43.7s\n",
      "[CV] min_samples_leaf=90, max_depth=10, n_estimators=80 ..............\n",
      "[CV]  min_samples_leaf=80, max_depth=10, n_estimators=90, score=0.896342, total=  44.5s\n",
      "[CV] min_samples_leaf=90, max_depth=10, n_estimators=90 ..............\n",
      "[CV]  min_samples_leaf=80, max_depth=10, n_estimators=90, score=0.908501, total=  45.3s\n",
      "[CV] min_samples_leaf=90, max_depth=10, n_estimators=90 ..............\n",
      "[CV]  min_samples_leaf=80, max_depth=10, n_estimators=90, score=0.899893, total=  45.0s\n",
      "[CV] min_samples_leaf=90, max_depth=10, n_estimators=90 ..............\n",
      "[CV]  min_samples_leaf=90, max_depth=10, n_estimators=80, score=0.896472, total=  38.8s\n",
      "[CV] min_samples_leaf=90, max_depth=10, n_estimators=90 ..............\n",
      "[CV]  min_samples_leaf=90, max_depth=10, n_estimators=80, score=0.905660, total=  40.3s\n",
      "[CV] min_samples_leaf=90, max_depth=10, n_estimators=90 ..............\n",
      "[CV]  min_samples_leaf=90, max_depth=10, n_estimators=80, score=0.890261, total=  40.5s\n",
      "[CV]  min_samples_leaf=90, max_depth=10, n_estimators=80, score=0.909656, total=  39.4s\n",
      "[CV]  min_samples_leaf=90, max_depth=10, n_estimators=80, score=0.897307, total=  38.9s\n",
      "[CV]  min_samples_leaf=90, max_depth=10, n_estimators=90, score=0.900554, total=  41.0s\n",
      "[CV]  min_samples_leaf=90, max_depth=10, n_estimators=90, score=0.901329, total=  38.4s\n",
      "[CV]  min_samples_leaf=90, max_depth=10, n_estimators=90, score=0.890249, total=  37.4s\n",
      "[CV]  min_samples_leaf=90, max_depth=10, n_estimators=90, score=0.911937, total=  35.6s\n",
      "[CV]  min_samples_leaf=90, max_depth=10, n_estimators=90, score=0.898554, total=  26.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 200 out of 200 | elapsed: 17.6min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken for X5 predictions:  1112.1471800804138 seconds.\n"
     ]
    }
   ],
   "source": [
    "start =  time.time()\n",
    "y_score5 = rf_clf5.fit(X_counts, np.array(train[\"sentiment\"].tolist())).predict(X_counts2)\n",
    "\n",
    "\n",
    "# Get the end time and print how long the process took\n",
    "end = time.time()\n",
    "elapsed = end - start\n",
    "print (\"Time taken for X5 predictions: \", elapsed, \"seconds.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data = {\"id\": test[\"id\"], \"sentiment\": y_score1})\n",
    "df.to_csv(\"sampleSubmission1.csv\", quoting = 3, index = False)\n",
    "df = pd.DataFrame(data = {\"id\": test[\"id\"], \"sentiment\": y_score2})\n",
    "df.to_csv(\"sampleSubmission2.csv\", quoting = 3, index = False)\n",
    "df = pd.DataFrame(data = {\"id\": test[\"id\"], \"sentiment\": y_score3})\n",
    "df.to_csv(\"sampleSubmission3.csv\", quoting = 3, index = False)\n",
    "df = pd.DataFrame(data = {\"id\": test[\"id\"], \"sentiment\": y_score4})\n",
    "df.to_csv(\"sampleSubmission4.csv\", quoting = 3, index = False)\n",
    "#df = pd.DataFrame(data = {\"id\": test[\"id\"], \"sentiment\": y_score5})\n",
    "#df.to_csv(\"sampleSubmission.csv\", quoting = 3, index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Kaggle submission scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "X1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"http://imgur.com/rIrLvGN\"><img src=\"http://i.imgur.com/rIrLvGN.png\" title=\"source: imgur.com\" /></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "X2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"http://imgur.com/RvLearN\"><img src=\"http://i.imgur.com/RvLearN.png\" title=\"source: imgur.com\" /></a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "X3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"http://imgur.com/bCNxM0G\"><img src=\"http://i.imgur.com/bCNxM0G.png\" title=\"source: imgur.com\" /></a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "X4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"http://imgur.com/8tDQtKQ\"><img src=\"http://i.imgur.com/8tDQtKQ.png\" title=\"source: imgur.com\" /></a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "X5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"http://imgur.com/CQlxzpr\"><img src=\"http://i.imgur.com/CQlxzpr.png?1\" title=\"source: imgur.com\" /></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Part c\n",
    "\n",
    "Based on the Kaggle submission scores, we can see that the fourth featurization technique (using an LDA model with 20 topics) worked best for sentiment classification. It had an in-sample ROC AUC score of 0.74 and a Kaggle score of 0.68236. \n",
    "\n",
    "This is better than the Kaggle score achieved by using a simple bag of words (0.60), however the simple BOW model had a higher insample AUC score. \n",
    "\n",
    "To improve the classifier, we can take the following 3 steps:\n",
    "\n",
    "1) Use a higher number of topics (i.e. greater than 20)\n",
    "\n",
    "2) Train the model on a larger corpus (i.e. including the unlabeled training data)\n",
    "\n",
    "3) Tune the random forest classifier's parameters over a larger grid of values to arrive at an optimum classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
